{"id":"claude-01a","title":"Immich: Foto-Import (~135GB von Solaris)","description":"## Quellen (auf Solaris/MacBook)\n\n### 1. Fotos-Mediathek (~34.335 Fotos, iCloud-synced)\n- Import: Über Immich iOS App (läuft)\n- HEIC + JPEG, EXIF-Daten und Alben bleiben erhalten\n\n### 2. Event-Fotos (loose files, ~3,4 GB) ✅\n- Play4Agile 2024: 1.022 Fotos → Album \"Play4Agile 2024\"\n- RFG 2023: 36 Fotos → Album \"RFG 2023\"\n- Agile Coach Camp Germany 2019: 154 Fotos → Album \"Agile Coach Camp Germany 2019\"\n- VIYEMA: 85 Fotos → Album \"VIYEMA\"\n\n### 3. Syndication Library — IRRELEVANT\n- Nur Apple-interner Cache (Featured Photos, iMessage-Hintergründe, Widget-Daten)\n- Keine eigenständigen Fotos, alles schon in der Haupt-Mediathek\n\n## Infrastruktur\n- Immich v2.5.6 auf LXC 107 (alle Container healthy)\n- Reverse Proxy: photos.sussdorff.de via Caddy (LXC 102)\n- ML Container für Face Recognition läuft\n- API Key (cli) mit Permissions: user.read, asset.upload, album.create, album.read, albumAsset.create\n\n## Akzeptanzkriterien\n- [x] Immich iOS App konfiguriert und Upload gestartet\n- [ ] Fotos-Mediathek vollständig importiert (läuft, ~34.335 Elemente)\n- [x] Event-Fotos importiert (1.297 Fotos in 4 Alben)\n- [x] Face Recognition läuft (ML Container)\n- [x] Fotos von extern abrufbar (https://photos.sussdorff.de)","notes":"POST-IMPORT ARCHIVIERUNG: Nach erfolgreichem Import Quelldateien auf PRO-G40 verschieben (Pattern: claude-e41). Ziel: /Volumes/PRO-G40/Imported-to-Elysium/{Service}/ mit .manifest.json. Befreit lokalen Speicher auf Solaris und dokumentiert Import-Status.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:03:19Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","closed_at":"2026-02-17T12:55:29Z","close_reason":"Event-Fotos importiert (1.297 in 4 Alben), iOS-Upload läuft im Hintergrund (~34.335 Elemente). Syndication Library als irrelevant identifiziert (Apple-Cache).","labels":["epic:claude-k6i"]}
{"id":"claude-0go","title":"ntfy: Self-hosted oder eigenes Topic für AlertManager einrichten","description":"## Hintergrund\nAlertManager nutzt aktuell den Placeholder-Topic https://ntfy.sh/claude-alerts. \nDas ist ein öffentliches Topic auf ntfy.sh — jeder der den Topicnamen kennt kann mitlesen.\n\n## Optionen\n1. **Self-hosted ntfy** auf Elysium (eigener LXC oder als Container im Monitoring-LXC)\n2. **Privates Topic auf ntfy.sh** mit Access Token\n3. **Pushover** statt ntfy (kostenpflichtig, aber nativ in vielen Tools)\n\n## Akzeptanzkriterien\n- [ ] Notification-Kanal entschieden und eingerichtet\n- [ ] AlertManager config aktualisiert (alertmanager.yml)\n- [ ] Test-Notification erfolgreich empfangen auf Smartphone\n- [ ] Deploy-Script (deploy.sh) aktualisiert","status":"open","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:56:18Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z"}
{"id":"claude-0hv","title":"Calibre-Web auf Elysium deployen (E-Book Server)","description":"## Ziel\nSelf-hosted Buecherei fuer E-Books. Web-UI + OPDS-Feed fuer E-Reader Apps.\n\n## Ist-Zustand\n- 2 Calibre Libraries lokal auf Solaris:\n  - ~/Calibre Library (4 Buecher)\n  - ~/Calibre-Bibliothek (17 Buecher)\n- ~710 E-Book Dateien in ~/Documents (.mobi, .epub, .lrf)\n- ~/Hugo/ -- Hugo Awards Voter Pakete 2016-2025 (73 GB!)\n  - Jaehrliche Sammlungen nominierter Werke (E-Books, Novellas etc.)\n- Calibre Desktop App installiert\n- Apple Books vermutlich auch einige Buecher\n\n## Schritte\n1. LXC/Docker fuer Calibre-Web auf Elysium\n2. Calibre Libraries nach Elysium migrieren\n3. Lose E-Book Dateien aus Documents in Calibre importieren\n4. Hugo Awards Sammlung importieren (73 GB -- groesster Posten)\n5. Apple Books exportieren und importieren (falls moeglich)\n6. Web-UI via Caddy (books.sussdorff.de)\n7. OPDS-Feed aktivieren (kompatibel mit iOS E-Reader Apps)\n8. Backup auf DAS\n\n## Domain\nbooks.sussdorff.de (Hetzner DNS, Caddy, Let's Encrypt)\n\n## Ressourcen\n- RAM: ~256 MB\n- Disk: ~80+ GB (hauptsaechlich Hugo Awards)\n- CPU: Minimal\n\n## Akzeptanzkriterien\n- [ ] Calibre-Web erreichbar unter books.sussdorff.de\n- [ ] Alle E-Books importiert und durchsuchbar (inkl. Hugo Awards)\n- [ ] OPDS-Feed funktioniert\n- [ ] Backup auf DAS","notes":"LXC setup-skripte + docker-compose + deploy.sh erstellt (lxc/calibre-web/). Caddy-Entry für books.sussdorff.de. Nächster Schritt: setup-lxc.sh auf Proxmox, deploy.sh, dann Bücher importieren (Hugo Awards 73GB + Calibre Libraries + lose E-Books).\nDeployed und verifiziert. Calibre-Web läuft mit leerer Calibre-DB. Extern erreichbar unter https://books.sussdorff.de (HTTP 302 -\u003e Login). Default: admin/admin123.\nWeb-Setup abgeschlossen. Admin-Passwort geändert. DB-Writeable Warning (Permissions prüfen). Bücher noch nicht importiert.","status":"closed","priority":3,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T10:14:23Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:43Z","closed_at":"2026-02-17T02:50:30Z","close_reason":"LXC 109 deployed, Calibre-Web mit leerer DB läuft. Admin PW geändert. Bücher noch nicht importiert (separater Bead).","labels":["epic:claude-k6i"]}
{"id":"claude-0tk","title":"node_exporter auf allen LXCs + Proxmox Host deployen","description":"## Anforderungen\nnode_exporter auf allen laufenden LXC-Containern und dem Proxmox Host installieren.\n\n## Vorgehen\n- node_exporter Binary auf jedem LXC installieren (systemd service)\n- Port 9100 auf jedem Container\n- Prometheus scrape config erweitern um alle Targets\n- Auf Proxmox Host ebenfalls node_exporter installieren\n\n## Akzeptanzkriterien\n- [ ] node_exporter läuft auf allen LXCs als systemd service\n- [ ] node_exporter läuft auf Proxmox Host\n- [ ] Prometheus scraped erfolgreich alle Targets (Targets-Page zeigt \"UP\")\n- [ ] Metriken node_filesystem_avail_bytes und node_memory_MemAvailable_bytes verfügbar\n- [ ] Deploy-Script für node_exporter Installation (wiederholbar)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:30:34Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:44Z","closed_at":"2026-02-17T14:44:58Z","close_reason":"node_exporter v1.8.2 auf allen 11 LXCs + Proxmox Host deployed, alle 18 Prometheus Targets UP","dependencies":[{"issue_id":"claude-0tk","depends_on_id":"claude-tlf","type":"blocks","created_at":"2026-02-17T15:31:03Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-0wv","title":"[LEARNING] NetBird Reverse Proxy is UI-only — no API for service configuration","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T18:01:02Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:45Z","labels":["learning"]}
{"id":"claude-0xg","title":"Globaler piler-cli Skill für Claude Code","description":"Skill unter ~/.claude/skills/piler-cli/ der dokumentiert wie der piler CLI zu nutzen ist. Trigger: mailpiler, mail archiv, piler search, archived mail. Analog zu abs-cli/hass-cli Pattern. Acceptance: Claude Code triggert Skill bei relevanten Fragen.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:27:19Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:46Z","closed_at":"2026-02-18T04:31:46Z","close_reason":"Im Scaffold-Task mitimplementiert und gegen Live-Instanz getestet","labels":["epic:claude-ecz"],"dependencies":[{"issue_id":"claude-0xg","depends_on_id":"claude-8oh","type":"blocks","created_at":"2026-02-18T05:27:29Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-14v","title":"[DISCOVERY] Intranet-Zukunft klären (project-open / erp4projects)","description":"Entscheidung treffen ob cognovis Intranet (project-open / erp4projects) weitergeführt, migriert oder ersetzt wird.\n\n## Kontext\n- Läuft auf Hetzner VPS (erp4projects), Docker Compose, PostgreSQL 9\n- project-open wird kaum noch genutzt, nicht aktiv vertrieben\n- 1 Altkunde\n- PG9 ist EOL, Upgrade auf PG16 vermutlich inkompatibel mit aktuellem Stack\n\n## Optionen\n1. Weiter betreiben auf Elysium LXC (1:1 Migration mit PG9)\n2. Auf leichtgewichtiges Rechnungstool umstellen\n3. Für Altkunden weiter betreiben, kein Invest\n\n## Ergebnis\n- Entscheidung dokumentieren\n- Bei Migration: claude-32d aktualisieren\n- Beeinflusst wann alter Hetzner VPS (CX22) stillgelegt werden kann\n\n## Siehe auch\n- claude-32d (erp4projects Server nach Elysium migrieren)","status":"open","priority":4,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:49:55Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z"}
{"id":"claude-16v","title":"ScanSnap iX1600: WiFi-Profil für Paperless SMB-Share einrichten","description":"## Scope\nScanSnap iX1600 per WiFi direkt auf den Paperless consume-Ordner scannen lassen.\n\n## Vorgehen\n1. Scanner-Firmware auf aktuellsten Stand bringen (ScanSnap Home)\n2. In ScanSnap Home neues Profil erstellen:\n   - Ziel: Netzwerk-Ordner\n   - Pfad: \\\\192.168.60.24\\scaninput (oder IP des Paperless-LXC)\n   - Credentials: scanner-User aus Samba-Setup\n   - Dateiformat: PDF (Searchable) oder PDF (Image) — Paperless macht OCR\n3. Profil auf Scanner-Touchscreen pushen\n4. Testscans durchführen:\n   - Einzelseite\n   - Mehrseitig (Duplex)\n   - Verschiedene Formate\n\n## Voraussetzung\n- Scanner muss im selben Netzwerk sein (oder VLAN-Routing aktiv)\n- iX1600 ist auf 192.168.2.x (WiFi), Paperless auf 192.168.60.x (VLAN 60)\n  → Routing zwischen VLANs muss funktionieren, oder Scanner in VLAN 60 bringen\n\n## Offene Frage\n- VLAN-Routing: Kann der Scanner (192.168.2.x WiFi) den SMB-Share auf VLAN 60 erreichen?\n  Optionen: a) Router-Regel, b) Paperless auch auf vmbr0 lauschen lassen, c) Scanner per WiFi in VLAN 60\n\n## Akzeptanzkriterien\n- [ ] Scanner-Firmware aktuell\n- [ ] WiFi-Profil konfiguriert und auf Touchscreen verfügbar\n- [ ] Testscan landet in Paperless consume-Ordner\n- [ ] Paperless erkennt und importiert den Scan automatisch\n- [ ] OCR-Text in Paperless vorhanden","notes":"SCANNER: ScanSnap iX1600 auf VLAN 10 (Sussdorff), IP 192.168.10.20, MAC 1C:BC:EC:1B:E6:9C. Auch per USB an Elysium. WiFi-Profil muss SMB-Share auf 192.168.60.18 targetieren. Inter-VLAN Routing 10\u003c-\u003e60 aktiv.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T07:43:48Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:48Z","closed_at":"2026-02-19T07:12:32Z","close_reason":"ScanSnap iX1600 WiFi-Profil konfiguriert via ScanSnap Home (Netzwerkordner, SMB auf 192.168.60.18/scaninput). Testscan erfolgreich: 3-Seiten-PDF, OCR, Document ID 2 in Paperless.","labels":["epic:claude-6wa"],"dependencies":[{"issue_id":"claude-16v","depends_on_id":"claude-jf2","type":"blocks","created_at":"2026-02-18T08:43:59Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-1c2","title":"piler-cli: search — Volltextsuche über Manticore","description":"'piler search \"rechnung cognovis\"' sucht über Manticore piler1 Index. Muss Email-Adressen in Tokens aufsplitten (Manticore tokenisiert @ und . weg). Felder: subject, body, sender, rcpt. Output: Tabelle mit ID, From, Subject, Date. Acceptance: Suche nach bekannter Mail findet sie.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:27:06Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:48Z","closed_at":"2026-02-18T04:31:46Z","close_reason":"Im Scaffold-Task mitimplementiert und gegen Live-Instanz getestet","labels":["epic:claude-ecz"],"dependencies":[{"issue_id":"claude-1c2","depends_on_id":"claude-8oh","type":"blocks","created_at":"2026-02-18T05:27:28Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-1i0","title":"Dev-VM aufsetzen: Claude Code + TMUX (VLAN 60)","description":"Persistente Dev-VM auf Proxmox VLAN 60 für manuelle Claude Code Sessions.\n\n## Zweck\nMacBook-unabhängige Claude Code Sessions. SSH + TMUX = Session überlebt MacBook-Sleep.\nGastown-Workflow: tmux-basierte Mayor/Crew-Sessions wie in der Community üblich.\n\n## Komponenten\n- Claude Code (aktuell installiert, Plugin auto-updated)\n- TMUX für persistente Sessions\n- claude-mem Plugin → Worker auf Services-VM (CLAUDE_MEM_WORKER_HOST)\n- bd → DOLT auf Services-VM (bd dolt set host → Services-VM)\n- NetBird für SSH-Zugang von außen\n\n## Workflow\n1. SSH in Dev-VM\n2. tmux attach (oder neue Session)\n3. Claude Code startet, claude-mem Worker auf Services-VM läuft bereits\n4. bd ready zeigt gleichen Stand wie MacBook\n\n## Update-Strategie\n- Claude Code: normales npm/package update\n- claude-mem: Plugin-Verzeichnis ist git repo → Cron: git pull (unabhängig von Claude Code)\n  → Wenn Claude Code irgendwann deinstalliert wird: claude-mem Worker als separater\n    systemd-Service auf Services-VM umziehen\n\n## Acceptance Criteria\n- [ ] VM läuft auf Proxmox VLAN 60\n- [ ] Claude Code + TMUX installiert\n- [ ] SSH via NetBird funktioniert\n- [ ] claude-mem zeigt Memory von MacBook-Sessions\n- [ ] bd ready zeigt gleichen Stand wie MacBook","notes":"Hokora (VM 201) sauber von null aufgesetzt. IP 192.168.60.51 (statisch), VLAN 60.\n\nIaC Scripts:\n- vm/hokora/setup-vm.sh — VM-Erstellung auf Proxmox (cloud-init)\n- vm/hokora/deploy.sh — Claude Code Config via SSH (settings, plugins, claude-mem, beads)\n\nInstalliert: Claude Code v2.1.52, Node 22, Docker 29, tmux 3.4, User malte.\nclaude-mem zeigt auf Services-VM (192.168.60.30:37777).\nbeads Dolt zeigt auf Services-VM (192.168.60.30:3307).\nPlugin-Marketplaces registriert (beads, claude-mem, claude-plugins-official).\n\nhome-infra Skill aktualisiert: VM/LXC-Tabellen, CC-VM-Setup-Anleitung, No-Clone-Regel.\nMemory aktualisiert: Prinzip 7 (niemals klonen).","status":"in_progress","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T01:36:51Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:49Z","dependencies":[{"issue_id":"claude-1i0","depends_on_id":"claude-4r0","type":"blocks","created_at":"2026-02-24T02:37:25Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-1rh","title":"[LEARNING] LXC 1Password injection pattern: op CLI + service account + .env.tpl + start.sh with op run","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T05:20:08Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:50Z","closed_at":"2026-02-22T06:00:22Z","close_reason":"Materialisiert: project CLAUDE.md 'LXC Secret Management' section","labels":["learning","learning:architecture","scope:project"]}
{"id":"claude-1tx","title":"Nextcloud auf Elysium deployen (Datei-Sync)","description":"## Ziel\nSelf-hosted iCloud Drive / Google Drive Alternative. Datei-Sync zwischen Mac, iPhone, iPad.\n\n## Schritte\n1. LXC fuer Nextcloud erstellen (Docker: Nextcloud + MariaDB/PostgreSQL + Redis)\n2. Storage auf NVMe (primaer), Backup auf DAS\n3. Desktop-Client auf Mac installieren (Sync-Ordner)\n4. iOS App konfigurieren\n5. Externer Zugriff via Caddy Reverse Proxy + Domain + Let's Encrypt\n   ODER Tailscale (einfacher, kein Port-Forwarding)\n6. Backup-Job: Nextcloud-Daten auf DAS\n7. Cloud-Tarif (iCloud/Google) als Off-Site-Backup runterstufen\n\n## Ueberlegungen\n- Verschluesselung: Nextcloud Server-Side Encryption oder E2E\n- Collabora/OnlyOffice fuer Dokumenten-Bearbeitung (optional)\n- CalDAV/CardDAV: Kalender/Kontakte-Sync moeglich (siehe Kalender-Track)\n\n## Akzeptanzkriterien\n- [ ] Nextcloud Web-UI erreichbar\n- [ ] Mac Desktop-Sync funktioniert\n- [ ] iOS App Datei-Zugriff funktioniert\n- [ ] Externer Zugriff (VPN oder Reverse Proxy) funktioniert","notes":"2026-02-16: Nextcloud Use-Case hinterfragt. Mit Immich (Fotos), Paperless-ngx (Dokumente), Obsidian (Notizen), Git (Code) und Fastmail (Kalender/Mail) bleiben kaum Dateien uebrig die Nextcloud-Sync brauchen. Auf P4 herabgestuft -- nur deployen wenn konkreter Bedarf entsteht (z.B. CalDAV-Konsolidierung, iCloud-Drive-Ersatz, oder Datei-Sharing mit Familie).","status":"open","priority":4,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T08:30:20Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:51Z","labels":["epic:claude-k6i"]}
{"id":"claude-1xz","title":"Ollama: Use Case klären und Modell pullen","description":"## Offene Fragen\n- Welcher konkrete Use Case? Lokale Embeddings, Privacy-Tasks, Paperless-Integration?\n- Welches Modell? Qwen 2.5 72B (Coding), Mistral Small 24B (schnell), oder kleines Embedding-Modell?\n- Lohnt sich 96GB RAM Reservation oder besser reduzieren?\n\n## Mögliche Use Cases\n1. Lokale Embeddings für Semantic Search (Paperless, Immich)\n2. Privacy-sensitive Dokument-Analyse\n3. Paperless-ngx KI-Tagging\n4. Coding-Assistent als Fallback (offline)\n5. OpenClaw Agent-Backend (aber Kimi K2 via OpenRouter vermutlich besser)\n\n## Akzeptanzkriterien\n- [ ] Use Case definiert\n- [ ] Modell ausgewählt und gepullt\n- [ ] RAM-Allokation angepasst falls nötig\n- [ ] Integration mit mindestens einem Service getestet","status":"open","priority":4,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:03:42Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:52Z"}
{"id":"claude-21q","title":"[LEARNING] NetBird reverse proxy: use dedicated domain (sussdorff.org) not wildcard on primary business domain","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T18:01:21Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:53Z","labels":["learning"]}
{"id":"claude-22f","title":"claude-mem: Lokale Observations nach Remote-Server übertragen (Offline-Fallback)","description":"Wenn das MacBook unterwegs ist (kein VLAN 60 / kein NetBird), startet der claude-mem Hook einen lokalen Worker der in ~/.claude-mem/claude-mem.db schreibt. Nach Rückkehr ins Heimnetz müssen neue lokale Observations auf den zentralen Server (192.168.60.30:37777) übertragen werden.\n\n## Ansatz\nKEIN automatischer Sync/Merge. Stattdessen manuelles Vorgehen:\n\n1. Lokale DB abfragen: welche Observations sind neuer als der letzte bekannte Server-Stand?\n2. Diese per API (`POST /api/memory/save` oder direktem SQLite-Insert) auf dem Server einfügen\n3. Lokale DB danach nicht löschen (bleibt als Backup)\n\n## Umsetzung\n- Script `lxc/services/sync-claude-mem.sh` oder Python-Script\n- Vergleicht `created_at_epoch` zwischen lokal und remote\n- Zeigt Diff an (dry-run), überträgt per `--apply`\n\n## Trigger\n- Manuell nach Rückkehr ins Heimnetz\n- Oder als Check in Session-Start-Hook: \"lokale Einträge vorhanden die nicht auf Server sind?\"\n\n## Wird obsolet durch\n- NetBird VPN (claude-bgf) — dann ist der Server immer erreichbar","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T02:38:53Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z"}
{"id":"claude-32d","title":"erp4projects Server (Hetzner CX22) nach Elysium migrieren","description":"Docker-Stack vom erp4projects Server (116.202.111.75, Hetzner CX22) nach Elysium Proxmox umziehen.\n\n## Was läuft (Docker Compose)\n- naviserver (cognovis ERP/Intranet, OpenACS-basiert) ~700 MB RAM\n- postgres (DB für Intranet) ~80 MB\n- libreoffice (Dokumenten-Konvertierung) ~140 MB\n- webix (Frontend) ~7 MB\n- postfix (Mail-Versand) ~25 MB\n- nginx auf Host als Reverse Proxy\n\n## Domains die auf den Server zeigen\n- intranet.cognovis.de (aktiv genutzt!)\n- bbdc.erp4projects.com\n- registration.berlinbalboaweekend.de\n- p4a.cognovis.de (inaktiv)\n- bbw.cognovis.de (inaktiv)\n\n## Zusätzlich auf Host\n- PostgreSQL 9.6 (nativ installiert, prüfen ob noch genutzt)\n- nginx als Reverse Proxy mit SSL\n- node_exporter (Prometheus Monitoring)\n\n## Ressourcen\n- Aktuell: CX22 (4 GB RAM, 40 GB Disk) - ~5 EUR/Monat, 6 Jahre alt\n- Real benötigt: ~2 GB RAM\n- Disk: 20 GB belegt\n\n## Akzeptanzkriterien\n- [ ] LXC oder VM auf Elysium mit Docker\n- [ ] docker-compose Stack migriert\n- [ ] PostgreSQL-Daten migriert\n- [ ] SSL-Zertifikate neu via Let's Encrypt\n- [ ] intranet.cognovis.de erreichbar (Port-Forwarding nötig!)\n- [ ] Server kann abgeschaltet werden\n\n## Hinweise\n- Server ist 6 Jahre alt, Software veraltet (Postgres 9.6!)\n- Kosten: ~5 EUR/Monat (~60 EUR/Jahr)\n- Priorität niedriger als Ignis/OpenClaw, da günstiger\n- Intranet braucht externe Erreichbarkeit → Reverse Proxy + Port-Forwarding","status":"open","priority":3,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-15T13:12:15Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:54Z","work_type":"mutex"}
{"id":"claude-3bi","title":"Deploy Plex Media Server (Music + Video, ersetzt Jellyfin + Navidrome)","description":"## Ziel\nPlex Media Server als zentrale Medien-Lösung deployen. Ersetzt Jellyfin (LXC 106) und macht Navidrome überflüssig.\n\n## Warum Plex statt Jellyfin + Navidrome\n- Malte hat Plex Pass Lifetime → Hardware-Transcoding, PlexAmp, Offline-Sync\n- Native Apple TV App (statt Swiftfin 3rd-party)\n- PlexAmp für Musik mit AirPlay → HomePod-Streaming\n- Ein Server für Video + Music statt zwei separate Dienste\n- Bessere Apple-Ökosystem-Integration (iOS, macOS, tvOS)\n\n## Deployment\n- LXC Container auf VLAN 60 (LXC 106 wiederverwenden oder neuer Container)\n- Docker-based (linuxserver/plex oder official plexinc/pms-docker)\n- Hardware Transcoding (VAAPI passthrough)\n- Caddy reverse proxy: plex.sussdorff.de (oder Port 32400 direkt)\n- Storage: /mnt/media/ für Video-Bibliotheken, /mnt/music/ für Musik\n\n## Bibliotheken\n- **Music** → Musik von Backup-Platte (jetzt auf PRO-G40/Music/)\n- **Kurse** → Kursvideos (~75 GB von Solaris)\n- **Persönlich** → Persönliche Videos (~80 GB)\n- **TV** → Serien (32 GB)\n- **Filme** → Einzelne Filme\n\n## Migration von Jellyfin\n- Medien-Dateien übernehmen (gleiche Ordnerstruktur)\n- Jellyfin LXC 106 nach erfolgreicher Plex-Migration dekommissionieren\n- Deploy-Scripts unter lxc/jellyfin/ entfernen oder archivieren\n\n## Akzeptanzkriterien\n- [ ] Plex Server deployed und erreichbar\n- [ ] Musik-Bibliothek eingerichtet, PlexAmp funktioniert\n- [ ] AirPlay zu HomePods getestet\n- [ ] Video-Bibliotheken migriert von Jellyfin\n- [ ] Apple TV App verbunden und funktional\n- [ ] Hardware Transcoding verifiziert\n- [ ] Jellyfin LXC 106 dekommissioniert\n- [ ] Deploy-Scripts im Repo aktualisiert","notes":"Plex deployed on LXC 106, claimed with token. Jellyfin stopped and volumes removed. Monitoring updated (prometheus labels + blackbox probe). Hostname changed to plex. arr-stack (Sonarr/Radarr/Prowlarr/SABnzbd) mitgenommen.\nErledigt: Plex deployed+claimed, Monitoring aktualisiert, Jellyfin dekommissioniert, Deploy-Scripts im Repo. Offen: Musik-Bibliothek einrichten (Dateien noch nicht auf Server), PlexAmp/AirPlay/Apple TV manuell testen, Hardware Transcoding in Plex UI aktivieren (Settings \u003e Transcoder \u003e VAAPI), Video-Bibliotheken migrieren (braucht claude-9p1).\nMedien-Transfer abgeschlossen: 196 GB auf /mnt/media (500G LVM thin volume, bind-mount in LXC 106). Music 39GB (74 Künstler), Courses 103GB (Dance/Tischlern/Silva), TV 33GB (DOTA/Mushoku Tensei), Personal 24GB (Home Videos/Filmchen/Queen Mary). Offen: Hardware Transcoding in Plex UI aktivieren, PlexAmp/AirPlay/Apple TV manuell testen.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T11:08:42Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","closed_at":"2026-02-17T19:09:08Z","close_reason":"Plex deployed auf LXC 106 mit 500G LVM thin volume, 196GB Medien migriert (67 Künstler, 690 Kursvideos, 243 persönliche Videos, 2 TV-Serien). Jellyfin dekommissioniert, Monitoring aktualisiert. Hardware Transcoding + PlexAmp/AirPlay manuell zu testen."}
{"id":"claude-3l4","title":"Libation Docker auf LXC 110 (Audiobookshelf) für automatischen Audible-Import","description":"## Ziel\nLibation als Docker-Container auf LXC 110 neben Audiobookshelf betreiben. Neue Audible-Käufe werden automatisch heruntergeladen und von Audiobookshelf erkannt.\n\n## Setup\n- Docker Image: rmcrackan/libation:latest\n- Shared Volume: Libation schreibt direkt ins Audiobookshelf audiobooks-Verzeichnis\n- SLEEP_TIME=1h für stündlichen Scan\n- AccountsSettings.json + Settings.json vom Mac übertragen (Audible Auth)\n\n## Schritte\n1. Audiobookshelf Docker-Compose auf LXC 110 inspizieren (Volume-Pfade)\n2. Libation Config vom Mac exportieren (~/.config/Libation/ oder aus Libation.app)\n3. Libation Service in docker-compose.yml hinzufügen mit shared audiobooks Volume\n4. SLEEP_TIME=1h setzen\n5. Container starten und Test-Scan verifizieren\n6. Deploy-Script erstellen/aktualisieren\n\n## Akzeptanzkriterien\n- [ ] Libation Container läuft auf LXC 110\n- [ ] Shared Volume mit Audiobookshelf (keine Duplikate)\n- [ ] Automatischer Scan alle 1h\n- [ ] Audiobookshelf erkennt neue Downloads automatisch\n- [ ] Deploy-Script dokumentiert","notes":"Deployed successfully. 427 Audible-Bücher erkannt, Download läuft. Permission-Fix für User 1001 im deploy.sh eingebaut. Custom entrypoint patcht liberate.sh um --pdf Pass hinzuzufügen. Symlink-Warning (harmlos) bei DB-Restart.\nLibation läuft: 94/427 Bücher nach ~50 min. 14 Decrypt-Failures bei älteren Büchern (werden trotzdem heruntergeladen, aber bleiben möglicherweise verschlüsselt). PDF-Download funktioniert (DownloadPdf entries in Logs). Disk auf 204 GB vergrößert. SSH-Key für LXC 110 eingerichtet (ProxyJump über elysium). rsync auf LXC 110 installiert.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T10:40:54Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:56Z","closed_at":"2026-02-17T12:31:05Z","close_reason":"Libation Docker läuft auf LXC 110, shared audiobooks Volume mit Audiobookshelf, stündlicher Scan, PDF-Download via custom Entrypoint. 95 Bücher im ersten Durchlauf, deploy.sh mit Permission-Fix."}
{"id":"claude-3rm","title":"[LEARNING] Fastmail domain setup: pre-set MX/DKIM/SPF/DMARC in Hetzner DNS before adding domain in Fastmail dashboard","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T18:01:18Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:57Z","labels":["learning"]}
{"id":"claude-3wc","title":"[LEARNING] NetBird custom domain verification requires wildcard CNAME, not A-records","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T18:01:07Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:58Z","labels":["learning"]}
{"id":"claude-422","title":"Immich auf Elysium deployen (Foto-Management)","description":"## Ziel\nSelf-hosted Google Photos Alternative auf Elysium. Automatischer iPhone/iPad Foto-Upload.\nDomain: immich.sussdorff.de (oder photos.sussdorff.de)\n\n## Schritte\n\n### Deployment\n1. LXC fuer Immich erstellen (Docker-basiert, Privileged fuer GPU-Zugriff)\n2. Immich Stack deployen (Server, ML, Redis, PostgreSQL)\n3. Storage: Fotos auf NVMe (schnell), Backup auf DAS\n4. DNS: A-Record fuer immich.sussdorff.de auf Caddy/Elysium zeigen (Hetzner DNS)\n5. Caddy Reverse Proxy: TLS + Proxy zu Immich LXC\n6. Optional: 890M iGPU Passthrough fuer ML-Beschleunigung\n\n### Foto-Migration\n7. Google Photos Export via Google Takeout\n8. iCloud Photos Export (alle Fotos laden + immich-cli bulk import)\n9. Eigene Fotos: Import als primaere Library\n10. Geteilte/freigegebene Fotos: Import als Shared Library oder Partner-Sharing\n11. Deduplizierung nach Import pruefen\n\n### Mobile Setup\n12. iOS Immich App installieren\n13. Auto-Upload konfigurieren (WLAN oder auch mobil)\n14. iCloud Foto-Sync deaktivieren (nach erfolgreicher Migration + Verify)\n\n### Backup\n15. DAS-Backup: Immich-Daten (Fotos + DB) auf /mnt/das/archive\n16. Off-Site: Verschluesseltes Backup via Restic/Rclone auf Google Drive 2TB\n\n## Ressourcen\n- RAM: ~3-4 GB (ML Engine)\n- Disk: NVMe primaer, DAS fuer Backup\n- Optional: 890M iGPU fuer ML\n\n## Domain-Setup\n- DNS Provider: Hetzner (sussdorff.de)\n- Reverse Proxy: Caddy auf LXC 102 (192.168.60.5)\n- TLS: Let's Encrypt via Caddy (automatisch)\n\n## Akzeptanzkriterien\n- [ ] Immich Web-UI erreichbar unter immich.sussdorff.de\n- [ ] iOS Auto-Upload funktioniert\n- [ ] Fotos durchsuchbar (Gesichtserkennung, Orte, Objekte)\n- [ ] Google Photos migriert (eigene + geteilte)\n- [ ] iCloud Photos migriert (eigene + geteilte)\n- [ ] Backup auf DAS eingerichtet\n- [ ] Off-Site Backup auf Google Drive verschluesselt","notes":"LXC setup-skripte + docker-compose (Immich Server+ML+Redis+PostgreSQL) + .env.example + deploy.sh erstellt (lxc/immich/). Caddy-Entry für photos.sussdorff.de. Nächster Schritt: setup-lxc.sh auf Proxmox, .env anlegen, deploy.sh, dann Fotos migrieren.\nDeployed und verifiziert. 4/4 Container healthy (Server, ML, Redis, PostgreSQL). Extern erreichbar unter https://photos.sussdorff.de (HTTP 200). Placeholder-Passwort in .env muss noch geändert werden.\nWeb-Setup abgeschlossen. Admin: malte@sussdorff.de. Dark Theme. v2.5.6 läuft. Fotos noch nicht migriert.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T08:30:08Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:58Z","closed_at":"2026-02-17T02:50:30Z","close_reason":"LXC 107 deployed, Immich v2.5.6 läuft mit ML+Redis+PostgreSQL. Admin: malte@sussdorff.de. Fotos noch nicht migriert (separater Bead).","labels":["epic:claude-k6i"]}
{"id":"claude-4eg","title":"Inter-VLAN Routing: VLAN 60 → VLAN 2 (HA API)","description":"VLAN 60 (Services, 192.168.60.0/24) kann nicht auf VLAN 2 (Default, 192.168.2.0/24) zugreifen. Shikigami VM (192.168.60.63) kann HA API (192.168.2.5:8123) nicht erreichen.\n\n## Problem\n- ping 192.168.2.5 von shikigami → 100% packet loss\n- curl http://192.168.2.5:8123/api/ → timeout\n\n## Lösung\nFirewall-Regel auf UniFi Gateway erstellen:\n- Allow VLAN 60 → 192.168.2.5:8123 (HA API)\n- Allow VLAN 60 → 192.168.2.5:22 (HA SSH, optional)\n\n## Acceptance Criteria\n- [ ] ping 192.168.2.5 von shikigami erfolgreich\n- [ ] curl http://192.168.2.5:8123/api/ gibt HTTP 401 zurück (auth required)","status":"open","priority":1,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T01:37:11Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:16:59Z"}
{"id":"claude-4gy","title":"Home Assistant Blackbox Probe: VLAN 60 Erreichbarkeit herstellen","description":"## Hintergrund\nHA VM (100) ist nur auf vmbr0 (192.168.2.100:8123), nicht auf VLAN 60. \nBlackbox Exporter in LXC 113 kann HA daher nicht proben.\n\n## Optionen\n1. Zweites NIC an HA VM auf vmbr1/VLAN 60 hinzufügen\n2. Reverse Proxy (LXC 102) als Probe-Target nutzen (prüft indirekt)\n3. HA über Proxmox Host routen (ip route auf LXC 113)\n\n## Akzeptanzkriterien\n- [ ] HA erreichbar von LXC 113 (VLAN 60)\n- [ ] Blackbox Probe in prometheus.yml aktiviert\n- [ ] probe_success Metrik für HA verfügbar","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:56:24Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:00Z"}
{"id":"claude-4r0","title":"Services-VM aufsetzen: DOLT + claude-mem + Langfuse (VLAN 60)","description":"Zentrale Services-VM auf Proxmox VLAN 60 für alle shared Infrastructure Services.\n\n## Zweck\nZentrale, stabile VM für alle Services die von mehreren Clients genutzt werden.\nVLAN 60 = über NetBird von außen erreichbar, von MacBook + Dev-VM + (später) Shikigami.\n\n## Komponenten\n1. **DOLT Server** (systemd-Service, Port 3307)\n   - Zentrale beads-Datenbank für alle Agents\n   - bd dolt set host → diese VM (in allen Repos/Clients)\n2. **claude-mem Worker** (Port 37777)\n   - Zentral damit MacBook + Dev-VM auf dasselbe Memory zugreifen\n   - Auto-Update via Cron: git pull in Plugin-Verzeichnis (kein npm, nur git)\n   - CLAUDE_MEM_WORKER_HOST → diese VM in allen Clients\n3. **Langfuse** (konsolidiert aus shiki-2dq)\n   - Tracing für alle Agents zentral\n\n## Clients die sich verbinden\n- MacBook Claude Code\n- Dev-VM (Claude Code + TMUX)\n- Shikigami-Bot (anderes VLAN, Firewall-Regel Outbound nur zu dieser VM)\n\n## Security\n- VLAN 60, über NetBird erreichbar\n- Kein direkter Zugriff auf Shikigami-Bot-VLAN\n- Monitoring/Observability VM = erhöhte Security-Aufmerksamkeit\n\n## Acceptance Criteria\n- [ ] VM läuft auf Proxmox VLAN 60\n- [ ] DOLT Server systemd-Service, bd dolt test grün von MacBook\n- [ ] claude-mem Worker erreichbar, Memory sync MacBook ↔ Dev-VM\n- [ ] Langfuse erreichbar (konsolidiert mit shiki-2dq)","status":"closed","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T01:36:32Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:01Z","closed_at":"2026-02-24T02:00:52Z","close_reason":"LXC 116 deployed: Dolt:3307, claude-mem:37777, Langfuse:3000 — alle erreichbar, MacBook connected"}
{"id":"claude-4sz","title":"[DECISION] Backup-Architektur: DAS an Proxmox + Hetzner Storage Box statt dediziertes NAS","description":"## Entscheidung\n\nDAS direkt an Proxmox belassen + Hetzner Storage Box für Offsite-Backup. Kein dediziertes NAS auf MBP 2018.\n\n## Begründung\n\n### Option A: MBP 2018 als TrueNAS-NAS (VERWORFEN)\n- ~80 EUR/Jahr Stromkosten (30W idle)\n- T2-Chip Treiber-Probleme unter Linux (WiFi, Boot, Thermal)\n- Wartungsaufwand für separates OS\n- Akku-Degradation bei 24/7 Betrieb\n- Kein ECC-RAM (für Home-Backup akzeptabel, aber suboptimal)\n- Hardware: 16GB RAM, i5/i7 quad-core, USB 3.1 Gen 1 (5 Gbps)\n\n### Option B: DAS an Proxmox + Hetzner Storage Box (GEWÄHLT)\n**Tier 1+2: DAS an Proxmox**\n- Kein extra Stromverbrauch\n- ZFS-Pool direkt auf dem Host\n- Nutzbar für Backups UND andere Dinge (Media, Bulk-Daten, SMB/NFS Shares)\n- Einfach: kein extra OS, kein extra Netzwerk\n\n**Tier 3: Hetzner Storage Box**\n- BX11 = 1TB für 3,81 EUR/Monat (~46 EUR/Jahr)\n- BX21 = 5TB für 7,14 EUR/Monat (~86 EUR/Jahr)\n- PBS kann nativ über SSH/SFTP dahin sichern\n- Echtes Offsite ohne Hardware-Wartung\n- Vergleichbare Jahreskosten wie MBP-Strom, aber zero Maintenance\n\n### Kostenvergleich\n| Option | Jährlich | Wartung |\n|--------|----------|---------|\n| MBP TrueNAS | ~80 EUR Strom | Hoch (OS, Treiber, Thermal) |\n| Hetzner BX21 5TB | ~86 EUR | Keine |\n\n### MBP 2018 Empfehlung\nVerkaufen — Erlös deckt ~2-3 Jahre Hetzner Storage Box.\n\n## 3-2-1 Backup Architektur\n1. Proxmox lokale Snapshots (Tier 1)\n2. DAS am Proxmox-Host via PBS (Tier 2 — lokal, schnell)\n3. Hetzner Storage Box via PBS Remote (Tier 3 — Offsite)\n\n## Nächste Schritte\n- [ ] DAS-Gehäuse mit Platten bestücken und ZFS-Pool einrichten (claude-wlo)\n- [ ] PBS auf DAS konfigurieren (claude-mzj)\n- [ ] Hetzner Storage Box bestellen und PBS Remote Datastore einrichten (claude-usn)\n- [ ] MBP 2018 verkaufen/verschenken","notes":"Entscheidung getroffen: DAS bleibt an Proxmox, Hetzner Storage Box für Offsite. MBP 2018 wird nicht als NAS genutzt.","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T08:48:19Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","closed_at":"2026-02-22T08:53:45Z","close_reason":"Decision: DAS an Proxmox + Hetzner Storage Box. MBP 2018 als NAS verworfen (Strom ≈ Hetzner-Kosten, aber mehr Wartung)","labels":["decision","epic:claude-k6i"]}
{"id":"claude-59a","title":"[EPIC] Unified Development Workflow: Superpowers + Charly-Server + Gas Town Integration","description":"Einheitlichen, allgemeingültigen Entwicklungsworkflow aufbauen, der die besten Konzepte aus Superpowers (TDD, Verification, Subagent Review), dem ausgereiften Charly-Server Workflow (/ticket → /revise → /impl → /mr-prepare), und Gas Town (parallele Agent-Orchestrierung) kombiniert.\n\n## Motivation\n- Charly-Server hat einen 4.5/5 reifen Workflow, aber er ist projektspezifisch (PowerShell/Shell)\n- Superpowers bringt TDD-Enforcement, Verification-Disziplin und Subagent-Patterns\n- Gas Town bringt parallele Orchestrierung mit Mayor/Polecat-Modell\n- BMAD bringt Document Sharding und Scale-Adaptive Planning als Konzepte\n- All das muss in einen einheitlichen, wiederverwendbaren Workflow münden\n\n## Phasen\n1. Charly-Server Workflow extrahieren und allgemeingültig machen\n2. Superpowers-Konzepte selektiv einbauen (TDD, Verification, Subagent Review)\n3. BMAD-Konzepte für Greenfield-Phasen integrieren (Document Sharding, Scale-Adaptive)\n4. Gas Town Integration: Mayor kennt den Workflow, Polecats nutzen ihn\n5. Multi-Framework Support: Mayor kann zwischen Workflow-Varianten wählen\n\n## Acceptance Criteria\n- [ ] Allgemeingültiger Workflow als Standards/Skills im claude/ Repo\n- [ ] TDD-Enforcement als optionaler aber empfohlener Gate\n- [ ] Verification-before-completion als Standard\n- [ ] Gas Town Mayor-Konfiguration die den Workflow kennt\n- [ ] Dokumentation wie der Workflow mit Gas Town Polecats funktioniert\n- [ ] Optional: BMAD-Methodik als alternatives Framework wählbar","notes":"## Research-Ergebnisse (2026-02-26)\n\n### Superpowers (obra/superpowers)\n- 42k+ Stars, Anthropic Plugin Marketplace\n- 14 composable Skills, Session-Start Hook Injection\n- Kern: TDD Iron Law, Verification-before-completion, Subagent-Driven Dev\n- 7-Phasen: Brainstorm → Worktree → Plan → Execute → TDD → Review → DoD\n- Nutzt exakt gleiche Primitives wie unser Setup (Skills, Hooks, Slash Commands)\n\n### Charly-Server Workflow (Bestand)\n- 4.5/5 Reifegrad: /ticket → /revise → /impl → /mr-prepare\n- 19 Commands, 9 Agents, 5 Skill Sets\n- Self-healing Pipelines, Integration Tests auf echten Systemen\n- Fehlt: TDD-first, Verification, Mid-Implementation Checkpoints\n\n### BMAD V6 (Breakthrough Method for Agile AI-Driven Development)\n- 38k Stars, v6.0.3 (23. Feb 2026)\n- 19+ Agent-Personas, YAML-Workflows, Document Sharding\n- Scale-Adaptive: Level 0 (Bug) bis Level 4 (Enterprise)\n- Für Greenfield gut, für bestehende Codebases eher Konzepte übernehmen\n- BMAD-Agents = Prompt-Templates, KEINE echten parallelen Agenten\n\n### Gas Town v0.8.0 (Steve Yegge)\n- Go-basierter Multi-Agent Workspace Manager, NICHT CrewAI\n- Mayor → Beads → Convoys → Polecats (Worker in Worktrees) → Refinery (Merge)\n- v0.5→v0.7: SQLite→Dolt, Convoy Ownership, Multi-Runtime, Resilience\n- Komplementär zu Relay: Gas Town = Dev-Time, Relay = Runtime Orchestrierung\n- Community: gastownhall.ai, Discord, GitHub Discussions\n\n### Pyramide\nLevel 1: CLAUDE.md + Skills + Hooks + Beads (jetzt)\nLevel 2: + Superpowers Konzepte (TDD, Verification, Subagent Review)\nLevel 3: + BMAD Konzepte (Document Sharding, Scale-Adaptive)\nLevel 4: Gas Town (parallele Agent-Flotten)\n## Projekt-Zuordnung (2026-02-26)\n- Gas Town spezifische Beads nach gastown-vm verschoben:\n  - gastown-2fh: [RESEARCH] Gas Town Workflow-Integration\n  - gastown-pxc: Multi-Framework Support\n- Im claude-Projekt verbleiben:\n  - claude-pa3: Charly-Server Workflow extrahieren\n  - claude-hn7: Superpowers-Konzepte integrieren\n  - claude-o6f: BMAD-Konzepte übernehmen","status":"open","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T01:56:23Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","labels":["decision"]}
{"id":"claude-5rk","title":"Blackbox Exporter: HTTP Health Checks für Services","description":"## Anforderungen\nBlackbox Exporter konfigurieren für HTTP Health Checks aller kritischen Services.\n\n## Targets:\n- Audiobookshelf (LXC 110, Port 13378)\n- Mailpiler (LXC 111)\n- Pi-hole (LXC, Admin UI)\n- Home Assistant (VM, Port 8123)\n- Weitere Services nach Bedarf (Immich, Jellyfin, Paperless etc.)\n\n## Akzeptanzkriterien\n- [ ] Blackbox Exporter Module config (http_2xx probe)\n- [ ] Prometheus scrape config für alle HTTP Targets\n- [ ] probe_success Metrik verfügbar für jeden Service\n- [ ] Alert-Rule: ServiceDown wenn probe_success == 0 für \u003e2min","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:30:47Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:04Z","closed_at":"2026-02-17T14:44:58Z","close_reason":"Blackbox HTTP Probes für ABS, Piler, Pi-hole aktiv (HA auskommentiert, nicht auf VLAN 60)","dependencies":[{"issue_id":"claude-5rk","depends_on_id":"claude-tlf","type":"blocks","created_at":"2026-02-17T15:31:03Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-5z1","title":"Grafana Dashboards visuell verifizieren via agent-browser","description":"## Hintergrund\n4 Grafana Dashboards wurden provisioniert, aber noch nicht visuell getestet.\nDie Dashboards müssen im Browser geöffnet und auf korrekte Darstellung geprüft werden.\n\n## Zu prüfen\n1. **Elysium Status** (http://192.168.60.23:3000/d/claude-status)\n   - Service Status Stat Panels zeigen grün/rot\n   - Disk/Memory Gauges haben korrekte Werte\n   - 7d Trend Graph zeigt Daten\n2. **Node Detail** (http://192.168.60.23:3000/d/node-detail)\n   - Instance-Dropdown funktioniert\n   - CPU/Memory/Disk/Network Panels zeigen Daten\n3. **Proxmox Host** (http://192.168.60.23:3000/d/proxmox-host)\n   - Host-Metriken korrekt (CPU Cores, RAM, Storage)\n   - Load Average, Disk I/O, Network Bridges\n4. **Docker Containers** (http://192.168.60.23:3000/d/docker-containers)\n   - Instance + Container Dropdowns funktionieren\n   - CPU/Memory/Network pro Container sichtbar\n\n## Vorgehen\n- agent-browser mit Grafana-Profil nutzen (ggf. Profil anlegen mit Login)\n- Screenshots der 4 Dashboards machen\n- Panels ohne Daten (\"No data\") identifizieren und dokumentieren\n\n## Akzeptanzkriterien\n- [ ] Alle 4 Dashboards im Browser geöffnet und geprüft\n- [ ] Panels mit fehlenden Daten oder Fehlern identifiziert\n- [ ] Screenshots als Nachweis\n- [ ] Ggf. Fixes für kaputte Panels durchgeführt","notes":"Fixes durchgeführt:\n1. claude-status.json: job=blackbox→blackbox_http, IP-Adressen→job-basierte Selektoren, instance→service Label\n2. proxmox-host.json: Hostname-Panel Query von node_cpu_seconds_total→node_uname_info, textMode→name\nHA Service Status zeigt erwartungsgemäß 'No data' (Blackbox Probe auskommentiert, HA nur auf vmbr0)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T15:08:29Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:32Z","closed_at":"2026-02-17T15:21:11Z","close_reason":"Alle 4 Dashboards visuell verifiziert, 2 Bugs gefixt (claude-status: falsche Job/Instance-Selektoren, proxmox-host: Hostname-Panel Query). HA Panel 'No data' ist expected (Probe auskommentiert)."}
{"id":"claude-61k","title":"piler-cli: stats — Archiv-Statistiken + Import-Status","description":"'piler stats' zeigt: Gesamtzahl Mails, Archiv-Größe, Import-Jobs (Status, Progress, Fehler). Liest aus MySQL metadata + import Tabellen. Acceptance: Gibt sinnvolle Übersicht über Archiv-Zustand.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:27:15Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:05Z","closed_at":"2026-02-18T04:31:46Z","close_reason":"Im Scaffold-Task mitimplementiert und gegen Live-Instanz getestet","labels":["epic:claude-ecz"],"dependencies":[{"issue_id":"claude-61k","depends_on_id":"claude-8oh","type":"blocks","created_at":"2026-02-18T05:27:28Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-66o","title":"Proxmox Monitoring: Prometheus + Grafana + AlertManager Stack","description":"## Hintergrund\nLXC 110 (Audiobookshelf) lief auf 100% Disk ohne jegliches Alerting. Python-Scripts, pct push, Docker — alles versagte lautlos. Wir brauchen proaktives Monitoring mit historischen Metriken für Root-Cause-Analyse (besonders bei Agent-Runs).\n\n## Architektur-Entscheidung\nPrometheus-Stack statt Uptime Kuma + Cron-Script:\n- Ein System statt zwei halbe\n- Historische Metriken von Tag 1\n- AlertManager mit Dead Man's Switch\n- Grafana für Status-Dashboard (Stat Panels als grün/rot Kacheln)\n- Grafana bereits bekannt (läuft in HA VM für HA-Dashboards)\n\n## Komponenten\n### Neuer LXC (Monitoring):\n- Prometheus (Scraper + TSDB)\n- AlertManager (Routing → ntfy)\n- Grafana (Dashboards)\n- Blackbox Exporter (HTTP Health Checks)\n\n### Auf jedem LXC:\n- node_exporter (ein Binary, ~10MB RAM)\n\n### Auf Proxmox Host:\n- node_exporter\n\n## Akzeptanzkriterien\n- [ ] Monitoring-LXC deployed mit Prometheus + AlertManager + Grafana + Blackbox Exporter\n- [ ] node_exporter auf allen LXC-Containern + Proxmox Host\n- [ ] Disk-Alert bei \u003e80% (warn) und \u003e90% (critical) für alle LXCs\n- [ ] Memory-Alert bei \u003e85% (warn) und \u003e95% (critical) für alle LXCs\n- [ ] HTTP Health Checks für ABS, Piler, Pi-hole, HA via Blackbox Exporter\n- [ ] Notifications via ntfy konfiguriert\n- [ ] Grafana Status-Dashboard (Stat Panels: grün/rot pro Service + Disk/Memory)\n- [ ] Deploy-Script vorhanden (IaC)","notes":"Architektur-Entscheidung: Prometheus-Stack statt Uptime Kuma + Cron. Gründe: (1) Ein System statt zwei, (2) historische Metriken für Agent-Run Root-Cause-Analyse, (3) Grafana bereits bekannt aus HA. Separates Grafana auf eigenem LXC, unabhängig von HA-Grafana.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:07:16Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:06Z","closed_at":"2026-02-17T14:45:49Z","close_reason":"Prometheus-Stack deployed: LXC 113, 18/18 Targets UP, 6 Alert-Regeln, ntfy Notifications, Grafana Dashboard. HA Probe auskommentiert (nicht auf VLAN 60).","labels":["decision"]}
{"id":"claude-6wa","title":"[EPIC] Paperless-ngx: Deploy, ScanSnap-Anbindung und Dokumenten-Import","description":"## Vision\nPaperless-ngx als zentrales DMS auf Elysium. ScanSnap iX1600 scannt direkt per WiFi/SMB in den consume-Ordner. Bestehende Dokumente von Solaris werden migriert.\n\n## Tracks\n\n### Track 1: Deploy (LXC + Docker)\n- Neues LXC erstellen (Pattern wie Komga/Mailpiler)\n- Docker Compose: Paperless-ngx + Redis + PostgreSQL\n- Samba-Share für consume-Ordner\n- node_exporter für Monitoring\n\n### Track 2: ScanSnap iX1600 Anbindung\n- WiFi → SMB Profil konfigurieren (via ScanSnap Home, einmalig)\n- Scanner scannt direkt in Paperless consume-Ordner\n- Kein USB-Passthrough nötig, kein SANE\n\n### Track 3: Dokumenten-Import (existierendes Bead claude-fyv)\n- Bestehende Dokumente von Solaris inventarisieren\n- Tag/Correspondent-Struktur definieren\n- Batch-Import mit Review-Workflow\n\n## Hardware\n- Scanner: ScanSnap iX1600 (USB an Elysium, WiFi-fähig)\n- LXC auf Elysium (Proxmox)\n- Netzwerk: VLAN 60 (192.168.60.x)\n\n## Architektur-Entscheidung\nWiFi → SMB statt USB-Passthrough weil:\n- Kein SANE-Treiber nötig (ix1600 Support unzuverlässig)\n- Kein udev/Device-Pfad-Management\n- Scanner bleibt standalone nutzbar\n- Ein-Knopf-Bedienung am Touchscreen","status":"open","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T07:43:17Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","labels":["decision"]}
{"id":"claude-727","title":"Komga: Docker Setup auf Elysium","description":"## Ziel\nKomga Comic-/Manga-Server als Docker Container auf Elysium deployen.\n\n## Warum Komga\n- OPDS-Support für Chunky/Panels auf iPad\n- Native Unterstützung für CBR/CBZ/PDF/EPUB\n- Ordner-basierte Bibliotheks-Organisation\n- Leichtgewichtig (Java, ~256MB RAM)\n\n## Setup\n- Docker Container auf bestehendem LXC oder eigener LXC\n- Reverse Proxy via Caddy (comics.sussdorff.de oder intern)\n- Persistente Volumes für /config und /data\n- OPDS-Endpoint für mobile Apps konfigurieren\n\n## Docker Compose\n```yaml\nservices:\n  komga:\n    image: gotson/komga\n    container_name: komga\n    volumes:\n      - ./config:/config\n      - ./data:/data  # Comic-Bibliothek\n    ports:\n      - 25600:25600\n    restart: unless-stopped\n```\n\n## Akzeptanzkriterien\n- [ ] Komga Container läuft und ist erreichbar\n- [ ] Admin-User angelegt\n- [ ] Bibliothek konfiguriert (/data Verzeichnis)\n- [ ] OPDS-Endpoint erreichbar\n- [ ] Chunky auf iPad kann per OPDS verbinden","notes":"RAM von 1GB auf 4GB erhöht - 1GB war zu wenig für JVM + Thumbnail-Generierung. 4GB stabil.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:14:55Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:08Z","closed_at":"2026-02-17T04:13:20Z","close_reason":"LXC 112 deployed, Komga v1.24.1 running with 4GB RAM, Caddy + DNS configured, admin user created","labels":["epic:claude-k6i"]}
{"id":"claude-7as","title":"Langfuse self-hosted deployen","description":"Langfuse als Docker-Container auf Services-VM aufsetzen (konsolidiert mit Services-VM Task).\n\n## Scope\n- Docker Compose für Langfuse + Postgres\n- Reverse Proxy (Caddy/nginx) mit HTTPS (self-signed oder Let's Encrypt intern)\n- Erreichbar im VLAN 60 (nicht public)\n- Initial-Konfiguration: Projekt 'shikigami' anlegen\n\n## Acceptance Criteria\n- [ ] Langfuse Dashboard erreichbar im LAN\n- [ ] Postgres persistent (Volume)\n- [ ] Health-Check funktioniert","status":"closed","priority":1,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T01:37:04Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:09Z","closed_at":"2026-02-24T02:00:53Z","close_reason":"Langfuse v2 auf Services-VM (LXC 116) deployed, Projekt shikigami angelegt, API Keys generiert","dependencies":[{"issue_id":"claude-7as","depends_on_id":"claude-4r0","type":"blocks","created_at":"2026-02-24T02:37:25Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-7il","title":"Ollama LLM Server als LXC","description":"LXC Container mit Ollama für lokale LLM-Inferenz aufsetzen.\n\n## Kontext\n- Elysium hat ~100 GB freien RAM → 70B-Modelle möglich\n- CPU-only Inferenz (Zen 5, 12C/24T), ggf. iGPU via Vulkan\n- Kein GPU-Passthrough nötig\n\n## Akzeptanzkriterien\n- [ ] LXC Container erstellt und konfiguriert (RAM: 64-96 GB)\n- [ ] Ollama installiert und lauffähig\n- [ ] Mindestens ein 70B-Modell getestet (z.B. Llama 3.3 70B oder Qwen 2.5 72B)\n- [ ] API von lokalem Netz erreichbar (Port 11434)\n- [ ] Autostart konfiguriert","notes":"LXC setup-skripte + docker-compose + deploy.sh erstellt (lxc/ollama/). Caddy-Entry für ollama.sussdorff.de konfiguriert. Nächster Schritt: setup-lxc.sh auf Proxmox ausführen, dann deploy.sh.\nDeployed und verifiziert. API antwortet auf 192.168.60.15:11434. Kein Modell gepullt (70B dauert zu lang für Session). Intern-only, kein öffentliches DNS.\nService läuft, kein Modell gepullt. User überlegt ob Ollama für lokale Embeddings/Privacy-Tasks oder eher API-basierte Modelle (Kimi K2, Claude) für Agent-Tasks sinnvoller sind.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-15T12:46:13Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:09Z","closed_at":"2026-02-17T02:50:29Z","close_reason":"LXC 105 deployed, Ollama API läuft auf 192.168.60.15:11434, kein Modell gepullt (bewusst). Intern-only.","work_type":"mutex"}
{"id":"claude-88k","title":"Shikigami-Bot: Isoliertes VLAN (7x) + Firewall-Regeln","description":"Shikigami-Bot VM in neues isoliertes VLAN umziehen. Kontrolle über Outbound-Zugriffe.\n\n## Motivation\n- VLAN 60 ist über NetBird von außen erreichbar → zu viel Exposition für Bot-VM\n- 'Vertrauen ist gut, Kontrolle ist besser'\n- Bot soll nur auf explizit erlaubte Services zugreifen\n\n## Ziel-Architektur\n- Shikigami-Bot VM → neues VLAN (70, 80 oder 90, noch festzulegen)\n- Kein freier Outbound ins lokale Netz\n- Firewall-Regeln in UniFi Dream Wall:\n\n### Erlaubte Outbound-Verbindungen aus Bot-VLAN\n| Ziel | Port | Zweck |\n|------|------|-------|\n| Services-VM (VLAN 60) | 3307 | DOLT / beads |\n| Services-VM (VLAN 60) | 37777 | claude-mem Worker |\n| Services-VM (VLAN 60) | Langfuse-Port | Tracing |\n| HA-VM (VLAN 60, genau eine IP) | 8123 | Home Assistant API |\n| Internet | 443 | Telegram API, Anthropic API |\n\n### Blockiert\n- Alle anderen lokalen VLANs\n- Management-Netz (VLAN 1/2)\n\n## Acceptance Criteria\n- [ ] Neues VLAN für Bot ausgewählt und angelegt\n- [ ] VM 200 in neues VLAN migriert\n- [ ] UniFi Firewall-Regeln konfiguriert\n- [ ] Bot kann Telegram + Anthropic API erreichen\n- [ ] Bot kann Services-VM (DOLT + claude-mem) erreichen\n- [ ] Bot kann HA-API erreichen (eine IP, ein Port)\n- [ ] Bot kann NICHT ins Management-Netz oder andere VLANs","status":"open","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T01:37:03Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:10Z","dependencies":[{"issue_id":"claude-88k","depends_on_id":"claude-4r0","type":"blocks","created_at":"2026-02-24T02:37:25Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-8o7","title":"[LEARNING] Calibre-Web: LXC 109, IP 192.168.60.19, Port 8083","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T18:01:12Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:11Z","labels":["learning"]}
{"id":"claude-8oh","title":"piler-cli: Projekt-Scaffold + SSH/Docker Transport Layer","description":"Grundgerüst: pyproject.toml, Click CLI Entry Point, Transport-Klasse die SSH → pct exec 111 → docker exec abstrahiert. Config für Proxmox Host IP, LXC ID, DB Credentials (aus 1Password oder .env). Acceptance: 'piler stats' zeigt Archiv-Statistiken.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:27:03Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:12Z","closed_at":"2026-02-18T04:31:40Z","close_reason":"Scaffold fertig: pyproject.toml, Click CLI, PilerTransport mit base64-Encoding, alle 4 Commands (stats/search/list/read) getestet gegen Live-Instanz (120k+ Mails)","labels":["epic:claude-ecz"]}
{"id":"claude-8r4","title":"Mailpiler Import: Knox Sparsebundles + mail-archive DB","description":"## Ziel\nHistorische E-Mail-Archive aus Knox (verschlüsselte Sparsebundles) und der bestehenden mail-archive DB nach Mailpiler importieren.\n\n## Quellen\n1. **Knox Sparsebundles** (~/Documents) - verschlüsselte Archive, vermutlich Mail-Inhalte\n   - Müssen erst gemountet und Inhalt identifiziert werden\n   - Passwörter bei Malte erfragen\n2. **mail-archive DB** - bestehende Datenbank (Format prüfen)\n3. **EagleFiler Archive** - möglicherweise Mail-Inhalte (prüfen)\n\n## Vorgehen\n1. Knox-Vaults mounten und Inhalt inventarisieren\n2. Mail-relevante Dateien identifizieren (mbox, eml, emlx)\n3. mail-archive DB Format analysieren und Export-Strategie festlegen\n4. EagleFiler Libraries auf Mail-Inhalte prüfen\n5. Import nach Mailpiler\n6. Verifizierung\n\n## Akzeptanzkriterien\n- [ ] Knox-Inhalte identifiziert\n- [ ] Alle Mail-relevanten Archive nach Mailpiler importiert\n- [ ] Verifizierung per Stichprobe","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T11:20:48Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:13Z","dependencies":[{"issue_id":"claude-8r4","depends_on_id":"claude-9fg","type":"blocks","created_at":"2026-02-16T12:20:54Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-92t","title":"NetBird VPN Deployment — Zero-Trust Remote Access","description":"Deploy NetBird (WireGuard mesh VPN) to replace port-forwarding (80/443) with zero-trust tunnels.\n\n## Goals\n- Remove 80/443 port forwards from router — no public attack surface\n- Remote access to Elysium services (Grafana, Paperless, Komga, ABS, Plex) from anywhere\n- Secure tunnel into Shikigami (OpenClaw VM) for development access\n- Single NetBird network with ACL-based segmentation (claude-services vs shikigami)\n\n## Architecture Decision: Single Network, ACL Segmentation\n- One NetBird management server/account\n- ACL groups: claude-services, shikigami, admin-devices\n- Policies: admin-devices → all, external → shikigami only\n\n## Key Decisions Needed\n1. Self-hosted management server vs. netbird.io cloud (free tier: 5 peers)\n2. NetBird on Proxmox host vs. dedicated LXC\n3. Shikigami: NetBird client on OpenClaw VM directly or on Hyper-V host?\n4. Client setup: macOS, iOS, Android\n\n## Acceptance Criteria\n- [ ] NetBird management server running\n- [ ] Elysium services reachable via NetBird tunnel from external network\n- [ ] OpenClaw VM on Shikigami reachable via NetBird tunnel\n- [ ] ACLs configured: admin full access, restricted peers OpenClaw only\n- [ ] Port forwards 80/443 removed from router\n- [ ] Clients configured on macOS + mobile","status":"closed","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-19T19:48:16Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","closed_at":"2026-02-19T21:20:32Z","close_reason":"Not needed — Shikigami is a VM on Elysium (same Proxmox host, same VLAN 60). No multi-site mesh needed. UDM WireGuard already provides remote access. Recommendation: keep UDM WireGuard, remove 80/443 port forwards instead."}
{"id":"claude-9fg","title":"E-Mail Archiv auf Elysium einrichten","description":"## Ziel\nMailpiler als **Single Source of Truth** für alle E-Mail-Archive auf Elysium. Ersetzt msq CLI, second-brain Mail-Beads, und perspektivisch den direkten Fastmail-MCP-Zugriff.\n\n## Architektur\n```\nFastmail (IMAP) ──→ Mailpiler (regelmäßiger Fetch) ──→ REST API ──→ KI-Agenten / MCP\nGmail (IMAP) ────→        ↑\nHistorische Archive ──→ (EML Import)\n```\n\n## Vorteile vs. Eigenentwicklung (second-brain)\n- Fertige Lösung: Volltextsuche (Sphinx), Web-UI, IMAP-Fetch, Audit-Trail\n- REST API für KI-Agenten (MCP-Wrapper trivial)\n- Fastmail-MCP wird überflüssig - Agenten suchen im Archiv statt im Live-Postfach\n- Datensouveränität: alles auf eigener Hardware\n\n## Bekannter Trade-off\n- Keine Vektor-Embeddings / semantische Suche (könnte nachgelagert als separater Service ergänzt werden)\n\n## Laufende IMAP-Konten (Mailpiler pollt direkt)\n- malte.sussdorff@cognovis.de (Fastmail)\n- sussdorff@sussdorff.de (Fastmail)\n- malte.sussdorff@gmail.com\n- malte.sussdorff@agiler-norden.de\n- malte@zahnrad-network.de\n\n## Historische Archive (einmaliger Import)\n- MailSteward SQLite-DBs (msq extract als Export-Tool)\n- Knox Sparsebundles (verschlüsselte Mail-Archive)\n- Bestehende mail-archive DB\n\n## Nicht anbinden\n- sussdorff@me.com (ad acta)\n\n## Ablösung nach Erfolg\n- ~/code/msq → archivieren\n- ~/code/fastmail → löschen (leeres Repo)\n- second-brain Mail-Beads → schließen (superseded)\n- Fastmail MCP → perspektivisch durch Mailpiler-MCP ersetzen\n\n## Akzeptanzkriterien\n- [ ] Mailpiler LXC deployed und erreichbar (mail-archive.sussdorff.de)\n- [ ] Alle 5 IMAP-Konten angebunden und polled\n- [ ] Historische Archive importiert (MailSteward, Knox, mail-archive)\n- [ ] REST API verifiziert und von KI-Agent nutzbar\n- [ ] Volltextsuche funktional über alle Archive","notes":"LXC setup-skripte + docker-compose (Mailpiler+MariaDB) + .env.example + deploy.sh erstellt (lxc/mailpiler/). Caddy-Entry für mail-archive.sussdorff.de. Nächster Schritt: setup-lxc.sh auf Proxmox, .env anlegen, deploy.sh, dann IMAP-Fetch von Fastmail konfigurieren.\n## Bestehende CLI-Projekte (2026-02-16)\n- ~/code/fastmail/ existiert als leeres Git-Repo (kein Commit) - war vermutlich als Mail-Archivierungs-CLI geplant\n- Mailpiler ersetzt diesen Bedarf: bietet IMAP-Fetch, Volltextsuche, Web-UI out-of-the-box\n- ~/code/fastmail/ kann nach Mailpiler-Deployment gelöscht werden\n\n## Mail-Archive Import-Quellen\n- MailSteward-Datenbanken (lokal auf Solaris in ~/Documents)\n- Knox Sparsebundles (evtl. Mail-Archive verschlüsselt)\n- EagleFiler Archive (evtl. Mail-Inhalte)\n- Fastmail IMAP (laufender Sync via Mailpiler)\n## msq CLI (~/code/msq) - bestehende MailSteward-Abfrage-CLI\nFunktionierende Python-CLI (Typer/Rich) für MailSteward SQLite-Archive:\n- Befehle: dbs, search, show, attachments, extract, stats\n- Features: Parallel-Suche über alle DBs, Schema-Auto-Detection, Filter (from/to/subject/date/attachments)\n- Tech: Python 3.14, Typer, Rich, uv-basiert\n\n### Migration zu Mailpiler\nmsq wird nach Mailpiler-Deployment nicht mehr benötigt, ABER:\n1. Zuerst MailSteward-Archive nach Mailpiler importieren (EML/mbox Export aus SQLite)\n2. msq könnte temporär als Export-Tool dienen (extract-Funktion für Anhänge)\n3. Nach erfolgreichem Import + Verifizierung: msq + ~/code/fastmail archivieren/löschen\nDeployed und verifiziert. Mailpiler (simatec/piler:1.4.8) + MariaDB + Manticore + Memcached laufen. Intern erreichbar auf 192.168.60.21:8080 (HTTP 200). Default: admin@local/pilerrocks.\nContainer laufen (healthy), aber Web-Setup hatte temporären DB-Connection Error. Service antwortet jetzt mit HTTP 200. Default-Passwort (admin@local/pilerrocks) noch nicht geändert.","status":"closed","priority":3,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T08:30:27Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:14Z","closed_at":"2026-02-17T02:50:31Z","close_reason":"LXC 111 deployed, Mailpiler (simatec/piler 1.4.8) mit MariaDB+Manticore+Memcached. Admin PW geändert. IMAP-Fetch + Archiv-Import als Follow-up Beads.","labels":["epic:claude-k6i"]}
{"id":"claude-9p1","title":"Jellyfin: Medien-Migration (~230GB Videos von Solaris)","description":"## MERGED: Medien-Migration ist jetzt Teil von claude-3bi (Plex Deploy)\n\nDie Video-Migration wird im Rahmen des Plex-Deploys erledigt. Dieses Bead kann geschlossen werden sobald claude-3bi die Video-Bibliotheken aufgesetzt hat.\n\nOriginale Quellen-Dokumentation siehe claude-3bi.","notes":"POST-IMPORT ARCHIVIERUNG: Nach erfolgreichem Import Quelldateien auf PRO-G40 verschieben (Pattern: claude-e41). Ziel: /Volumes/PRO-G40/Imported-to-Elysium/{Service}/ mit .manifest.json. Befreit lokalen Speicher auf Solaris und dokumentiert Import-Status.\nMerged into claude-3bi (Plex Deploy ersetzt Jellyfin + Navidrome). Video-Migration wird dort abgedeckt.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:03:09Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","closed_at":"2026-02-17T16:40:58Z","close_reason":"196 GB Medien auf Elysium transferiert (Music 39GB, Courses 103GB, TV 33GB, Personal 24GB) — jetzt unter Plex statt Jellyfin","labels":["epic:claude-k6i"],"dependencies":[{"issue_id":"claude-9p1","depends_on_id":"claude-3bi","type":"blocks","created_at":"2026-02-17T16:31:51Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-9ws","title":"piler-cli: list — Mails filtern nach Datum/Absender/Domain","description":"'piler list --from cognovis --since 2025-01 --limit 50' filtert über SQL auf v_messages View. Flags: --from, --to, --domain, --since, --until, --limit. Output: Tabelle wie search. Acceptance: Filterung nach Absender-Domain liefert korrekte Ergebnisse.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:27:12Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:16Z","closed_at":"2026-02-18T04:31:46Z","close_reason":"Im Scaffold-Task mitimplementiert und gegen Live-Instanz getestet","labels":["epic:claude-ecz"],"dependencies":[{"issue_id":"claude-9ws","depends_on_id":"claude-8oh","type":"blocks","created_at":"2026-02-18T05:27:28Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-ac7","title":"Eaton 850 USV mit NUT überwachen und Proxmox konfigurieren","description":"Eaton Ellipse ECO 850 USV per USB an Elysium angeschlossen, muss mit NUT (Network UPS Tools) konfiguriert werden.\n\n## Hardware\n- USV: Eaton (MGE UPS Systems), USB ID 0463:ffff\n- Anschluss: USB an Elysium\n- lsusb: Bus 003 Device 007\n\n## Akzeptanzkriterien\n- [ ] NUT (nut-server, nut-client) installiert\n- [ ] ups.conf konfiguriert (usbhid-ups Treiber für MGE/Eaton)\n- [ ] upsd.conf + upsd.users konfiguriert\n- [ ] upsmon konfiguriert für automatisches Shutdown bei niedrigem Akku\n- [ ] USV-Status abrufbar (upsc)\n- [ ] Proxmox Web-UI zeigt USV-Status (optional, ggf. via Node-Konfiguration)\n- [ ] Home Assistant Integration prüfen (NUT Addon oder Integration)\n\n## Treiber\nEaton/MGE USVs nutzen den usbhid-ups Treiber in NUT.\n\n## Shutdown-Policy\n- Bei Stromausfall: VMs graceful herunterfahren\n- Dann Proxmox Host herunterfahren\n- Typisch: Shutdown wenn Akku \u003c 20% oder Laufzeit \u003c 2 Min","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-15T13:39:08Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:17Z","closed_at":"2026-02-15T13:44:57Z","work_type":"mutex"}
{"id":"claude-ahk","title":"Grafana Status-Dashboard: Service Health + Disk/Memory Übersicht","description":"## Anforderungen\nGrafana Dashboard das auf einen Blick zeigt ob alles OK ist.\n\n## Dashboard-Panels:\n1. **Service Status Row**: Stat Panels (grün/rot) für jeden HTTP-Service\n   - Letzter Wert von probe_success (1=UP/grün, 0=DOWN/rot)\n2. **Disk Usage Row**: Gauge Panels pro LXC\n   - Aktueller Disk-Usage % mit Schwellenwert-Farben (grün \u003c80%, gelb 80-90%, rot \u003e90%)\n3. **Memory Usage Row**: Gauge Panels pro LXC\n   - Aktueller Memory-Usage % mit Schwellenwert-Farben\n4. **Trend Panels**: Time-Series Graphs\n   - Disk-Usage über letzte 7 Tage pro LXC (Trend erkennen)\n\n## Akzeptanzkriterien\n- [ ] Grafana Dashboard als JSON provisioniert (nicht manuell erstellt)\n- [ ] Stat Panels für Service-Status (grün=UP, rot=DOWN)\n- [ ] Gauge Panels für Disk + Memory mit Farbschwellenwerten\n- [ ] Mindestens 1 Trend-Graph (Disk über Zeit)\n- [ ] Dashboard lädt automatisch beim Grafana-Start (provisioning)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:30:55Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:18Z","closed_at":"2026-02-17T14:45:38Z","close_reason":"Grafana Dashboard 'Elysium Status' provisioniert mit 11 Panels (Service Status, Disk/Memory Gauges, 7d Trend)","dependencies":[{"issue_id":"claude-ahk","depends_on_id":"claude-0tk","type":"blocks","created_at":"2026-02-17T15:31:04Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-ahk","depends_on_id":"claude-5rk","type":"blocks","created_at":"2026-02-17T15:31:04Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-ahk","depends_on_id":"claude-wj6","type":"blocks","created_at":"2026-02-17T15:31:04Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-ald","title":"Remove 80/443 port forwards from DreamMachine","description":"Remove the HTTP/HTTPS port forwards from the UniFi DreamMachine router. These expose Elysium to the public internet unnecessarily.\n\n## Context\n- 80/443 currently forwarded to Elysium\n- Remote access handled via UDM WireGuard VPN — no need for open ports\n- Evaluated NetBird as alternative (claude-92t) — not needed since everything is on same host\n\n## Steps\n1. Document current port forward rules (screenshot/export)\n2. Remove 80/443 NAT rules from UDM\n3. Verify services still reachable via WireGuard VPN from external network\n4. Verify no other services depend on the port forwards\n\n## Acceptance Criteria\n- [ ] No inbound port forwards on UDM (except WireGuard UDP)\n- [ ] All services reachable via VPN tunnel\n- [ ] Router scan shows 80/443 closed","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-19T21:20:41Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:32Z","closed_at":"2026-02-20T06:50:02Z","close_reason":"Ersetzt durch claude-bgf.6 (DreamMachine Port Forwards entfernen) im NetBird Epic"}
{"id":"claude-amx","title":"Mailpiler: IMAP-Fetch von Fastmail + Archiv-Import","description":"## Teilaufgaben\n\n### 1. IMAP-Fetch von Fastmail konfigurieren\n- In Mailpiler UI IMAP-Source anlegen\n- Server: imap.fastmail.com:993 (SSL)\n- Credentials: Fastmail App-Passwort generieren\n- Regelmäßiger Sync konfigurieren\n\n### 2. Bestehende Archive importieren\n- ~/Mailsteward Verzeichnisse identifizieren und Format prüfen\n- mail-archive DB anbinden/importieren\n- Ggf. mbox/EML Export aus alten Archiven\n\n## Akzeptanzkriterien\n- [ ] IMAP-Fetch von Fastmail läuft automatisch\n- [ ] Bestehende Mailsteward-Archive importiert\n- [ ] Volltextsuche über alle Mails funktioniert","notes":"POST-IMPORT ARCHIVIERUNG: Mailpiler-Archiv nach Import auf PRO-G40 verschieben falls lokal vorhanden (Pattern: claude-e41).\nSession 17.02.2026: IMAP-Fetch läuft für alle 6 Accounts (3 Fastmail, 2 Gmail, 1 IONOS). Domains angelegt (sussdorff.de, cognovis.de, gmail.com, agiler-norden.de, zahnrad-network.de, solutio.de). Retention auf 29000 Tage gesetzt (32-bit INT Limit bei retained-Spalte). enable_folders=1. 8 Archiving Rules für Kalender-Responses. Solutio EML-Import: 4393 Mails (1529 Archive + 2864 Sent) via pilerimport mit Folder-Zuordnung importiert. pilerimport hatte silent failure wegen retention overflow - Fix war retention von 36500 auf 29000 Tage.","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:03:35Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","labels":["epic:claude-k6i"]}
{"id":"claude-any","title":"[LEARNING] 1Password op-create scripts: set -euo pipefail aborts on field name errors, leaving items uncreated","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T05:20:03Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:20Z","closed_at":"2026-02-22T06:00:21Z","close_reason":"Materialisiert: CLAUDE.md Pre-Flight table (op item create case-sensitivity)","labels":["learning","learning:workflow","scope:global"]}
{"id":"claude-b7a","title":"[DISCOVERY] Parallels VMs nach Proxmox migrieren + Zahnrad Testumgebungen klaeren","description":"## Ist-Zustand\n- Parallels auf Solaris (MacBook) mit mehreren VMs\n- charly-dev2: Kann nach Proxmox migriert werden\n- Weitere VMs: Zahnrad/Solutio Testumgebungen\n  - Lizenz-Status unklar ('nicht mehr offiziell haben sollte')\n  - Dirk fragen nach offiziellen Testumgebungen\n\n## Zu klaeren\n1. charly-dev2: Was laeuft darauf? Braucht man es noch? Migration nach Proxmox sinnvoll?\n2. Zahnrad VMs: Bei Dirk anfragen ob offizielle Testumgebungen verfuegbar sind\n3. Solutio Installation: Aufraumen oder archivieren?\n4. Parallels-Lizenz: Kann nach VM-Migration gekuendigt werden?\n\n## Migration (falls gewuenscht)\n- Parallels exportiert als .pvm oder .hdd\n- Konvertierung zu qcow2 fuer Proxmox: qemu-img convert\n- Import als VM in Proxmox\n\n## Akzeptanzkriterien\n- [ ] Entscheidung ueber jede VM (migrieren/loeschen/archivieren)\n- [ ] Dirk kontaktiert bzgl. Zahnrad Testumgebungen\n- [ ] charly-dev2 migriert oder archiviert","status":"open","priority":4,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T10:14:42Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:21Z","labels":["epic:claude-k6i"]}
{"id":"claude-b7h","title":"[LEARNING] Prefer demo.\u003cdomain\u003e subdomains for reverse proxy demo instances, keep bare domain for landing page","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T18:01:15Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:22Z","labels":["learning"]}
{"id":"claude-bgf","title":"[EPIC] NetBird Self-Hosted VPN + Reverse Proxy (netbird.cognovis.de)","description":"Zero-Trust Remote-Zugang zu Elysium-Services via self-hosted NetBird auf neuem Hetzner CX23 VPS.\n\n## Drei Zugangs-Tiers\n- **Public** (keine Auth): mira.cognovis.de, ignis.sussdorff.de — Demo-Sites für jeden\n- **Personal** (SSO Auth): audiobooks.sussdorff.de, paperless.sussdorff.de, grafana.sussdorff.de — Familie + Admin\n- **Internal-only**: Plex, *arr — nur über DreamMachine WireGuard VPN im LAN\n\n## Architektur\n- Neuer Hetzner CX23 VPS mit NetBird self-hosted (Management + Signal + Relay + Proxy)\n- Traefik als Reverse Proxy mit TLS passthrough + Let's Encrypt\n- NetBird LXC auf Elysium als Routing Peer für 192.168.60.0/24\n- Collaborator SSH-Zugang via NetBird ACLs\n- Domain: netbird.cognovis.de + *.proxy.netbird.cognovis.de\n\n## Ergebnis\n- Zero offene Ports auf DreamMachine (außer WireGuard UDP)\n- Alle Public/Personal Services über NetBird Reverse Proxy\n- Collaborators SSH-Zugang mit per-User ACLs\n- DreamMachine WireGuard bleibt für Internal-only Tier\n\n## Ersetzt\n- claude-ald (Port Forwards entfernen)\n- claude-c6c (Reverse Proxy für Grafana)","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:47:43Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","closed_at":"2026-02-25T13:49:00Z","close_reason":"NetBird VPN + Reverse Proxy vollständig deployed. VPS (Hetzner CX23), Routing Peer (LXC 115), alle Services via *.sussdorff.org, DreamMachine Port Forwards entfernt. 6/6 Sub-Tasks closed."}
{"id":"claude-bgf.1","title":"Hetzner CX23 provisionieren + Basis-Setup","description":"Neuen Hetzner CX23 VPS erstellen und absichern.\n\n## Steps\n- CX23 via hcloud CLI erstellen (Ubuntu 24.04, Falkenstein/Nürnberg)\n- SSH hardening (key-only, no root password), fail2ban, ufw\n- DNS bei Hetzner anlegen: netbird.cognovis.de + *.proxy.netbird.cognovis.de → VPS IP\n\n## Acceptance Criteria\n- [ ] Server erreichbar via SSH\n- [ ] fail2ban + ufw aktiv\n- [ ] DNS netbird.cognovis.de + Wildcard auflösbar","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:47:51Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:24Z","closed_at":"2026-02-22T08:25:33Z","close_reason":"CX23 (46.224.133.69) provisioniert, fail2ban+ufw aktiv, DNS netbird.cognovis.de + *.proxy.netbird wildcard auflösbar","dependencies":[{"issue_id":"claude-bgf.1","depends_on_id":"claude-bgf","type":"parent-child","created_at":"2026-02-20T07:47:50Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-bgf.2","title":"NetBird self-hosted deployen auf VPS","description":"NetBird Management Server self-hosted auf dem neuen CX23 VPS deployen.\n\n## Steps\n- Docker Compose: Management + Signal + Relay + Coturn + Dashboard + Proxy\n- Traefik für TLS passthrough (Reverse Proxy Feature aktivieren)\n- Built-in IdP mit Admin-User (malte@sussdorff.de)\n- Reverse Proxy Feature gemäß docs.netbird.io/selfhosted/migration/enable-reverse-proxy\n\n## Acceptance Criteria\n- [ ] NetBird Dashboard erreichbar unter netbird.cognovis.de\n- [ ] Admin-Login funktioniert\n- [ ] Reverse Proxy Feature aktiviert\n- [ ] Signal + Relay + Coturn healthy","notes":"NetBird v0.65 deployed auf 46.224.133.69. 4 Container healthy: server, dashboard, traefik, proxy. Dashboard unter https://netbird.cognovis.de erreichbar (HTTP 200). Proxy-Domain: proxy.cognovis.de. Config in /opt/. Admin-Onboarding muss manuell im Browser erfolgen (/setup). Noch offen: sussdorff.de als Custom Domain im Dashboard hinzufügen.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:47:58Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:25Z","closed_at":"2026-02-22T08:55:09Z","close_reason":"NetBird v0.65 self-hosted deployed: 4 Container (server, dashboard, traefik, proxy) healthy, Dashboard unter https://netbird.cognovis.de mit Admin-Account, Proxy-Domain proxy.cognovis.de, DNS für beide Domains (cognovis.de + sussdorff.de) konfiguriert","dependencies":[{"issue_id":"claude-bgf.2","depends_on_id":"claude-bgf","type":"parent-child","created_at":"2026-02-20T07:47:57Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-bgf.2","depends_on_id":"claude-bgf.1","type":"blocks","created_at":"2026-02-20T07:48:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-bgf.3","title":"NetBird LXC auf Elysium als Routing Peer","description":"Neuer LXC auf Elysium der als NetBird Routing Peer für VLAN 60 dient.\n\n## Steps\n- LXC erstellen (Ubuntu 24.04, 1 Core, 1 GB RAM, 8 GB Disk, VLAN 60)\n- TUN device passthrough in LXC config:\n  lxc.cgroup2.devices.allow: c 10:200 rwm\n  lxc.mount.entry: /dev/net dev/net none bind,create=dir\n  lxc.mount.entry: /dev/net/tun dev/net/tun none bind,create=file\n- NetBird Client installieren, Setup Key Enrollment\n- Als Routing Peer konfigurieren für 192.168.60.0/24 mit Masquerading\n\n## Acceptance Criteria\n- [ ] LXC läuft auf Elysium mit NetBird Client\n- [ ] Peer im NetBird Dashboard sichtbar und connected\n- [ ] VPS kann über NetBird-Mesh 192.168.60.x Services erreichen (curl test)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:48:08Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:25Z","closed_at":"2026-02-22T09:03:29Z","close_reason":"LXC 115 (192.168.60.25) als Routing Peer deployed, P2P connected (16ms), IP forwarding + masquerading aktiv. VPS erreicht alle 5 Services: Grafana(:3000), MIRA(:80), ABS(:13378), Paperless(:8000), Ignis(:80)","dependencies":[{"issue_id":"claude-bgf.3","depends_on_id":"claude-bgf","type":"parent-child","created_at":"2026-02-20T07:48:07Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-bgf.3","depends_on_id":"claude-bgf.2","type":"blocks","created_at":"2026-02-20T07:48:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-bgf.4","title":"Reverse Proxy Services konfigurieren","description":"Public und Personal Tier Services über NetBird Reverse Proxy exponieren.\n\n## Proxy-Domains (zwei Custom Domains)\n- **proxy.cognovis.de** + *.proxy.cognovis.de → für cognovis Services (mira)\n- **proxy.sussdorff.de** + *.proxy.sussdorff.de → für sussdorff Services (ignis, abs, paperless, grafana)\n\n## Public Tier (keine Auth)\n- mira.proxy.cognovis.de → MIRA LXC 114 (Port 3000)\n- ignis.proxy.sussdorff.de → Ignis LXC 101 (Port 3000)\n\n## Personal Tier (Service-eigene Auth vorerst, SSO kommt in Epic 2)\n- audiobooks.proxy.sussdorff.de → ABS LXC 110 (Port 13378)\n- paperless.proxy.sussdorff.de → Paperless LXC 108 (Port 8000)\n- grafana.proxy.sussdorff.de → Monitoring LXC 113 (Port 3000)\n\n## Steps\n- sussdorff.de als Custom Domain im NetBird Dashboard hinzufügen\n- Services im Dashboard als Reverse Proxy Endpoints anlegen (Target: Network Resource 192.168.60.x)\n- DNS bereits konfiguriert: proxy/\\*.proxy CNAME auf netbird.cognovis.de für beide Domains\n- TLS automatisch via Let's Encrypt (ACME TLS-ALPN-01)\n- Public Tier: Auth deaktiviert\n- Personal Tier: vorerst Service-eigene Auth (ABS/Paperless/Grafana Login)\n\n## Acceptance Criteria\n- [ ] Alle 5 Services extern über HTTPS erreichbar\n- [ ] Public Sites ohne Login-Prompt\n- [ ] Personal Sites zeigen Service-eigenen Login\n- [ ] TLS-Zertifikate gültig","notes":"## Stand 2026-02-22\n\n### Erledigt\n- proxy.sussdorff.de als Custom Domain hinzugefügt (Cluster: proxy.cognovis.de)\n- DNS korrekt konfiguriert und via Hetzner Nameserver verifiziert (CNAME → netbird.cognovis.de → 46.224.133.69)\n- Korrektes Target-Pattern entdeckt: VLAN60 Subnet Resource (nicht Routing Peer) auswählen → IP-Feld wird editierbar\n- mira.proxy.cognovis.de → 192.168.60.24:80 erstellt ✅ (TLS wird ausgestellt)\n\n### Blocker\n- proxy.sussdorff.de steht auf 'Pending Verification' — NetBird muss CNAME noch verifizieren (async, bis 24h)\n- Domain erscheint erst im Service-Dropdown wenn verifiziert\n- Restliche 4 Services warten auf Domain-Verification:\n  - ignis.proxy.sussdorff.de → 192.168.60.10:80\n  - audiobooks.proxy.sussdorff.de → 192.168.60.20:13378\n  - paperless.proxy.sussdorff.de → 192.168.60.18:8000\n  - grafana.proxy.sussdorff.de → 192.168.60.23:3000\n\n### Korrigierte Ports (vs. Bead-Description)\n- MIRA: Port 80 (nginx, nicht 3000)\n- Ignis: Port 80 (nginx, nicht 3000)\n- ABS: Port 13378\n- Paperless: Port 8000\n- Grafana: Port 3000\n\n### Nächste Schritte\n1. Warten bis proxy.sussdorff.de verifiziert ist\n2. Restliche 4 Services anlegen\n3. /tmp/op-update-netbird.sh ausführen (NetBird Admin-Password in 1Password speichern)\n## Domain-Änderung 2026-02-22\nProxy-Domain geändert von proxy.sussdorff.de → proxy.sussdorff.org\nDNS für sussdorff.org ist korrekt konfiguriert. Kein weiterer Playwright-Einsatz nötig — Services können direkt über das NetBird Dashboard angelegt werden sobald die Domain verfügbar ist.\n## Korrektur Domain-Setup 2026-02-22\nCustom Domain ist 'sussdorff.org' (nicht proxy.sussdorff.org/de) — Status: Active ✅\nServices werden direkt als Subdomains exponiert:\n- ignis.sussdorff.org → 192.168.60.10:80\n- audio.sussdorff.org → 192.168.60.20:13378\n- paperless.sussdorff.org → 192.168.60.18:8000\n- grafana.sussdorff.org → 192.168.60.23:3000\nDomain ist verifiziert, Services können jetzt angelegt werden.\n## Finale Konfiguration 2026-02-22\nAlle 6 Services im NetBird Reverse Proxy angelegt und aktiv:\n- audiobooks.sussdorff.org → 192.168.60.20:13378 ✅\n- books.sussdorff.org → 192.168.60.19:8083 ✅ (Calibre-Web, nachträglich hinzugefügt)\n- grafana.sussdorff.org → 192.168.60.23:3000 ✅\n- ignis.sussdorff.org → 192.168.60.10:80 ✅\n- mira.proxy.cognovis.de → aktiv (kein 'Issuing certificate' mehr) ✅\n- paperless.sussdorff.org → 192.168.60.18:8000 ✅\nTLS-Zertifikate werden gerade ausgestellt (Let's Encrypt, ACME). Kein API-Zugriff möglich — Reverse Proxy ist UI-only Feature, nicht in der NetBird REST API.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:48:17Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:26Z","closed_at":"2026-02-22T10:29:09Z","close_reason":"6 Services konfiguriert (audiobooks, books, grafana, ignis, mira, paperless), TLS wird ausgestellt, alle Targets auf VLAN60 Subnet Resource","dependencies":[{"issue_id":"claude-bgf.4","depends_on_id":"claude-bgf","type":"parent-child","created_at":"2026-02-20T07:48:17Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-bgf.4","depends_on_id":"claude-bgf.3","type":"blocks","created_at":"2026-02-20T07:48:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-bgf.5","title":"Collaborator SSH-Zugang einrichten","description":"SSH-Zugang für 2-3 Collaborators via NetBird ACLs.\n\n## Steps\n- ACL-Gruppen im Dashboard anlegen: admin (alles), collaborators (SSH auf spezifische LXCs)\n- Setup Keys generieren (reusable, mit Expiry)\n- Onboarding-Anleitung schreiben: NetBird installieren → Setup Key → SSH-Config\n- Anleitung per Chat teilbar\n\n## ACL-Regeln\n- collaborators → zugewiesene LXCs, nur Port 22\n- admin → alles (192.168.60.0/24)\n- Zuweisungen änderbar im Dashboard wenn Collaborator auf anderes LXC wechselt\n\n## Acceptance Criteria\n- [ ] Test-Collaborator kann nach NetBird-Install per SSH auf zugewiesenes LXC\n- [ ] Kein Zugriff auf andere LXCs/Services\n- [ ] Onboarding-Anleitung vorhanden","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:48:26Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:27Z","closed_at":"2026-02-25T13:48:47Z","close_reason":"Vorerst nicht benötigt, wird bei Bedarf eingerichtet","dependencies":[{"issue_id":"claude-bgf.5","depends_on_id":"claude-bgf","type":"parent-child","created_at":"2026-02-20T07:48:26Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-bgf.5","depends_on_id":"claude-bgf.2","type":"blocks","created_at":"2026-02-20T07:48:41Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-bgf.5","depends_on_id":"claude-bgf.3","type":"blocks","created_at":"2026-02-20T07:48:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-bgf.6","title":"DreamMachine Port Forwards entfernen","description":"Port Forwards 80/443 von der UniFi DreamMachine entfernen.\n\n## Steps\n- Aktuelle Port Forward Rules dokumentieren (Screenshot)\n- 80/443 NAT-Rules entfernen\n- DreamMachine WireGuard VPN bleibt für Internal-only (Plex, *arr)\n- Verifizieren dass alle Services weiterhin über NetBird Reverse Proxy erreichbar sind\n\n## Acceptance Criteria\n- [ ] Keine Port Forwards auf DreamMachine (außer WireGuard UDP)\n- [ ] Public/Personal Services weiterhin erreichbar über NetBird\n- [ ] Plex/*arr weiterhin über DreamMachine WireGuard VPN erreichbar\n- [ ] Port-Scan von außen zeigt 80/443 geschlossen","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:48:34Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:28Z","closed_at":"2026-02-25T13:48:47Z","close_reason":"6 alte DNS A-Records (sussdorff.de) gelöscht, Port Forwards 80/443 auf DreamMachine entfernt. Services laufen über *.sussdorff.org via NetBird Reverse Proxy","dependencies":[{"issue_id":"claude-bgf.6","depends_on_id":"claude-bgf","type":"parent-child","created_at":"2026-02-20T07:48:34Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-bgf.6","depends_on_id":"claude-bgf.4","type":"blocks","created_at":"2026-02-20T07:48:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-c6c","title":"Monitoring: DNS-Eintrag und Reverse Proxy für Grafana","description":"## Hintergrund\nGrafana ist nur über IP erreichbar (http://192.168.60.23:3000). \nFür bessere Erreichbarkeit DNS-Eintrag und ggf. Reverse Proxy einrichten.\n\n## Akzeptanzkriterien\n- [ ] DNS-Eintrag für Grafana (z.B. grafana.sussdorff.de oder monitoring.sussdorff.de)\n- [ ] Reverse Proxy Entry in LXC 102 (Caddy) konfiguriert\n- [ ] HTTPS via Let's Encrypt","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:56:28Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:32Z","closed_at":"2026-02-20T06:50:02Z","close_reason":"Ersetzt durch claude-bgf.4 (Reverse Proxy Services konfigurieren) im NetBird Epic — Grafana wird über NetBird Reverse Proxy erreichbar"}
{"id":"claude-c8c","title":"Jellyfin Media Server als LXC","description":"LXC Container mit Jellyfin Media Server + arr-Stack aufsetzen.\n\n## Kontext\n- 890M iGPU fuer Hardware-Transcoding (VAAPI)\n- ~3.8 TB Storage verfuegbar auf NVMe\n- Kein GPU-Passthrough noetig, VAAPI geht ueber LXC Device-Mapping\n\n## Media-Quellen (Migration von Solaris)\n\n### Kursvideos (Backup! Kurse verschwinden gern)\n- ~/Movies/Tischlern/ (40 GB) -- Holzarbeiten/Moebelbau Kurse\n- ~/Movies/Docker/ (14 GB) -- Docker Kursvideos\n- ~/Movies/16-01 Silva Life System 2.0/ (312 MB)\n- ~/Movies/Unraid/ (631 MB)\n- ~/code/agenticcoding.school/ -- AgenticSchool Kursvideos (Backup)\n- ~/code/indydevdan/ -- IndyDevDan Kurse (2 Kurse, Backup)\n\n### Persoenliche Videos\n- ~/Movies/Dance Movies/ (62 GB) -- Tanzworkshop-Aufnahmen 2007-2013\n- ~/Movies/Filmchen/ (11 GB) -- persoenliche Videos\n- ~/Movies/Queen Mary 2010/ (2 GB)\n\n### TV/Serien\n- ~/Movies/TV/ (32 GB) -- aufgenommene Serien\n\n### Gesamt: ~160+ GB von Solaris zu migrieren\n\n## Storage-Strategie\n- Kursvideos + persoenliche Videos: NVMe (schneller Zugriff) oder DAS (Platz)\n- Bei DAS: /mnt/das/media/courses/, /mnt/das/media/personal/, /mnt/das/media/tv/\n- Jellyfin Libraries: Kurse, Persoenlich, TV als separate Bibliotheken\n\n## Domain\nmedia.sussdorff.de oder jellyfin.sussdorff.de (Hetzner DNS, Caddy, Let's Encrypt)\n\n## Akzeptanzkriterien\n- [ ] LXC Container erstellt\n- [ ] Jellyfin installiert mit VAAPI Hardware-Transcoding\n- [ ] Sonarr + Radarr + Prowlarr installiert\n- [ ] Download-Client (z.B. qBittorrent oder SABnzbd)\n- [ ] Kursvideos migriert und als 'Kurse' Library in Jellyfin\n- [ ] Persoenliche Videos migriert\n- [ ] AgenticSchool + IndyDevDan Kurse gesichert\n- [ ] Von lokalem Netz + extern erreichbar\n- [ ] Autostart konfiguriert\n- [ ] Backup der Kursvideos auf DAS (nicht wiederbeschaffbar!)","notes":"LXC setup-skripte + docker-compose (Jellyfin+Sonarr+Radarr+Prowlarr+qBittorrent) + deploy.sh erstellt (lxc/jellyfin/). GPU-Passthrough für VAAPI konfiguriert. Caddy-Entry für media.sussdorff.de. Nächster Schritt: setup-lxc.sh auf Proxmox, dann deploy.sh, dann Medien von Solaris migrieren.\nqBittorrent durch SABnzbd ersetzt (User präferiert Usenet/Message Boards statt Torrent). Kein Port-Forwarding für 6881 nötig.\nDeployed und verifiziert. 5/5 Services laufen (Jellyfin healthy, Sonarr, Radarr, Prowlarr, SABnzbd). GPU /dev/dri verfügbar. Extern erreichbar unter https://media.sussdorff.de (HTTP 302 -\u003e Setup Wizard).\nWeb-Setup abgeschlossen. Server 'Elysium', Admin: malte. GPU VAAPI verfügbar. SABnzbd statt qBittorrent. Medien noch nicht migriert.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-15T12:46:17Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:30Z","closed_at":"2026-02-17T02:50:30Z","close_reason":"LXC 106 deployed, Jellyfin+Sonarr+Radarr+Prowlarr+SABnzbd laufen, GPU VAAPI OK. Admin: malte. Medien noch nicht migriert (separater Bead).","labels":["epic:claude-k6i"],"work_type":"mutex"}
{"id":"claude-ckb","title":"Gastown: Claude Code Remote Control on Hokora VM","description":"Set up Claude Code Remote Control as a persistent, always-on orchestrator session ('Gastown Mayor') on Hokora VM (201, 192.168.60.51). This enables connecting to long-running CC sessions from MacBook, iPhone (Claude App), or any browser via claude.ai/code.\n\n## Motivation\n- Move software development workload off MacBook onto always-on Proxmox VM\n- Enable phone-based interaction with running dev sessions (review, approve, kick off work)\n- Gastown mayor session can run 24/7, surviving MacBook sleep/network changes\n- Shikigami-bot can trigger work via beads; mayor picks it up without programmatic claude invocation\n\n## Architecture\n- Hokora VM runs Claude Code in tmux with remote-control enabled\n- Outbound HTTPS only to Anthropic API (message routing)\n- Connect from MacBook (SSH+RC), iPhone (Claude App QR), browser (claude.ai/code)\n- DOLT server on Services-VM (192.168.60.30:3307) provides shared beads state\n- claude-mem worker on Services-VM (192.168.60.30:37777) provides shared memory\n\n## Acceptance Criteria\n- [ ] Claude Code installed and authenticated on Hokora VM (claude /login with Pro/Max account)\n- [ ] Remote Control enabled globally via /config on Hokora\n- [ ] tmux session 'gastown' auto-starts on boot (systemd unit or cron @reboot)\n- [ ] Auto-restart wrapper for remote-control reconnection after \u003e10min network drop\n- [ ] Successfully connect from Claude mobile app via QR code\n- [ ] Successfully connect from browser via claude.ai/code\n- [ ] Verify beads sync works (DOLT on Services-VM reachable from Hokora)\n- [ ] Verify claude-mem shared memory works from Hokora\n- [ ] Document connection workflow in docs/","notes":"Deployed infrastructure: bd v0.56.1 installed on Hokora, Dolt env configured in .bashrc, gastown.sh wrapper + systemd service enabled. TCP to Dolt (192.168.60.30:3307) verified. claude-mem worker reachable. Blocking: claude auth login requires interactive browser OAuth.\nGastown (gt v0.7.0) deployed on Hokora: HQ at ~/gt/, bd v0.56.1, Claude Code v2.1.56 authenticated, beads Dolt connected to 192.168.60.30:3307. Auto-update cron daily 4am. Generic deploy scripts moved to github.com/sussdorff/gastown-vm (private repo).","status":"in_progress","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-25T07:16:18Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:31Z","dependencies":[{"issue_id":"claude-ckb","depends_on_id":"claude-cqf","type":"blocks","created_at":"2026-02-25T10:58:27Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-ckb","depends_on_id":"claude-l5n","type":"blocks","created_at":"2026-02-25T07:20:59Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-ckb","depends_on_id":"claude-xly","type":"blocks","created_at":"2026-02-25T07:17:01Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-cqf","title":"Dolt Server absichern + via NetBird/Traefik TCP öffentlich exponieren","description":"Dolt SQL Server (LXC 116, 192.168.60.30:3307) für Cloud-Zugriff (Claude Code Remote, Gastown) absichern und über Hetzner VPS exponieren.\n\n## Ist-Zustand\n- Dolt läuft ohne Auth (root, kein Passwort)\n- Kein TLS\n- Nur auf VLAN 60 erreichbar\n- Beads verbindet sich via MySQL wire protocol (kein HTTP)\n- NetBird Reverse Proxy ist HTTP-only (Traefik) → kein direkter MySQL-Proxy möglich\n\n## Lösung: Traefik TCP Router auf Hetzner VPS\nNetBird's built-in Reverse Proxy kann kein TCP/MySQL. Stattdessen: Traefik TCP Entrypoint auf dem VPS, der über den NetBird WireGuard-Tunnel zu 192.168.60.30:3307 routet.\n\n## Schritte\n\n### 1. Dolt absichern (LXC 116)\n- [ ] MySQL User mit Passwort anlegen (mindestens: `beads_cloud` für Remote, `beads_local` für VLAN)\n- [ ] TLS aktivieren (tls_key + tls_cert in config.yaml, Let's Encrypt oder self-signed)\n- [ ] `require_secure_transport: true` setzen\n- [ ] Credentials in 1Password ablegen\n\n### 2. Traefik TCP Router auf Hetzner VPS\n- [ ] TCP Entrypoint für Port 3307 in bestehender Traefik-Config hinzufügen\n- [ ] TCP Router mit TLS passthrough zu NetBird Peer (Elysium Routing Peer → 192.168.60.30:3307)\n- [ ] DNS: `dolt.cognovis.de` A-Record auf VPS IP\n- [ ] Firewall: Port 3307 nur von bekannten IPs oder offen (TLS+Auth schützt)\n\n### 3. Beads-Clients umstellen\n- [ ] Lokale Clients: BEADS_DOLT_PASSWORD + BEADS_DOLT_SERVER_TLS setzen\n- [ ] Cloud/Remote Clients: host=dolt.cognovis.de, gleiche Auth\n- [ ] Hokora VM (Gastown): Settings aktualisieren\n- [ ] Verifizieren: `bd dolt test` von lokal + remote\n\n## Beads-Kompatibilität (verifiziert)\nBeads v0.55.4 unterstützt alle nötigen Env Vars:\n- BEADS_DOLT_PASSWORD\n- BEADS_DOLT_SERVER_TLS\n- BEADS_DOLT_SERVER_HOST/PORT/USER/DATABASE","notes":"Traefik TCP router (port 3307) verified working end-to-end: Mac → dolt.cognovis.de:3307 → VPS Traefik → NetBird tunnel → LXC 116. DNS dolt.cognovis.de → 46.224.133.69 confirmed. MySQL users root/beads_local/beads_cloud all have passwords. TLS on Dolt itself still outstanding.","status":"in_progress","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-25T10:58:17Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:31Z","dependencies":[{"issue_id":"claude-cqf","depends_on_id":"claude-bgf","type":"blocks","created_at":"2026-02-25T10:58:33Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-dlh","title":"Audible Hör-History in Audiobookshelf importieren","description":"## Ziel\nBereits bei Audible gehörte Bücher in Audiobookshelf als 'finished' markieren.\n\n## Ansatz\n1. Libation DB (LibationContext.db auf LXC 110) enthält Audible-Bibliothek mit Status-Info\n2. Script schreiben: Libation DB auslesen → gehörte Bücher identifizieren → per Audiobookshelf API als finished markieren\n3. Alternative falls Libation keinen finished-Status hat: Audible Library Extractor Chrome Extension\n\n## Recherche nötig\n- [ ] Libation DB Schema prüfen: gibt es ein 'listened'/'finished' Feld?\n- [ ] Audiobookshelf API: wie markiert man ein Buch als finished? (PATCH /api/me/progress/{itemId})\n- [ ] Matching: Libation ASIN → Audiobookshelf Item (über Dateiname oder ASIN-Metadaten)\n\n## Akzeptanzkriterien\n- [ ] Alle bei Audible gehörten Bücher in Audiobookshelf als finished markiert\n- [ ] Script wiederholbar (für zukünftige Bücher)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T13:38:46Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:32Z","closed_at":"2026-02-17T14:01:15Z","close_reason":"72/90 ASIN-matchable ABS items marked as finished. Script sync-read-status.py deployed. LXC 110 disk resized 204G→512G. ASIN enrichment for remaining 62 items deferred to claude-vsx."}
{"id":"claude-e2r","title":"[EPIC] Session Close Protocol v2: CalVer + Changelog + Release Workflow","description":"Erweitertes Session Close Protokoll das über git commit/push hinausgeht:\n- CalVer Versionierung (YYYY.0M.MICRO)\n- git-cliff Changelog-Generierung\n- Doku-Check vor Close\n- Learnings-Extraktion automatisch\n- Security/Test-Review\n- Globaler Skill in malte/ (sofort überall nutzbar)\n\nEntscheidungen:\n- Versioning: CalVer YYYY.0M.MICRO\n- Release-Trigger: Bei Session Close\n- Changelog: git-cliff\n- Scope: Globaler Skill in code/claude/malte/","status":"open","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T02:07:53Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:33Z","labels":["decision"],"dependencies":[{"issue_id":"claude-e2r","depends_on_id":"claude-kiq","type":"blocks","created_at":"2026-02-26T02:09:23Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-e2r","depends_on_id":"claude-l31","type":"blocks","created_at":"2026-02-26T02:09:19Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-e2r","depends_on_id":"claude-oii","type":"blocks","created_at":"2026-02-26T02:09:20Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-e2r","depends_on_id":"claude-pog","type":"blocks","created_at":"2026-02-26T02:09:16Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-e2r","depends_on_id":"claude-qeu","type":"blocks","created_at":"2026-02-26T02:09:21Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-e2r","depends_on_id":"claude-uwm","type":"blocks","created_at":"2026-02-26T02:09:18Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-e41","title":"Post-Import Archivierung: Quelldateien auf PRO-G40 verschieben","description":"## Pattern für alle Elysium-Imports\n\nNach erfolgreichem Import auf Elysium werden die Quelldateien von Solaris auf PRO-G40 verschoben.\nDies befreit lokalen Speicher und dokumentiert was bereits importiert wurde.\n\n## Zielstruktur auf PRO-G40\n\n```\n/Volumes/PRO-G40/Imported-to-Elysium/\n├── .README.md                    # Erklärt das Pattern\n├── Comics/                       # \u003c- Komga (claude-eg7, DONE)\n│   ├── Chunky/                   # 8 GB\n│   ├── Hugo-Graphic/             # 9 GB\n│   └── .manifest.json            # Datum, Ziel-LXC, Dateiliste\n├── Books/                        # \u003c- Calibre-Web (claude-uvj)\n│   ├── Hugo/                     # 73 GB (nur EPUB/MOBI, keine Audio/Graphic)\n│   ├── INBOX-Books/              # 6.1 GB\n│   ├── Calibre-Bibliothek/       # 57 MB\n│   ├── Agile-Training/           # 4.6 GB\n│   └── .manifest.json\n├── Audiobooks/                   # \u003c- Audiobookshelf (claude-oza)\n│   ├── iCloud-Audiobooks/        # 11 GB\n│   ├── Hugo-Audiobooks/          # ~43 GB (Fiction-Kategorien)\n│   ├── Maze-of-Games/            # 1.1 GB\n│   └── .manifest.json\n├── Media/                        # \u003c- Jellyfin (claude-9p1)\n│   ├── Kurse/                    # 70-75 GB\n│   ├── Persoenlich/              # 80 GB\n│   ├── TV/                       # 32 GB\n│   └── .manifest.json\n├── Photos/                       # \u003c- Immich (claude-01a)\n│   ├── Event-Collections/        # 4 GB (Play4Agile, RFG2023, etc.)\n│   ├── Syndication/              # 1.1 GB\n│   └── .manifest.json            # Hauptbibliothek via iOS App, nicht hier\n└── Documents/                    # \u003c- Paperless-ngx (claude-fyv)\n    ├── Reviewed-Batches/         # Stapelweise nach Review\n    └── .manifest.json\n```\n\n## .manifest.json Format\n\n```json\n{\n  \"service\": \"Komga\",\n  \"target_lxc\": \"112 (192.168.60.22)\",\n  \"imported_date\": \"2026-02-17\",\n  \"source_paths\": [\n    \"~/Library/Mobile Documents/iCloud~com~mike-ferenduros~Chunky-Comic-Reader/Documents/\",\n    \"~/Hugo/Hugo {2016-2025}/*Graphic*/\"\n  ],\n  \"total_size_gb\": 17,\n  \"file_count\": 155,\n  \"bead_id\": \"claude-eg7\"\n}\n```\n\n## Workflow pro Service\n1. Import auf Elysium abschließen und verifizieren\n2. Quelldateien nach PRO-G40/Imported-to-Elysium/{Service}/ kopieren (rsync)\n3. .manifest.json erstellen\n4. Verifizieren: Dateizahl + Größe stimmen\n5. Quelldateien von Solaris löschen\n\n## Sofort umsetzbar (Import bereits done)\n- [x] Comics (claude-eg7) — 17 GB Chunky + Hugo Graphic\n\n## Nach Import umsetzbar\n- [ ] Books (claude-uvj)\n- [ ] Audiobooks (claude-oza)\n- [ ] Media (claude-9p1)\n- [ ] Photos (claude-01a) — nur Event-Collections, Hauptbibliothek via iOS\n- [ ] Documents (claude-fyv)\n\n## Akzeptanzkriterien\n- [ ] PRO-G40 Verzeichnisstruktur angelegt\n- [ ] README.md mit Pattern-Dokumentation\n- [ ] Comics-Quelldateien verschoben + Manifest\n- [ ] Alle Import-Beads referenzieren dieses Archivierungs-Pattern","notes":"Comics-Archivierung abgeschlossen: 70 Chunky-Dateien + Hugo Graphic Stories auf PRO-G40 verschoben, Quelldateien gelöscht. Tachimanga als iPad-Reader konfiguriert (direkte Komga-API, kein OPDS nötig). Chunky iCloud-Ordner geleert (~8.4 GB befreit).","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T04:14:48Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","labels":["epic:claude-k6i"]}
{"id":"claude-ecz","title":"[EPIC] piler-cli: Mail-Archiv CLI für Mailpiler","description":"Python/UV/Click CLI zum Suchen, Lesen und Exportieren von archivierten Mails aus Mailpiler. Zugriffskette: SSH → pct exec 111 → docker exec (Manticore/MySQL/pilerget). Eigenes Repo ~/code/piler-cli/. Companion-Skill als dünner Wrapper.","status":"open","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:26:56Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:35Z"}
{"id":"claude-eg7","title":"Komga: Comic-Import (~17GB, Chunky + Hugo Graphic Stories)","description":"## Quellen (auf Solaris/MacBook)\n\n### 1. Chunky Comic Reader / iCloud (8 GB, 71 Dateien)\n- Pfad: ~/Library/Mobile Documents/iCloud~com~mike-ferenduros~Chunky-Comic-Reader/Documents/\n- Formate: CBR (47), PDF (19), CBZ (4), EPUB (1)\n- Serien:\n  - Monstress (Liu \u0026 Takeda) — CBR/CBZ + PDF Vol 5-6 (~20 Issues)\n  - Critical Role (Vox Machina Origins III, Bright Queen, Chronicles, Mighty Nein) — CBR/PDF/EPUB (~15)\n  - Far Sector — CBR (8)\n  - Y: The Last Man — CBR (4 Books)\n  - Paper Girls (Vaughan) Vol 1-6 — PDF (6)\n  - Die (Gillen \u0026 Hans) Vol 1-4 — PDF (4)\n  - Once \u0026 Future (Gillen \u0026 Mora) — PDF (1)\n  - Invisible Kingdom (Wilson \u0026 Ward) — PDF (1)\n  - The Witcher Omnibus — PDF (1)\n  - D\u0026D: Evil at Baldur's Gate — CBR (1)\n\n### 2. Hugo Awards Graphic Stories (~9 GB, 102 Dateien)\n- Pfad: ~/Hugo/Hugo {2016-2025}/\\*Graphic\\*/\n- Formate: Überwiegend PDF, einige EPUB/MOBI\n- Jahrgänge: 2016-2022, 2024-2025\n- Größte: Hugo 2020 (3.2 GB), Hugo 2021 (2.2 GB), Hugo 2024 (1.3 GB)\n\n## Ordnerstruktur in Komga\n```\n/data/\n├── Serien/\n│   ├── Monstress/\n│   ├── Critical Role/\n│   ├── Far Sector/\n│   ├── Y The Last Man/\n│   ├── Paper Girls/\n│   ├── Die/\n│   └── ...\n└── Hugo Graphic Story/\n    ├── 2016/\n    ├── 2017/\n    └── ...\n```\n\n## Migrationsstrategie\n1. Chunky-Comics per rsync transferieren, nach Serie sortieren\n2. Hugo Graphic Stories nach Jahr organisiert transferieren\n3. Keine PDF-\u003eCBZ Conversion nötig (Komga unterstützt beides nativ)\n4. Duplikate zwischen Chunky und Hugo prüfen (z.B. Monstress, Far Sector)\n\n## Transfer\nrsync/scp nach Komga Docker Volume /data/\n\n## Akzeptanzkriterien\n- [ ] Alle Chunky-Comics nach Serien sortiert importiert\n- [ ] Hugo Graphic Stories nach Jahr importiert\n- [ ] Duplikate bereinigt\n- [ ] Komga zeigt alle Comics mit korrekten Metadaten\n- [ ] OPDS-Feed in Chunky auf iPad getestet","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:15:13Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:36Z","closed_at":"2026-02-17T03:37:41Z","close_reason":"Comics transferred and organized. 155 files (~17GB) across 2 libraries: Serien (10 series, 69 books) and Hugo Graphic Story (9 years, 86 books). Komga admin user created (malte@sussdorff.de), libraries configured, scan triggered.","labels":["epic:claude-k6i"],"dependencies":[{"issue_id":"claude-eg7","depends_on_id":"claude-727","type":"blocks","created_at":"2026-02-17T04:15:18Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-eol","title":"[REFACTOR] NetBird VPS: IaC Setup-Scripts nachholen","description":"NetBird VPS auf Hetzner CX23 — Dokumentation und IaC nachholen.\n\n## Server-Steckbrief\n- **Hostname**: netbird\n- **IP**: 46.224.133.69 (IPv6: 2a01:4f8:c010:b22b::1)\n- **OS**: Ubuntu 24.04.4 LTS (Kernel 6.8.0-90-generic)\n- **Hardware**: Hetzner CX23 — 2 vCPU, 4 GB RAM, 40 GB Disk (9% belegt)\n- **Backup**: Hetzner Backup aktiviert\n- **Domain**: netbird.cognovis.de\n\n## SSH-Zugang\n- **Config**: ~/.ssh/config.d/netbird (Host netbird → root@netbird.cognovis.de)\n- **Key**: ~/.ssh/id_ed25519 (ED25519, passwortgeschützt — braucht SSH-Agent)\n- **Befehl**: `ssh netbird`\n\n## Software\n- **NetBird**: v0.65.3 (Server + Client)\n- **fail2ban**: 1.0.2 (aktiv)\n- **Docker**: 4 Container (netbird-server, netbird-dashboard, netbird-traefik, netbird-proxy)\n- **Compose-Datei**: /opt/docker-compose.yml\n\n## UFW Firewall\n- 22/tcp (SSH), 80/tcp, 443/tcp, 10000/tcp, 3478/udp, 49152:65535/udp\n- Default: deny incoming, allow outgoing\n\n## Docker-Netzwerk\n- Bridge: 172.30.0.0/24 (netbird)\n- Traefik: 172.30.0.10 (trusted proxy für Proxy Protocol)\n\n## Konfigurationsdateien (alle unter /opt/)\n- docker-compose.yml — Container-Orchestrierung\n- config.yaml — NetBird Server Config (Auth, STUN, Store)\n- dashboard.env — Dashboard OIDC Config (embedded IdP)\n- proxy.env — Reverse Proxy Config (Token, Domain, ACME)\n- traefik-dynamic.yaml — Traefik Dynamic Config\n\n## Secrets\n- Proxy Token: proxy.env (NB_PROXY_TOKEN)\n- Auth Secret: config.yaml (server.authSecret)\n- Admin Login: 1Password 'NetBird' in Vault 'API Keys'\n- PAT: 1Password 'NetBird' Access token Feld\n\n## Gap (noch offen)\n- Kein `vps/netbird/setup.sh` — Server wurde manuell via bgf.1/bgf.2 aufgesetzt\n- Kein deploy.sh im Repo\n- hcloud CLI Context nicht konfiguriert (API Token aus 1Password)","notes":"## Stand 2026-02-25\n\n### Erledigt\n- SSH config Entry: ~/.ssh/config.d/netbird ✅\n- Config im Repo: vps/netbird/ ✅\n  - docker-compose.yml — Container-Orchestrierung\n  - config.yaml — Server Config (Secrets durch op:// Refs ersetzt)\n  - dashboard.env — Dashboard OIDC Config\n  - proxy.env — Proxy Config (Token durch op:// Ref ersetzt)\n  - traefik-dynamic.yaml — Proxy Protocol Config\n- setup.sh — Frisch-Installation eines VPS von null ✅\n- deploy.sh — Config-Update auf bestehenden Server ✅\n- Hetzner Backup aktiviert ✅\n\n### Hinweise\n- config.yaml und proxy.env im Repo enthalten op:// Referenzen statt echter Secrets\n- Die echten Secrets liegen nur auf dem Server und in 1Password (Vault: API Keys, Item: NetBird)\n- deploy.sh deployed nur non-secret Configs (docker-compose, traefik-dynamic, dashboard.env)\n- Secret-Dateien müssen manuell oder via setup.sh deployed werden\n\n### Noch offen\n- hcloud CLI Context konfigurieren (API Token aus 1Password)","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-25T10:37:27Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:36Z"}
{"id":"claude-fc0","title":"[DISCOVERY] Backup-Festplatte (4TB) inventarisieren vor DAS-Migration","description":"## Ziel\nInhalt der Backup-Festplatte (/Volumes/Backup, 3.6TB, 98% voll) pruefen bevor die WD-Platten ins DAS-Gehaeuse wandern. Sicherstellen dass keine Daten verloren gehen die nicht auf Solaris (2TB MacBook) liegen.\n\n## Hintergrund\n- Malte ist von einem 4TB Aura MacBook auf Solaris (2TB) gewechselt\n- Moeglich dass Daten aus ~/ nicht vollstaendig migriert wurden\n- Vermutlich viel Steam/Crossover, aber unklar ob noch anderes drauf liegt\n- Backup-Platte enthaelt auch das alte Windows-Disk-Image von Elysium\n\n## Auch vorhanden: PRO-G40 SSD\n- /Volumes/PRO-G40 (3.6TB, 508 GB belegt, 14%)\n- Inhalt ebenfalls pruefen\n\n## Vorgehen\n1. DaisyDisk Scan auf /Volumes/Backup ausfuehren\n2. Export/Screenshot des Ergebnisses\n3. Kategorisieren: Was ist Steam/Games, was ist Windows-Image, was sind persoenliche Daten\n4. Persoenliche Daten identifizieren die NICHT auf Solaris existieren\n5. Diese Daten sichern (auf NVMe/Elysium oder PRO-G40) bevor Platten formatiert werden\n6. Entscheidung: Windows-Image behalten oder loeschen?\n\n## Akzeptanzkriterien\n- [ ] DaisyDisk Scan abgeschlossen\n- [ ] Alle einzigartigen Daten identifiziert\n- [ ] Einzigartige Daten gesichert\n- [ ] Platte freigegeben fuer DAS-Einbau","notes":"## Erkenntnisse aus Backup-Analyse (2026-02-16)\n\nBereits bekannte Inhalte auf der Backup-Platte:\n- **Musik-Sammlung** → Wird nach Navidrome auf Elysium migriert (siehe claude-3bi)\n- **Steam + Crossover** (~750GB) → Gaming-Daten, behalten oder extern archivieren\n- **Orca** (Parallels VM) → Obsolet, kann gelöscht werden\n- **Podman** → Nicht mehr benötigt (Docker auf Elysium), kann gelöscht werden\n\nLokal auf Solaris in ~/Documents vorhanden (NICHT auf Backup-Platte):\n- **Knox** (verschlüsselte Sparsebundles) → Lokale verschlüsselte Archive\n- **EagleFiler** → Mac-basiertes Archivierungstool\n- **MailSteward** → Mail-Archive, potenziell nach Mailpiler konsolidierbar\n- Diese Mac-spezifischen Archive sind ein separates Thema für spätere Konsolidierung\nAlle Daten von Backup-Platte auf PRO-G40 gesichert: Music (68GB), Steam (336GB merged), CrossOver (454GB). PRO-G40 jetzt 1.6TB/3.6TB belegt.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T10:22:53Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","closed_at":"2026-02-17T19:07:16Z","close_reason":"Music, Steam, CrossOver auf PRO-G40 gesichert. Backup-Platte kann für DAS-Einbau freigegeben werden.","labels":["epic:claude-k6i"]}
{"id":"claude-flv","title":"[LEARNING] Always verify live system state before reporting task status","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T05:19:52Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:38Z","closed_at":"2026-02-22T06:00:21Z","close_reason":"Materialisiert: CLAUDE.md 'Verify Before Reporting' (merged flv+j9g)","labels":["learning","learning:correction","scope:global"]}
{"id":"claude-fvh","title":"Monitoring: Paperless-ngx in Prometheus + Grafana aufnehmen","description":"## Scope\nPaperless-LXC ins bestehende Monitoring integrieren.\n\n## Vorgehen\n1. node_exporter Target in prometheus.yml hinzufügen\n2. Blackbox HTTP Probe für Paperless Web-UI\n3. Grafana Dashboard aktualisieren (Node Detail reicht, kein Custom-Dashboard)\n4. Deploy-Script deploy-node-exporter.sh auf neues LXC anwenden\n\n## Akzeptanzkriterien\n- [ ] node_exporter Metrics in Prometheus sichtbar\n- [ ] Blackbox Probe grün\n- [ ] Alert bei Paperless Down","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T07:43:52Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:39Z","closed_at":"2026-02-19T07:12:32Z","close_reason":"Paperless war bereits in Prometheus + Grafana konfiguriert (node_exporter, Blackbox Probe, cAdvisor). Kein zusaetzlicher Aufwand noetig.","labels":["epic:claude-6wa"],"dependencies":[{"issue_id":"claude-fvh","depends_on_id":"claude-jf2","type":"blocks","created_at":"2026-02-18T08:43:59Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-fyv","title":"Paperless-ngx: Dokumenten-Import und Bereinigung","description":"## Kontext\nDokumente auf Solaris sind teilweise falsch einsortiert (fehlerhafte Hazel-Regeln).\nJedes Dokument muss vor dem Import reviewed werden:\n- Korrekte Zuordnung/Tagging\n- OCR wo fehlend\n- Bereinigung von falschen Dateinamen\n\n## Vorgehen\n1. Dokumenten-Ordner auf Solaris inventarisieren\n2. Paperless Tag/Correspondent-Struktur planen\n3. Review-Workflow definieren: Wie prüfen wir jedes Dokument?\n4. Import in Batches mit korrektem Tagging\n5. OCR für Dokumente ohne Text-Layer nachholen (Paperless macht das automatisch via Tika)\n\n## Paperless Features nutzen\n- consume/ Ordner für automatischen Import\n- Ordner-basierte Tags (PAPERLESS_CONSUMER_SUBDIRS_AS_TAGS=true)\n- OCR automatisch (deu+eng konfiguriert)\n- Correspondent/Tag-Erkennung trainierbar\n\n## Offene Fragen\n- Welche Ordnerstruktur soll als Tag-Basis dienen?\n- ScanSnap-Anbindung an Paperless (consume-Ordner)?\n- Workflow für Dokument-Review (manuell vs. KI-assistiert)?\n\n## Akzeptanzkriterien\n- [ ] Dokumenten-Inventar erstellt\n- [ ] Tag/Correspondent-Struktur definiert\n- [ ] Erste Batch importiert und reviewed\n- [ ] OCR für alle Dokumente vorhanden\n- [ ] ScanSnap an Paperless consume-Ordner angebunden","notes":"POST-IMPORT ARCHIVIERUNG: Nach erfolgreichem Import Quelldateien auf PRO-G40 verschieben (Pattern: claude-e41). Ziel: /Volumes/PRO-G40/Imported-to-Elysium/{Service}/ mit .manifest.json. Befreit lokalen Speicher auf Solaris und dokumentiert Import-Status.","status":"open","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:03:29Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","labels":["epic:claude-6wa","epic:claude-k6i"],"dependencies":[{"issue_id":"claude-fyv","depends_on_id":"claude-jf2","type":"blocks","created_at":"2026-02-18T08:43:59Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-fyz","title":"Ignis Demo-System von Hetzner nach Elysium migrieren","description":"Docker-Compose-Stack (Ignis) von ignis-hackathon (Hetzner CX53) nach Elysium Proxmox umziehen.\n\n## Was läuft auf Hetzner (167.235.236.238)\n- nginx (Reverse Proxy, SSL auf 80/443)\n- Next.js Frontend (Port 3000)\n- Bun API Backend (Port 3001) - nutzt ElevenLabs, OpenAI, Twilio\n- Aidbox FHIR Server (Port 8080)\n- PostgreSQL 16 (Aidbox DB)\n- Docker-Compose config: /opt/ignis/docker-compose.yaml\n- Synthea-Daten unter /opt/synthea-data\n\n## Ressourcen\n- Aktuell: CX53 (30 GB RAM) - massiv oversized, nutzt ~1.2 GB\n- Kosten: ~36 EUR/Monat (~430 EUR/Jahr)\n- Real benötigt: ~4 GB RAM, minimal CPU\n\n## Akzeptanzkriterien\n- [ ] LXC oder VM auf Elysium mit Docker\n- [ ] docker-compose.yaml + .env migriert\n- [ ] Aidbox PostgreSQL-Daten migriert (pg_dump/restore)\n- [ ] SSL-Zertifikate migriert oder neu erstellt\n- [ ] AIDBOX_BASE_URL auf neue Adresse angepasst\n- [ ] Stack läuft und ist erreichbar\n- [ ] Hetzner ignis-hackathon Server kann abgeschaltet werden","notes":"Netzwerk-Architektur geändert: vmbr1 als VLAN-aware Bridge auf nic1 konfiguriert. VLAN 10 (192.168.10.0/24) für Services. Proxmox hat 192.168.10.3 auf vmbr1.10. Ignis LXC wird 192.168.10.10. nic1 zeigt NO-CARRIER — physisches Kabel/UniFi Switch-Port muss noch verbunden werden.\nAnforderung: Ignis muss aus dem Internet erreichbar sein. Neues DMZ-Netz angelegt: VLAN 60, 192.168.60.0/24, Zone DMZ. Ignis LXC wird auf 192.168.60.10 statt 192.168.10.10. Port-Forwarding für 80/443 auf UniFi Dream Wall nötig. DNS: ignis.cognovis.de muss auf externe IP zeigen.\nDMZ VLAN 60 konfiguriert. Alle Dateien auf 192.168.60.x aktualisiert (setup-lxc.sh, docker-compose.yaml, docs). Switch Port: Native VLAN 10 + Tagged VLAN 60. vmbr1.60 existiert temporär auf Host (192.168.60.3) — nicht persistiert, da LXC tag=60 direkt über VLAN-aware bridge läuft.\nStack deployed und verifiziert. 5 Container laufen (nginx, frontend, api, aidbox, aidbox-db). 670 Patienten migriert. Erreichbar unter http://192.168.60.10/. Noch offen: Port-Forwarding im UniFi Gateway, DNS-Update ignis.cognovis.de, SSL.\nIgnis zurück auf VLAN 60 (192.168.60.10) — Services/DMZ Netz für gehostete Dienste. VLAN 10 ist Sussdorff (Familien-Netz). Reverse Proxy (LXC 102) übernimmt SSL-Terminierung.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-15T13:00:31Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:41Z","closed_at":"2026-02-15T16:51:05Z","close_reason":"Ignis auf LXC 101 (192.168.60.10, VLAN 60), 670 Patienten migriert, via Caddy Reverse Proxy unter https://ignis.cognovis.de erreichbar","work_type":"mutex"}
{"id":"claude-gn1","title":"Langfuse v3 + ClickHouse evaluieren","description":"Aktuell läuft Langfuse v2 (Postgres-only). v3 braucht ClickHouse, bringt aber schnellere Analytics. Evaluieren ob sich der Aufwand lohnt bei aktuellem Nutzungsvolumen (1 Bot, 1 User).","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T08:05:42Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:42Z"}
{"id":"claude-hn7","title":"Superpowers-Konzepte selektiv in Workflow integrieren","description":"Die besten Konzepte aus dem Superpowers Plugin (obra/superpowers) als Skills/Standards in den eigenen Workflow einbauen - NICHT das Plugin installieren, sondern die Ideen übernehmen.\n\n## Zu übernehmende Konzepte\n\n### 1. TDD Iron Law\n\"NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST\"\n- RED → Verify RED → GREEN → Verify GREEN → REFACTOR Cycle\n- 12 identifizierte Rationalisierungen warum man TDD überspringt + Gegenargumente\n- Als optionaler aber empfohlener Gate (nicht für jede Kleinigkeit erzwingen)\n\n### 2. Verification Before Completion\n\"NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE\"\n- Vor jeder Status-Behauptung: Kommando ausführen, Output prüfen, Exit Code checken\n- \"Should\", \"probably\", \"seems to\" als Red Flags\n- Satisfaction-Expressions (\"Great!\", \"Done!\") vor Verification als Warnung\n\n### 3. Subagent-Driven Development Pattern\n- Fresh Subagent pro Task mit Two-Stage Review\n- Controller extrahiert Tasks → Implementer-Subagent → Spec-Compliance-Review → Quality-Review\n- Sinnvoll für komplexe Features, nicht für kleine Änderungen\n\n### 4. Brainstorming Gate\n- Design-Approval vor jeder Implementierung (skalierbar nach Komplexität)\n- 2-3 Ansätze mit Trade-offs und Empfehlung\n- Design-Doc speichern und committen\n\n## Acceptance Criteria\n- [ ] TDD-Skill als Standard verfügbar (aktivierbar pro Projekt)\n- [ ] Verification-Standard als Default für alle Projekte\n- [ ] Subagent-Review-Pattern als Skill für komplexe Tasks\n- [ ] Brainstorming-Gate als optionaler Workflow-Schritt\n- [ ] Scale-Adaptive: Automatische Erkennung wann welcher Gate nötig ist","status":"open","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T01:56:55Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:42Z","labels":["epic:claude-59a"],"dependencies":[{"issue_id":"claude-hn7","depends_on_id":"claude-pa3","type":"blocks","created_at":"2026-02-26T01:57:52Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-j3g","title":"[LEARNING] Verify archive destination has files before deleting local sources after migration","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T05:20:13Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:43Z","closed_at":"2026-02-22T06:00:21Z","close_reason":"Materialisiert: CLAUDE.md 'Verify Before Deleting'","labels":["learning","learning:workflow","scope:global"]}
{"id":"claude-j9g","title":"[LEARNING] Don't guess container deployment status — check SSH/pct exec/docker ps","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T05:19:58Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:44Z","closed_at":"2026-02-22T06:00:21Z","close_reason":"Materialisiert: CLAUDE.md 'Verify Before Reporting' (merged flv+j9g)","labels":["learning","learning:correction","scope:global"]}
{"id":"claude-jf2","title":"Paperless-ngx LXC deployen (Docker Compose + Samba)","description":"## Scope\nNeues LXC auf Proxmox erstellen und Paperless-ngx deployen.\n\n## Vorgehen\n1. LXC erstellen (Debian 12, VLAN 60, ausreichend Disk für Dokumente)\n   - Vorschlag: LXC 114, IP 192.168.60.24\n   - RAM: 4GB (Paperless + OCR braucht Speicher)\n   - Disk: 64G initial (Dokumente sind klein, PDFs)\n   - 2 Cores\n\n2. Docker Compose Stack:\n   - paperless-ngx (latest)\n   - Redis (Broker)\n   - PostgreSQL (DB)\n   - Volumes für consume/, data/, media/, export/\n\n3. Paperless-Konfiguration:\n   - PAPERLESS_OCR_LANGUAGE=deu+eng\n   - PAPERLESS_CONSUMER_POLLING=10 (für SMB-Writes, inotify unreliable)\n   - PAPERLESS_CONSUMER_POLLING_DELAY=5\n   - PAPERLESS_TIME_ZONE=Europe/Berlin\n   - PAPERLESS_CONSUMER_SUBDIRS_AS_TAGS=true\n\n4. Samba installieren + Share konfigurieren:\n   - Share: [scaninput] → /opt/paperless/consume\n   - Dedizierter scanner-User\n   - SMB 2/3 (kein SMB1)\n\n5. node_exporter installieren (Monitoring-Integration)\n\n6. Deploy-Script nach lxc/paperless/ Pattern\n\n## Akzeptanzkriterien\n- [ ] LXC läuft, Paperless Web-UI erreichbar\n- [ ] Samba-Share erreichbar von VLAN\n- [ ] OCR funktioniert (deu+eng)\n- [ ] node_exporter im Prometheus Target\n- [ ] Deploy-Script reproduzierbar","notes":"NETZWERK: Paperless bleibt auf VLAN 60 (192.168.60.18, LXC 108 existiert bereits). ScanSnap auf VLAN 10 (Sussdorff, 192.168.10.20). Inter-VLAN Routing 10\u003c-\u003e60 ist aktiv (verifiziert). Scanner targetiert SMB-Share auf 192.168.60.18.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T07:43:37Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:45Z","closed_at":"2026-02-19T06:44:24Z","close_reason":"Paperless-ngx war bereits deployed (LXC 108, VLAN 60). Samba installiert + konfiguriert fuer ScanSnap WiFi-Scan. Consumer Polling aktiviert. RAM auf 4GB erhoeht. SMB-Share verifiziert (Mac -\u003e VLAN 60). Voller Flow getestet: SMB-Write -\u003e consume -\u003e Document ID 1 erstellt. Deploy-Script + smb.conf im Repo aktualisiert.","labels":["epic:claude-6wa"]}
{"id":"claude-jlq","title":"Audiobookshelf auf Elysium deployen (Hoerbuch-Server)","description":"## Ziel\nSelf-hosted Audible-Alternative. Hoerbuecher streamen, Fortschritt tracken, iOS App.\n\n## Ist-Zustand\n- Einige Audiobooks lokal (Documents/INBOX/Maze of Games etc.)\n- Audible-Account vorhanden (Buecher dort gekauft, DRM-geschuetzt)\n- Vermutlich auch Hoerbuecher in Apple Books\n\n## Schritte\n\n### Deployment\n1. LXC/Docker fuer Audiobookshelf auf Elysium\n2. Web-UI via Caddy (audiobooks.sussdorff.de oder listen.sussdorff.de)\n3. Storage: NVMe primaer, Backup auf DAS\n\n### Audible-Library Export\n4. Audible-Bibliothek exportieren (audible-cli oder OpenAudible)\n5. DRM entfernen und als M4B/MP3 speichern\n6. In Audiobookshelf importieren\n\n### Lokale Audiobooks\n7. Bestehende Audiobooks aus Documents/INBOX importieren\n8. Apple Books Hoerbuecher exportieren (falls vorhanden)\n\n### Mobile Setup\n9. Audiobookshelf iOS App installieren\n10. Streaming + Offline-Download testen\n11. Fortschritts-Sync zwischen Geraeten pruefen\n\n## Domain\naudiobooks.sussdorff.de (Hetzner DNS, Caddy, Let's Encrypt)\n\n## Ressourcen\n- RAM: ~256-512 MB\n- Disk: Abhaengig von Audiobook-Sammlung (Hoerbuecher sind gross, 500MB-2GB pro Buch)\n- CPU: Minimal (nur Streaming, kein Transcoding)\n\n## Akzeptanzkriterien\n- [ ] Audiobookshelf erreichbar unter audiobooks.sussdorff.de\n- [ ] Audible-Library exportiert und importiert\n- [ ] iOS App funktioniert (Streaming + Fortschritt)\n- [ ] Backup auf DAS","notes":"LXC setup-skripte + docker-compose + deploy.sh erstellt (lxc/audiobookshelf/). Caddy-Entry für audiobooks.sussdorff.de. Nächster Schritt: setup-lxc.sh auf Proxmox, deploy.sh, dann Audible-Export + Hörbuch-Import.\nDeployed und verifiziert. Audiobookshelf läuft. Extern erreichbar unter https://audiobooks.sussdorff.de (HTTP 200). Setup Wizard bereit.\nWeb-Setup abgeschlossen. Root-User: malte. v2.32.1 läuft. Hörbücher noch nicht importiert.","status":"closed","priority":3,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T10:14:32Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:46Z","closed_at":"2026-02-17T02:50:31Z","close_reason":"LXC 110 deployed, Audiobookshelf v2.32.1 läuft. Root-User: malte. Hörbücher noch nicht importiert (separater Bead).","labels":["epic:claude-k6i"]}
{"id":"claude-jua","title":"Mailpiler Import: MailSteward SQLite-Archive","description":"## Ziel\nHistorische E-Mails aus MailSteward SQLite-Datenbanken nach Mailpiler importieren.\n\n## Ist-Zustand\n- msq CLI (~/code/msq) kann MailSteward-DBs lesen und durchsuchen\n- Mehrere SQLite-DBs in ~/Documents (MailSteward-Format)\n- msq hat extract-Funktion für Anhänge\n\n## Vorgehen\n1. Inventur: Alle MailSteward-DBs auflisten (msq dbs)\n2. Statistiken pro DB erfassen (msq stats)\n3. Export-Pipeline: SQLite → EML-Dateien (msq extract oder custom Script)\n4. Import in Mailpiler via CLI oder API (piler-import Befehl)\n5. Verifizierung: Stichproben-Suche in Mailpiler vs. msq\n6. Deduplizierung: Mailpiler hat built-in Dedup\n\n## Abhängigkeiten\n- Mailpiler LXC muss deployed sein\n- msq muss funktionsfähig sein (Export-Tool)\n\n## Akzeptanzkriterien\n- [ ] Alle MailSteward-DBs identifiziert und gezählt\n- [ ] Export-Pipeline funktioniert (SQLite → EML)\n- [ ] Alle Mails in Mailpiler importiert\n- [ ] Stichproben-Verifizierung bestanden\n- [ ] Duplikate bereinigt","notes":"msq eml-export implementiert und gegen Nordex-DB (123 Mails) verifiziert. 136 Tests grün, 19 neue Tests. Nächster Schritt: pilerimport auf Proxmox-Server.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T11:20:42Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:47Z","closed_at":"2026-02-17T13:52:20Z","close_reason":"All 7 MailSteward DBs imported: 83,211 emails total in Mailpiler. Export errors: 48 DSN emails (0.05%). Pilerimport errors: only macOS ._resource forks (harmless). Calendar response emails (2,174) imported as regular mail.","dependencies":[{"issue_id":"claude-jua","depends_on_id":"claude-9fg","type":"blocks","created_at":"2026-02-16T12:20:54Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-jwb","title":"Claude Code + Gemini CLI auf Shikigami VM authentifizieren","description":"Claude Code und Gemini CLI auf der Shikigami Proxmox VM (192.168.60.63) einrichten und authentifizieren.\n\n## Kontext\n- VM läuft, SSH funktioniert: ssh shikigami\n- Tools sind installiert (Claude Code 2.1.42, Gemini 0.28.2)\n- Noch nicht authentifiziert - benötigt interaktive Login-Sessions\n\n## Schritte\n1. ssh shikigami → claude → Browser-Auth oder setup-token\n2. ssh shikigami → gemini → Google OAuth\n\n## Acceptance Criteria\n- [ ] claude --version und claude Session startet ohne Auth-Fehler\n- [ ] gemini --version und gemini Session startet ohne Auth-Fehler","status":"open","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-24T01:37:15Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:48Z"}
{"id":"claude-k6i","title":"[EPIC] Self-Hosted Cloud: Storage, Backup \u0026 Personal Data Sovereignty","description":"Vision: Elysium als zentrale Plattform fuer persoenliche Daten, Backups und Services -- weg von Cloud-Abhaengigkeit hin zu Self-Hosting mit Cloud als Fallback.\n\n## Tracks\n\n### Track 1: Storage \u0026 Backup Foundation\n- DAS-Gehaeuse (4x WD 4TB, USB-C, RAIDZ1) an Elysium\n- ZFS-Pool Setup auf Proxmox\n- Proxmox-Backup-Strategie (scheduled backups auf DAS)\n\n### Track 2: Foto-Management (iCloud/Google Photos Ersatz)\n- Immich auf Elysium (LXC/Docker)\n- iOS Auto-Upload konfigurieren\n- Backup der Immich-Daten auf DAS\n\n### Track 3: Datei-Sync (iCloud Drive/Google Drive Ersatz)\n- Nextcloud auf Elysium (LXC/Docker)\n- Desktop/iOS Sync-Clients\n- Externer Zugriff via Caddy Reverse Proxy oder Tailscale\n- Cloud-Tarif als Off-Site-Backup reduzieren\n\n### Track 4: E-Mail Archiv\n- IMAP-Konten sichern (Fastmail, etc.)\n- Integration mit bestehenden MailSteward/mail-archive Datenbanken\n- Langzeit-Archivierung auf Elysium\n\n### Track 5: Kalender-Konsolidierung (separates Thema, spaeter)\n- Ist-Zustand: Fastmail (Business), Apple (Privat), Google, Kunden-Kalender\n- Fantastical als Aggregator funktioniert, aber nicht rund\n- Optionen: CalDAV auf Nextcloud zentralisieren vs. Status Quo verbessern\n- Buchungslinks-Loesung evaluieren\n\n### Track 6: Media (Jellyfin)\n- Bereits als Bead geplant (claude-c8c)\n- Media-Storage auf DAS\n\n## Hardware-Basis\n- Elysium: Ryzen AI 9 HX 370, 128GB RAM, 4TB NVMe\n- DAS: USB-C 4-Bay Gehaeuse (ORICO/Mediasonic ~100 EUR)\n- Platten: 4x WD 4TB HDD (vorhanden)\n- Netzwerk: 2x 2.5GbE, Caddy Reverse Proxy vorhanden\n\n## Prioritaeten\n1. DAS + Backup (Foundation)\n2. Immich (schnellster sichtbarer Nutzen)\n3. Nextcloud (Datei-Sync)\n4. E-Mail Archiv\n5. Jellyfin (bereits geplant)\n6. Kalender (spaeter, separates Thema)","status":"open","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T08:29:44Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z"}
{"id":"claude-kiq","title":"Gasttown VM: Session Close Protocol adaptieren","description":"Session Close Protocol für gastown-vm Projekt adaptieren:\n1. Prüfen wie gastown-vm aktuell Releases macht\n2. cliff.toml für gastown-vm konfigurieren\n3. /session-close Skill dort verfügbar machen (über malte/ globale Skills)\n4. Ggf. projektspezifische Anpassungen\n\nHängt ab von: Session Close Skill muss fertig sein.\n\nAkzeptanzkriterien:\n- gastown-vm nutzt /session-close\n- CalVer Releases funktionieren","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T02:08:55Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:49Z","dependencies":[{"issue_id":"claude-kiq","depends_on_id":"claude-uwm","type":"blocks","created_at":"2026-02-26T02:09:15Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-l31","title":"CalVer Versioning: VERSION-Datei + Tag-Schema","description":"CalVer Versionierung im claude/ Repo einführen:\n1. VERSION-Datei anlegen mit aktuellem CalVer (YYYY.0M.MICRO)\n2. Tag-Schema definieren: v2026.02.0, v2026.02.1, etc.\n3. Script/Funktion zum Bestimmen der nächsten Version:\n   - Prüfe letzten Tag mit gleichem YYYY.0M Prefix\n   - Incrementiere MICRO\n   - Falls neuer Monat: MICRO reset auf 0\n4. Integration mit git-cliff (--tag Parameter)\n\nAkzeptanzkriterien:\n- VERSION Datei existiert\n- Nächste Version kann automatisch bestimmt werden\n- Tags folgen CalVer Schema","notes":"VERSION file (2026.02.0) and scripts/next-version.sh created. Script reads last git tag, increments MICRO for same month, resets for new month. Committed as 0e684da.","status":"completed","priority":1,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T02:08:32Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:12Z"}
{"id":"claude-l5n","title":"Claude Code auf Hokora VM authentifizieren","description":"Claude Code auf Hokora VM (201, 192.168.60.51) einrichten und authentifizieren.\n\n## Kontext\n- Hokora VM läuft auf Proxmox (Elysium)\n- SSH: ssh hokora (muss ggf. in config.d angelegt werden)\n- Claude Code muss installiert/aktualisiert und per /login authentifiziert werden (Pro/Max Account)\n- Voraussetzung für Gastown Remote Control Setup\n\n## Acceptance Criteria\n- [ ] Claude Code installiert und auf aktuellem Stand\n- [ ] claude /login erfolgreich (Pro/Max Account)\n- [ ] claude session startet ohne Auth-Fehler\n- [ ] Beads CLI (bd) installiert und funktionsfähig","notes":"Claude Code v2.1.52 installed, ~/.claude symlinked to centralized config. bd v0.56.1 installed. Missing: claude auth login (interactive browser OAuth, manual step).","status":"open","priority":1,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-25T07:20:51Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:51Z"}
{"id":"claude-mzj","title":"Proxmox Backup-Strategie auf DAS einrichten","description":"## Ziel\nAutomatische Proxmox-Backups aller VMs/LXCs auf das DAS-ZFS-Volume.\n\n## Schritte\n1. Proxmox Backup Storage hinzufuegen (Directory auf /mnt/das/backup)\n2. Backup-Schedule konfigurieren (taeglich/woechentlich)\n3. Retention Policy festlegen (z.B. 7 daily, 4 weekly, 3 monthly)\n4. Backup-Job fuer alle VMs/LXCs erstellen\n5. Erster Backup-Lauf + Verify\n6. Notification bei Backup-Fehler (optional: E-Mail)\n\n## Akzeptanzkriterien\n- [ ] Automatische Backups laufen nach Schedule\n- [ ] Retention Policy greift\n- [ ] Restore-Test mit einem LXC erfolgreich","status":"open","priority":1,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T08:30:02Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:52Z","labels":["epic:claude-k6i"],"dependencies":[{"issue_id":"claude-mzj","depends_on_id":"claude-wlo","type":"blocks","created_at":"2026-02-16T09:30:46Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-n9p","title":"Hardcover Integration: Audible-Bibliothek + Audiobookshelf Tracking","description":"## Ziel\nHardcover.app als optionales Book-Tracking für Calibre-Web E-Books einrichten.\n\nAudiobookshelf hat eigenes Tracking (Fortschritt, Statistiken) - Audiobooks brauchen kein Hardcover.\n\n## Offene Fragen\n- Lohnt sich Hardcover nur für E-Books?\n- Oder reicht Calibre-Web's eigenes Read/Unread Tracking?\n- Audible-Bibliothek (gehörte Bücher) nach Hardcover importieren?\n\n## Akzeptanzkriterien\n- [ ] Entscheidung ob Hardcover nötig ist\n- [ ] Falls ja: Account + Import der Audible-Bibliothek + Calibre-Bücher","status":"tombstone","priority":4,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T13:01:10Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:53Z"}
{"id":"claude-o6f","title":"BMAD-Konzepte für Greenfield/komplexe Projekte übernehmen","description":"Ausgewählte Konzepte aus dem BMAD Framework (Breakthrough Method for Agile AI-Driven Development, v6) als optionale Erweiterung für Greenfield-Phasen und komplexe Projekte integrieren.\n\n## Zu übernehmende Konzepte\n\n### 1. Document Sharding\nWorkflows in Einzelschrittdateien zerlegen. LLM sieht nur den aktuellen Step.\n~70-90% Token-Reduktion vs. monolithisch. Progressive Disclosure verhindert Abkürzungen.\n\n### 2. Scale-Adaptive Intelligence (Level 0-4)\n- Level 0: Bug Fix → minimale Planung\n- Level 1: Single-Component Feature → kurzer Plan\n- Level 2: Feature-Set → PRD + Architektur\n- Level 3: Komplettes Produkt → Full Lifecycle\n- Level 4: Enterprise → Governance + Audit\n\n### 3. Agent-Personas für Planungsphase\nAnalyst → PM → Architect als strukturierte Handoffs für die Anfangsphase komplexer Projekte.\nNicht als permanente Agenten, sondern als Prompt-Templates für tiefere Analyse.\n\n## Einschränkungen\n- NICHT das volle Framework installieren (zu viel Overhead)\n- Nur Konzepte übernehmen, nicht die YAML-Workflows\n- Primär für neue Projekte oder neue Major-Features in bestehenden Projekten\n- Für Mira/Shikigami: Zu spät für Greenfield, aber Scale-Adaptive Planning hilft bei neuen Epics\n\n## Acceptance Criteria\n- [ ] Document Sharding als Konzept in Plan-Skills integriert\n- [ ] Scale-Adaptive Erkennung: Workflow passt Planungstiefe automatisch an\n- [ ] Analyst/PM/Architect Prompts als optionale Planungs-Skills\n- [ ] Dokumentation wann BMAD-Konzepte vs. Lightweight-Workflow sinnvoll sind","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T01:57:07Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:53Z","labels":["epic:claude-59a"],"dependencies":[{"issue_id":"claude-o6f","depends_on_id":"claude-pa3","type":"blocks","created_at":"2026-02-26T01:57:53Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-oii","title":"PRIME.md Update: Session Close v2 Protokoll einbauen","description":"Das aktuelle Session Close Protokoll in PRIME.md und CLAUDE.md aktualisieren:\n1. Altes Checklist-basiertes Protokoll ersetzen durch Verweis auf /session-close Skill\n2. Dokumentieren wann Session Close getriggert werden soll\n3. Fallback-Checklist für den Fall dass der Skill nicht verfügbar ist\n\nAkzeptanzkriterien:\n- PRIME.md referenziert /session-close\n- Alte manuelle Checklist als Fallback erhalten\n- CLAUDE.md Session Close Capture Rule aktualisiert","status":"in_progress","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T02:08:40Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:54Z","dependencies":[{"issue_id":"claude-oii","depends_on_id":"claude-uwm","type":"blocks","created_at":"2026-02-26T02:09:11Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-oza","title":"Audiobookshelf: Hörbuch-Import (~56GB, inkl. Hugo Awards)","description":"## Quellen (auf Solaris/MacBook)\n\n### 1. iCloud Audiobooks (11 GB, 175+ Dateien)\n- Pfad: ~/Library/Mobile Documents/com~apple~CloudDocs/Audiobooks/\n- M4B: Phoenix Project (324MB), Unicorn Project (345MB), Beyond Phoenix Project (214MB)\n- MP3-Sammlungen:\n  - Dragonlance Chronicles Series 01-04 (3.2 GB, 123 Dateien)\n  - Dragonlance Legends (1.1 GB, 115 Dateien)\n  - The Sandman (1.9 GB)\n  - Termination Shock (576 MB)\n  - This Is How You Lose the Time War (130 MB)\n  - Daniel Green - Breach of Peace + Rebel's Creed (1.4 GB)\n  - Tracy Hickman - Annals of Drakis (1.0 GB)\n\n### 2. Hugo Awards Audiobooks (~43 GB, 1353 Dateien)\n- Pfad: ~/Hugo/Hugo {2019-2025}/\n- Nur Kategorien Novel, Novella, Novelette, Short Story, Series importieren\n- AUSSCHLUSS: Fancast, Semiprozine, Podcast-Episoden\n- Aufschlüsselung:\n  - Hugo 2025: 32.2 GB (Novel: Service Model, Sorceress Comes to Call, Someone You Can Build a Nest In; Series: Stormlight Archive, Tyrant Philosophers)\n  - Hugo 2022: 3.6 GB\n  - Hugo 2019: 2.9 GB\n  - Hugo 2021: 2.1 GB\n  - Hugo 2024: 1.8 GB\n  - Hugo 2020: 0.3 GB\n\n### 3. Maze of Games Audiobook (1.1 GB)\n- Pfad: ~/Documents/INBOX/Maze of Games Audiobook and Soundtrack/\n- Audiobook Solved + Unsolved + Soundtrack\n\n### 4. Brandon Sanderson\n- Tress of the Emerald Sea (342 MB, mp4)\n\n## Audible-Tool\n- **Libation.app** ist installiert (/Applications/Libation.app, ARM64)\n- Audible DRM-Entfernung möglich\n- Prüfen: Gibt es noch Audible-Bücher die nicht exportiert wurden?\n\n## Migrationsstrategie\n1. Libation starten und prüfen ob weitere Audible-Bücher zum Export bereit sind\n2. Hugo-Audiobooks filtern: nur Fiction-Kategorien (Novel, Novella, Novelette, Short Story, Series, Astounding, Lodestar)\n3. Alle Audiobooks nach LXC 110 transferieren\n4. Audiobookshelf importiert automatisch aus /audiobooks Volume\n\n## Transfer\nrsync/scp nach LXC 110 (192.168.60.20) Docker Volume audiobooks\n\n## Akzeptanzkriterien\n- [ ] Libation geprüft auf weitere Audible-Exporte\n- [ ] Alle iCloud-Audiobooks transferiert\n- [ ] Hugo Awards Audiobooks (Fiction-Kategorien) transferiert\n- [ ] Maze of Games transferiert\n- [ ] Audiobookshelf zeigt alle Hörbücher mit Metadaten\n- [ ] iOS App getestet","notes":"POST-IMPORT ARCHIVIERUNG: Nach erfolgreichem Import Quelldateien auf PRO-G40 verschieben (Pattern: claude-e41). Ziel: /Volumes/PRO-G40/Imported-to-Elysium/{Service}/ mit .manifest.json. Befreit lokalen Speicher auf Solaris und dokumentiert Import-Status.\n## Zusätzliche Quellen (Spotlight-Scan 2026-02-17)\n\n### 5. Brandon Sanderson - The Sunlit Man (308 MB, MP4)\n- Pfad: ~/Documents/The_Sunlit_Man_by_Brandon_Sanderson.mp4\n- Liegt lose in ~/Documents/, nicht in Audiobooks-Ordner\n\n### 6. cognovis Leadership Audiobook (MP3s)\n- Pfad: ~/Documents/cognovis/Dokumente/Reading Material/Leadership/servantleadershipinaction_audio-mp3/\n- \"Servant Leadership in Action\" als MP3-Sammlung\n- E-Book-Version geht nach Calibre-Web (claude-uvj)\n\n### 7. Apple Books Audiobooks (8 M4B in BKAgentService)\n- Pfad: ~/Library/Containers/com.apple.BKAgentService/Data/Documents/iBooks/Books/Audiobooks/\n- Duplikate von Hugo 2025 Audio-Dateien (Service Model, Sorceress, Heavenly Tyrant, etc.)\n- NICHT separat importieren, sind Kopien der Hugo-Quellen\n\n## Post-Import Validierung\n- Nach Verschieben aller Quelldateien: finaler Spotlight-Scan auf ~ um verbleibende Audiobooks zu finden\n- mdfind für M4B, MP3 (audiobook-Kontext), MP4 (audiobook-Kontext)\nLibation-Pfad korrigiert: ~/Music/Libation/Books/ (nicht ~/Applications). Aktuell 2 Autoren (Andrew Rowe - Arcane Ascension, K.T. Hanna - Library System Reset), 1.8 GB, Download läuft noch. Libation-Import nach Audiobookshelf erst starten wenn Download abgeschlossen.\nSpotlight scan 2026-02-17: Audiobook sources confirmed:\n- Libation (~/Music/Libation/Books/): 10 Autoren, 29 GB, M4B format (Audible DRM-frei). Noch am Downloaden.\n- iCloud Drive (~/Library/Mobile Documents/com~apple~CloudDocs/Audiobooks/): 14 M4B-Dateien (Phoenix/Unicorn Project, Sandman Trilogie, Termination Shock, Dragonlance, Annals of Drakis)\n- Hugo 2025 audiobooks: 10 M4B (werden mit Hugo-Archiv auf PRO-G40 gesichert, Duplikate der Apple Books)\n- Apple Books Audiobooks: Duplikate von Hugo 2025\n- Brandon Sanderson Sunlit Man: 308 MB MP4 (separater Import)\n## Transfer-Status (2026-02-17 12:40)\nManueller Import nach LXC 110 abgeschlossen:\n- iCloud Audiobooks: 446 Dateien, 12.85 GB (15 Collections inkl. Maze of Games, Sanderson, Servant Leadership)\n- Hugo Awards 2025 Fiction: 1.095 Dateien, ~25 GB (nur 2025 hatte Audio, 2019-2024 nur Text)\n- Hugo Awards 2019-2024: KEINE Audiodateien vorhanden, nur PDF/EPUB/MOBI\n\nLibation Auto-Import läuft: 94/427 Bücher downloaded (51 GB), einige ältere Bücher haben Decrypt-Probleme.\n\nLXC 110 Disk auf 204 GB vergrößert (war 64 GB). Aktuell: 99 GB audiobooks, 55% Disk.\n\nNoch offen:\n- [ ] Libation durchlaufen lassen (427 Bücher, ETA einige Stunden)\n- [ ] Audiobookshelf Library Scan triggern\n- [ ] Decrypt-Failures prüfen (ältere Audible DRM)\n- [ ] Archivierung auf PRO-G40\n## Finaler Status (2026-02-17 13:00)\nAudiobookshelf: 119 Items, 103 GB, http://192.168.60.20:13378\nLXC 110 Disk: 201 GB (57% belegt, 84 GB frei)\n\nAlle Quellen importiert:\n- Libation/Audible: 95 Bücher heruntergeladen (M4B + PDFs), läuft stündlich weiter\n- iCloud Audiobooks: 15 Collections (446 Dateien, 12.85 GB)\n- Hugo Awards 2025 Fiction: 1.095 Dateien, ~25 GB (Hugo 2019-2024 hatten keine Audio)\n- Maze of Games, Sanderson, Servant Leadership: alle transferiert\n\nCleanup erledigt:\n- MP4→M4B: Tress + Sunlit Man konvertiert (remux, keine Re-Encoding)\n- 7 lose PDFs in richtige Buch-Ordner verschoben, 6 Orphan-PDFs gesammelt\n- Hugo Metadaten: 22/23 Items mit korrekten Autoren/Titeln, 1 fehlt (Five Views of Tartarus)\n\nOffen:\n- [ ] Archivierung Quelldateien auf PRO-G40\n- [ ] iOS App testen\n- [ ] Five Views of Tartarus Autor manuell setzen\n- [ ] Heavenly Tyrant Audio-Dateien auf Disk prüfen (gemischte Dateien)\n## Library Restructure Complete (2026-02-17)\nPost-import cleanup:\n- 39 multi-book series folders split into 145 per-book subfolders\n- Root cause: Libation FolderTemplate lacked book-level subfolder\n- FolderTemplate fixed: \u003cauthor\u003e\u003cif series-\u003e/\u003cseries\u003e/\u003cseries#[00.##]\u003e - \u003ctitle short\u003e\u003c-if series\u003e\n- 33 stale isMissing entries deleted, metadata enriched via Audible/Google providers\n- Final library: 263 items, 252 ASIN (96%), 263 covers (100%), 0 isMissing\n## Decrypt-Failed Reimport (2026-02-17 18:00)\n14 decrypt-failed titles + Discord of Gods (new) imported from local Mac:\n- Downloaded via desktop Libation (macOS) - Docker CLI can't decrypt older titles\n- 14 m4b files (12 GB) rsync'd to Proxmox staging, then pct push to LXC 110\n- All files placed in correct ABS folder structure\n- ABS library scan: 395 items (was 393, +2 new entries)\n\nTitles replaced:\n1. Tad Williams - Der Drachenbeinthron (2 GB)\n2. Dan Simmons - Hyperion \u0026 Endymion 1 (592 MB)\n3. Dan Simmons - Hyperion \u0026 Endymion 2 (608 MB)\n4. Robert Sheckley - Dimension of Miracles (153 MB)\n5. Andreas Eschbach - Kelwitts Stern (667 MB)\n6. Andreas Eschbach - Das Jesusvideo (400 MB)\n7. Andreas Eschbach - Ein König für Deutschland (398 MB)\n8. Brent Weeks - Perfect Shadow (58 MB)\n9. Brent Weeks - Die blendende Klinge (1.8 GB)\n10. Haruki Murakami - 1Q84 Buch 1 \u0026 2 (1.8 GB)\n11. Haruki Murakami - 1Q84 Buch 3 (988 MB)\n12. Stephen King - Der Anschlag (1.8 GB)\n13. Arthur Conan Doyle - Blue Carbuncle (22 MB)\n\nNew entry:\n14. Jenn Lyons - The Discord of Gods (1.4 GB)\n\nKnown issues:\n- Some ABS items show audio:2 (stale metadata from old encrypted files) - cosmetic\n- 8 stray PDFs at volume root creating phantom library entries (not cleaned up yet)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:02:56Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","closed_at":"2026-02-22T04:11:58Z","close_reason":"395 Items in ABS (103GB), alle Quellen importiert (iCloud, Hugo 2019-2025, Libation, Maze of Games), 118GB auf PRO-G40 archiviert, iOS App läuft. Offen: Five Views of Tartarus Autor, Quelldateien noch nicht gelöscht.","labels":["epic:claude-k6i"]}
{"id":"claude-pa3","title":"Charly-Server Workflow extrahieren und allgemeingültig machen","description":"Den ausgereiften Entwicklungsworkflow aus ~/code/solutio/charly-server/.claude/ extrahieren und als wiederverwendbaren, projektunabhängigen Workflow in ~/code/claude/ verfügbar machen.\n\n## Quelle\ncharly-server/.claude/ enthält:\n- 19 Commands (/ticket, /revise, /impl, /mr-prepare, /bug, /feature, /chore, etc.)\n- 9 Agents (plan-reviewer, integration-test-runner, pester-test-engineer, etc.)\n- 5 Skill Sets (bash-best-practices, code-review, pester-testing, etc.)\n- Implizite Definition of Done (Tests, Linting, Docs, Security, Git/CI)\n\n## Aufgabe\n1. Commands analysieren und projektspezifische Teile identifizieren (PowerShell/Pester → generisch)\n2. Agents generalisieren (z.B. pester-test-engineer → test-engineer mit Framework-Erkennung)\n3. Workflow-Phasen als allgemeingültige Standards dokumentieren\n4. Skills projektunabhängig machen\n5. Ergebnis als Standards/Skills/Commands im claude/ Repo ablegen\n\n## Acceptance Criteria\n- [ ] Kern-Commands (/ticket, /revise, /impl, /mr-prepare) als generische Versionen\n- [ ] Plan-Reviewer Agent projektunabhängig\n- [ ] Test-Runner Agent mit Framework-Erkennung (pytest, jest, pester, shellspec)\n- [ ] Definition of Done als expliziter Standard\n- [ ] Workflow-Dokumentation","status":"open","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T01:56:42Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:56Z","labels":["epic:claude-59a"]}
{"id":"claude-pog","title":"git-cliff Setup: cliff.toml + Conventional Commits Convention","description":"git-cliff im claude/ Repo einrichten:\n1. git-cliff installieren (brew install git-cliff)\n2. cliff.toml konfigurieren mit:\n   - Conventional Commits Parser\n   - CalVer-kompatibles Tagging\n   - Keep-a-Changelog Template\n   - Scope-Mapping für Skill/Agent/Hook/Standard Änderungen\n3. CHANGELOG.md initialisieren aus bisheriger git History\n4. Convention/Standard für Conventional Commits anlegen (standards/)\n\nAkzeptanzkriterien:\n- git cliff generiert sauberes Changelog\n- cliff.toml commited\n- Standard für Commit-Messages dokumentiert","notes":"cliff.toml created with Conventional Commits parser, CalVer-compatible tagging, Keep-a-Changelog output, scope mapping. Committed as 001031f.","status":"completed","priority":1,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T02:08:17Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:04Z"}
{"id":"claude-q0h","title":"Static Website LXC: cognovis.de + sussdorff.de Landing Pages","description":"Neuer LXC auf Elysium für statische Websites, erreichbar über NetBird Reverse Proxy.\n\n## Ziel\nStatische Landing Pages für cognovis.de und sussdorff.de hosten, statt auf toten/fremden Servern zu landen.\n\n## Websites\n- **cognovis.de** + www.cognovis.de — Business Landing Page\n- **sussdorff.de** + www.sussdorff.de — Persönliche/Familien Landing Page\n\n## Zusätzlich: .well-known Redirects (Fastmail)\n- `/.well-known/carddav` → `https://carddav.fastmail.com` (301)\n- `/.well-known/caldav` → `https://caldav.fastmail.com` (301)\n- Löst Apple Contacts Autodiscovery-Timeout auf cognovis.de\n\n## Architektur\n- LXC auf Elysium (VLAN 60), nginx für Static Serving\n- Erreichbar über NetBird Reverse Proxy (Traefik auf VPS)\n- Zwei Optionen für Traefik-Integration:\n  - A) docker-compose.override.yml auf VPS (nginx Container neben NetBird)\n  - B) NetBird Reverse Proxy Dashboard → LXC als Target (wie andere Services)\n- Option B bevorzugt: konsistent mit bestehenden Services (ABS, Grafana, etc.)\n\n## DNS-Änderungen (Hetzner DNS / hcloud)\n- cognovis.de A → 46.224.133.69 (NetBird VPS, aktuell 138.201.89.78 = toter Server)\n- sussdorff.de A → prüfen ob Änderung nötig (aktuell 80.147.143.115 = Caddy)\n- Alternativ: CNAME auf netbird.cognovis.de\n\n## IaC\n- Setup-Script: `lxc/static-web/setup-lxc.sh`\n- Deploy-Script: `lxc/static-web/deploy.sh`\n- nginx Config + HTML im Repo\n\n## Acceptance Criteria\n- [ ] LXC auf Elysium deployed mit nginx\n- [ ] cognovis.de Landing Page served via HTTPS\n- [ ] sussdorff.de Landing Page served via HTTPS\n- [ ] .well-known/carddav + caldav Redirects funktionieren\n- [ ] Apple Contacts Autodiscovery kein Timeout mehr\n- [ ] Setup + Deploy Scripts im Repo\n- [ ] DNS Records aktualisiert","notes":"## Zukünftige Erweiterung\nWeitere Domains können später auf denselben LXC zeigen:\n- getmira.de / mira-pvs.de (MIRA Produkt-Landing Page)\n- ignis-ai.de (Ignis Produkt-Landing Page)\nJede Domain bekommt einen eigenen nginx vhost + NetBird Reverse Proxy Service.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-25T10:37:00Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:32Z","closed_at":"2026-02-25T11:25:50Z","close_reason":"Superseded by claude-wlg: nginx auf VPS statt separatem LXC. cognovis.de Custom Domain geht nicht als NetBird Wildcard (DKIM-Konflikt) → docker-compose.override.yml Ansatz gewählt.","labels":["decision"]}
{"id":"claude-qeu","title":"Nanobanana: Von Date-Based auf CalVer + Session Close migrieren","description":"Nanobanana Projekt von automatischem Date-Based Release auf CalVer + manuelles Release bei Session Close umstellen:\n1. GitHub Actions Workflow anpassen: Kein auto-release bei jedem Push\n2. Stattdessen: Release nur bei Tag-Push (CalVer Tags)\n3. CHANGELOG.md einführen (git-cliff)\n4. cliff.toml für nanobanana konfigurieren\n5. Release-Workflow dokumentieren\n\nAkzeptanzkriterien:\n- Kein automatisches Release bei Push\n- CalVer Tags triggern Release\n- CHANGELOG.md wird generiert","notes":"Migration complete: release.yml triggers on CalVer tags only, cliff.toml configured, CHANGELOG.md initialized, docs/release.md created, CLAUDE.md updated. Commit: 44ad2e4","status":"completed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T02:08:47Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:23:49Z","dependencies":[{"issue_id":"claude-qeu","depends_on_id":"claude-l31","type":"blocks","created_at":"2026-02-26T02:09:14Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-qeu","depends_on_id":"claude-pog","type":"blocks","created_at":"2026-02-26T02:09:12Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-qot","title":"[DISCOVERY] Documents/INBOX + alte Archive aufraeumen","description":"## Ist-Zustand\n~/Documents enthaelt diverse historische Altlasten:\n- INBOX (20 GB): Unsortiertes Sammelsurium\n- 14.800 .ovpn Dateien (NordVPN Config-Dump?) -\u003e loeschen\n- 10.400 .ttf Fonts (vermutlich aus EPUBs, nicht echte Sammlung) -\u003e pruefen\n- EagleFiler Archives (5 GB): Alte E-Mail/Dokumenten-Archive -\u003e nach Paperless migrieren?\n- Knox Vaults (10 GB): Verschluesselte Buchhaltungs-Sparsebundles -\u003e behalten oder nach Paperless?\n- WhatsApp Export (1.2 GB): Chat-History -\u003e archivieren\n- Websites-Ordner: Alte project-open Codes -\u003e aufraeumen\n- Larian Studios (1.9 GB): Spielstaende -\u003e loeschen oder behalten\n- cognovis (12 GB): Alte Firmendaten -\u003e archivieren/Paperless\n\n## Vorgehen\n1. INBOX durchgehen: Verteilen auf Paperless/Immich/Calibre/Loeschen\n2. VPN Configs: Pruefen ob noch gebraucht, sonst loeschen\n3. EagleFiler: Inhalt pruefen, nach Paperless migrieren\n4. Websites: project-open Code aufraeumen\n5. Rest kategorisieren und entscheiden\n\n## Akzeptanzkriterien\n- [ ] INBOX leer oder strukturiert\n- [ ] Offensichtlicher Muell geloescht (alte VPN configs, temp files)\n- [ ] Wertvolle Dokumente in Paperless importiert\n- [ ] Entscheidung ueber Knox, EagleFiler, cognovis","status":"open","priority":4,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T10:14:51Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:17:59Z","labels":["epic:claude-k6i"]}
{"id":"claude-qsm","title":"piler-cli: export — Batch-Export Wrapper","description":"'piler export --since 2025-01 --from cognovis -o /tmp/export/' wrappet pilerexport mit benutzerfreundlichen Flags. Optional: ZIP-Output. Acceptance: Export einer Datums-Range funktioniert.","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:27:18Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:00Z","labels":["epic:claude-ecz"],"dependencies":[{"issue_id":"claude-qsm","depends_on_id":"claude-8oh","type":"blocks","created_at":"2026-02-18T05:27:28Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-ruw","title":"[LEARNING] Hetzner Robot .de domain registration: create DNS zone first, wait for propagation before DENIC submission","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-22T18:01:10Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:01Z","labels":["learning"]}
{"id":"claude-rx4","title":"Mailpiler IMAP-Anbindung: 5 Konten konfigurieren","description":"## Ziel\nAlle aktiven E-Mail-Konten als IMAP-Quellen in Mailpiler konfigurieren für regelmäßiges Polling.\n\n## Konten\n1. malte.sussdorff@cognovis.de (Fastmail)\n2. sussdorff@sussdorff.de (Fastmail)\n3. malte.sussdorff@gmail.com (Google - App-Passwort nötig)\n4. malte.sussdorff@agiler-norden.de (Provider prüfen)\n5. malte@zahnrad-network.de (Provider prüfen)\n\n## NICHT anbinden\n- sussdorff@me.com (ad acta)\n\n## Vorgehen\n1. Mailpiler fetchmail/imapfetch Konfiguration für jedes Konto\n2. IMAP-Credentials sicher in .env oder Mailpiler-Config hinterlegen\n3. Polling-Intervall festlegen (z.B. alle 15 Min)\n4. Testlauf pro Konto, Verifizierung dass Mails ankommen\n5. Monitoring: Fehler-Alerts bei fehlgeschlagenen Fetches\n\n## Voraussetzungen\n- Mailpiler LXC muss deployed sein (claude-9fg)\n- Gmail: App-Passwort generieren (2FA aktiv)\n- Fastmail: App-Passwort oder JMAP-Token\n\n## Akzeptanzkriterien\n- [ ] Alle 5 Konten konfiguriert\n- [ ] Polling läuft automatisch\n- [ ] Mindestens ein erfolgreicher Fetch pro Konto verifiziert","notes":"## Konfiguration erstellt (2026-02-17)\n\nNeue Dateien in lxc/mailpiler/:\n- imap-accounts.conf.example - Template mit allen 5 Konten + korrekten IMAP-Servern\n- imap-fetch.sh - Fetch-Script mit Lock-File, Logging, Fehlerbehandlung\n- deploy-imap.sh - Deployment-Script für Proxmox (kopiert Config + richtet Cron ein)\n\nIMAP-Server ermittelt via MX-Records:\n- cognovis.de + sussdorff.de → imap.fastmail.com (Fastmail)\n- gmail.com → imap.gmail.com\n- agiler-norden.de → imap.gmail.com (Google Workspace)\n- zahnrad-network.de → imap.ionos.de (IONOS)\n\n.gitignore aktualisiert: lxc/*/imap-accounts.conf + lxc/*/.env ausgeschlossen\n\n### Nächste Schritte (manuell):\n1. imap-accounts.conf.example → imap-accounts.conf kopieren\n2. Echte Passwörter eintragen (Fastmail App-Passwort, Gmail App-Passwort, IONOS PW)\n3. deploy-imap.sh auf Proxmox ausführen\n4. Initialer Fetch verifizieren\n## Vereinfachung (2026-02-17)\n\nCustom imap-fetch.sh Script entfernt. Mailpiler hat nativen IMAP-Fetch:\n- import-Tabelle in MySQL speichert IMAP-Konten\n- Cron /usr/libexec/piler/import.sh läuft alle 5 Min\n- imapfetch.py -i liest Konten aus DB, ein Konto pro Zyklus\n- deploy-imap.sh vereinfacht: schreibt nur noch 1Password Credentials in import-Tabelle\n\nManticore Search Index-Fix: piler1, tag1, note1 Indizes mussten manuell per SQL angelegt werden (fehlten in der Default-Manticore-Config).\n\nErfolgreich archiviert:\n- Gmail: 383 Mails (inkl. Sent, Drafts, alle Ordner)\n- IONOS: 2 Mails\n\nNoch offen (Credential-Probleme):\n- Fastmail cognovis + sussdorff: Passwörter stimmen nicht\n- agiler-norden: Google Workspace App-Passwort fehlt\n- shikigami: imapfetch.py Read-Only Problem (conn.select ohne readonly)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T11:20:34Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","closed_at":"2026-02-22T04:18:15Z","close_reason":"6 Konten konfiguriert (statt ursprünglich 5): 2x Fastmail, 2x Gmail, 1x IONOS, 1x shikigami. 210.218 Mails total, alle status=FINISHED. malte@sussdorff.de (102k) noch beim Import.","dependencies":[{"issue_id":"claude-rx4","depends_on_id":"claude-9fg","type":"blocks","created_at":"2026-02-16T12:20:53Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-s7u","title":"Grafana: Node, Host \u0026 Docker Dashboards + cAdvisor","description":"## Anforderungen\nDrei zusätzliche Grafana Dashboards + cAdvisor Deployment.\n\n### Dashboard 1: Node Detail\n- Variable/Dropdown zur Container-Auswahl\n- CPU Usage (user/system/iowait), Load Average\n- Memory Usage (used/cached/buffers/available)\n- Disk I/O (read/write bytes/s, IOPS)\n- Network Traffic (rx/tx bytes/s)\n- Filesystem Usage (alle Mountpoints)\n\n### Dashboard 2: Proxmox Host\n- Host CPU, Memory, Swap\n- Storage Pool Usage\n- Network Traffic auf Bridges\n- System Load, Uptime\n- Kernel Version, CPU Info\n\n### Dashboard 3: Docker Containers\n- Container CPU/Memory Usage\n- Container Network I/O\n- Container Status (running/stopped/restarting)\n- Container Restart Count\n- Braucht cAdvisor auf Docker-LXCs\n\n### cAdvisor Deployment\n- cAdvisor Container auf allen LXCs die Docker nutzen\n- Port 8081 (um Konflikte zu vermeiden)\n- Prometheus scrape config erweitern\n\n## Akzeptanzkriterien\n- [ ] cAdvisor deployed auf Docker-LXCs\n- [ ] 3 Dashboards provisioniert in Grafana\n- [ ] Alle Dashboards laden korrekt mit Daten\n- [ ] Deploy-Script aktualisiert","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:58:07Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:03Z","closed_at":"2026-02-17T15:05:57Z","close_reason":"3 Dashboards provisioniert (Node Detail, Proxmox Host, Docker Containers), cAdvisor auf 10 LXCs deployed, 28/28 Prometheus Targets UP"}
{"id":"claude-t0h","title":"[EPIC] SSO via NetBird IdP für Familie + Services","description":"Single Sign-On für Elysium Services über den NetBird Built-in Identity Provider.\n\n## User\n- malte@sussdorff.de (admin, Zugriff auf alles)\n- jenny@sussdorff.de (family, Zugriff auf ABS, Paperless, Komga)\n- malte.sussdorff@cognovis.de (work, für zukünftige cognovis Services)\n\n## Services mit nativem OIDC-Support\n- Audiobookshelf (Web UI Config)\n- Paperless-ngx (Env vars, Django Allauth)\n- Grafana (generic_oauth in grafana.ini)\n- Komga (Spring Security OAuth2 in application.yml)\n\n## Nicht SSO-fähig (zur Kenntnis)\n- Plex: Auth über plex.tv, nicht änderbar\n- *arr/SABnzbd: Admin-Tools, kein Multi-User, internal-only\n- Mailpiler: OIDC nur Enterprise, Skip\n\n## Account-Migration\nJeder Service hat aktuell einen Account der NICHT auf malte@sussdorff.de läuft.\nVor SSO-Aktivierung muss der bestehende Account auf malte@sussdorff.de umgestellt werden,\ndamit OIDC Email-Matching funktioniert und History/Daten erhalten bleiben.\n\n## Abhängigkeit\nBlocked by Epic 1 (claude-bgf) — NetBird muss laufen bevor IdP konfiguriert werden kann.","status":"open","priority":3,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:48:54Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","dependencies":[{"issue_id":"claude-t0h","depends_on_id":"claude-bgf","type":"blocks","created_at":"2026-02-20T07:49:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-t0h.1","title":"NetBird IdP User + Gruppen einrichten","description":"User und Gruppen im NetBird Built-in Identity Provider anlegen.\n\n## User\n- malte@sussdorff.de → Gruppe: admin\n- jenny@sussdorff.de → Gruppe: family\n- malte.sussdorff@cognovis.de → Gruppe: cognovis\n\n## Gruppen + Policies\n- admin: Zugriff auf alle Services + Dashboard\n- family: Zugriff auf ABS, Paperless, Komga (kein Dashboard, kein SSH)\n- collaborators: SSH auf zugewiesene LXCs (existiert bereits aus Epic 1)\n- cognovis: Platzhalter für zukünftige cognovis Services\n\n## Acceptance Criteria\n- [ ] Alle 3 User können sich im NetBird Dashboard einloggen\n- [ ] Gruppen korrekt zugeordnet\n- [ ] Auth-Policies definiert: family sieht nur ABS/Paperless/Komga","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:49:03Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:04Z","dependencies":[{"issue_id":"claude-t0h.1","depends_on_id":"claude-bgf","type":"blocks","created_at":"2026-02-20T07:49:41Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-t0h.1","depends_on_id":"claude-t0h","type":"parent-child","created_at":"2026-02-20T07:49:03Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-t0h.2","title":"SSO in Audiobookshelf integrieren","description":"OIDC-Integration von ABS gegen NetBird IdP.\n\n## Vorarbeit\n- Bestehenden ABS Admin-Account Email auf malte@sussdorff.de ändern\n- Sicherstellen dass History/Fortschritt erhalten bleibt\n\n## Steps\n- OIDC in ABS Web UI konfigurieren (Settings \u003e Authentication)\n- Issuer URL: NetBird IdP\n- Client ID + Secret anlegen\n- Redirect URIs: Web + Mobile (für iOS App)\n- Auto Register aktivieren (jenny bekommt automatisch Account beim ersten Login)\n- Jenny-Account nach erstem Login: Libraries zuweisen (Hörbücher)\n\n## Acceptance Criteria\n- [ ] malte@sussdorff.de Login via SSO, bestehende Hör-History erhalten\n- [ ] jenny@sussdorff.de Login via SSO, eigene Library-Ansicht + History\n- [ ] iOS ABS App funktioniert mit SSO Login\n- [ ] Geteilte Bibliothek, separate History pro User","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:49:13Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:05Z","dependencies":[{"issue_id":"claude-t0h.2","depends_on_id":"claude-t0h","type":"parent-child","created_at":"2026-02-20T07:49:13Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-t0h.2","depends_on_id":"claude-t0h.1","type":"blocks","created_at":"2026-02-20T07:49:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-t0h.3","title":"SSO in Paperless-ngx integrieren","description":"OIDC-Integration von Paperless-ngx gegen NetBird IdP.\n\n## Vorarbeit\n- Bestehenden Paperless Admin-Account Email auf malte@sussdorff.de ändern\n\n## Steps\n- PAPERLESS_APPS + PAPERLESS_SOCIALACCOUNT_PROVIDERS in Docker Compose env setzen\n- OpenID Connect Provider konfigurieren (Client ID, Secret, Issuer URL)\n- Auto Register für jenny\n- Optional: PAPERLESS_REDIRECT_LOGIN_TO_SSO=true\n\n## Acceptance Criteria\n- [ ] malte@sussdorff.de Login via SSO, bestehende Dokumente + Tags erhalten\n- [ ] jenny@sussdorff.de Login via SSO\n- [ ] Deploy-Script (docker-compose) aktualisiert mit OIDC env vars","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:49:21Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:06Z","dependencies":[{"issue_id":"claude-t0h.3","depends_on_id":"claude-t0h","type":"parent-child","created_at":"2026-02-20T07:49:20Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-t0h.3","depends_on_id":"claude-t0h.1","type":"blocks","created_at":"2026-02-20T07:49:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-t0h.4","title":"SSO in Grafana integrieren","description":"OIDC-Integration von Grafana gegen NetBird IdP.\n\n## Vorarbeit\n- Bestehenden Grafana Admin-Account Email auf malte@sussdorff.de ändern\n\n## Steps\n- generic_oauth Section in Grafana Config / Docker env vars:\n  GF_AUTH_GENERIC_OAUTH_ENABLED, CLIENT_ID, CLIENT_SECRET, AUTH_URL, TOKEN_URL etc.\n- PKCE aktivieren\n- Optional: auto_login = true\n\n## Acceptance Criteria\n- [ ] malte@sussdorff.de Login via SSO, bestehende Dashboards erhalten\n- [ ] Deploy-Script aktualisiert mit OAuth env vars","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:49:28Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:07Z","dependencies":[{"issue_id":"claude-t0h.4","depends_on_id":"claude-t0h","type":"parent-child","created_at":"2026-02-20T07:49:28Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-t0h.4","depends_on_id":"claude-t0h.1","type":"blocks","created_at":"2026-02-20T07:49:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-t0h.5","title":"SSO in Komga integrieren","description":"OIDC-Integration von Komga gegen NetBird IdP.\n\n## Vorarbeit\n- Bestehenden Komga Admin-Account Email auf malte@sussdorff.de ändern\n- Komga Credentials klären (aktuell unklar, DB-basiert)\n\n## Steps\n- Spring Security OAuth2 Config in application.yml oder Docker env vars\n- SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION + PROVIDER konfigurieren\n- komga.oauth2-account-creation: true für jenny Auto-Register\n- Jenny Libraries zuweisen nach erstem Login\n\n## Acceptance Criteria\n- [ ] malte@sussdorff.de Login via SSO, bestehende Leselisten erhalten\n- [ ] jenny@sussdorff.de Login via SSO\n- [ ] Deploy-Script aktualisiert","status":"open","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T06:49:35Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:08Z","dependencies":[{"issue_id":"claude-t0h.5","depends_on_id":"claude-t0h","type":"parent-child","created_at":"2026-02-20T07:49:35Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-t0h.5","depends_on_id":"claude-t0h.1","type":"blocks","created_at":"2026-02-20T07:49:41Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-tlf","title":"Monitoring-LXC erstellen + Docker Compose Grundgerüst","description":"## Anforderungen\nNeuen LXC-Container auf Proxmox für den Monitoring-Stack erstellen.\n\n## Komponenten im Docker Compose:\n- Prometheus\n- AlertManager  \n- Grafana\n- Blackbox Exporter\n\n## Akzeptanzkriterien\n- [ ] LXC erstellt (ID festlegen, z.B. 112 oder nächste freie)\n- [ ] Docker + Docker Compose installiert\n- [ ] docker-compose.yml mit allen 4 Services (Prometheus, AlertManager, Grafana, Blackbox Exporter)\n- [ ] Alle Container starten und sind erreichbar\n- [ ] Prometheus UI erreichbar (Port 9090)\n- [ ] Grafana UI erreichbar (Port 3000)\n- [ ] Deploy-Script unter lxc/monitoring/ im Repo\n- [ ] Prometheus scrape config mit localhost-Targets (sich selbst)","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:30:30Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:09Z","closed_at":"2026-02-17T14:39:27Z","close_reason":"LXC 113 erstellt, alle 4 Docker-Container laufen (Prometheus, AlertManager, Grafana, Blackbox Exporter)"}
{"id":"claude-usn","title":"Off-Site Backup Strategie (3-2-1 Rule)","description":"## Ziel\nVerschluesselte Off-Site Backups von Elysium in die Cloud. Dritte Kopie nach der 3-2-1 Regel.\n\n## Backup-Quellen (was muss off-site gesichert werden)\n- Immich Fotos + Datenbank\n- Nextcloud Dateien\n- Proxmox VM/LXC Configs (klein, aber kritisch)\n- Home Assistant Backup\n- E-Mail Archiv (spaeter)\n- NICHT: Jellyfin Media (wiederbeschaffbar)\n\n## Off-Site Ziel: Google Drive 2TB (bereits bezahlt via Google AI Abo)\n- Verschluesselung: Restic oder Rclone crypt (client-seitig, Google sieht nur Ciphertext)\n- Bandbreite: Upload-Speed pruefen, ggf. Initial-Backup throttlen\n\n## Alternative falls 2TB nicht reichen\n- Backblaze B2 (~5 EUR/TB/Monat)\n- Hetzner Storage Box (~3.50 EUR/TB/Monat, DE-Standort)\n\n## Backup-Tool: Restic (empfohlen)\n- Dedupliziert + verschluesselt\n- Unterstuetzt Google Drive (via Rclone Backend), Backblaze B2, S3\n- Snapshot-basiert (Versionierung gratis)\n- Pruning-Policies (z.B. 7 daily, 4 weekly, 6 monthly)\n\n## Bestehendes Backup (nicht aendern)\n- Solaris (MacBook): Backblaze Personal -- laeuft unabhaengig, bleibt so\n- iPhone: Fotos kuenftig via Immich gesichert, iCloud als Fallback behalten\n\n## Schritte\n1. Rclone auf Elysium installieren + Google Drive Remote konfigurieren\n2. Restic Repository auf Google Drive erstellen (verschluesselt)\n3. Backup-Script: Immich + Nextcloud + HA + Configs\n4. Cron-Job: Taeglich oder woechentlich\n5. Pruning-Policy konfigurieren\n6. Restore-Test durchfuehren\n7. Monitoring: Benachrichtigung bei Backup-Fehler\n\n## Akzeptanzkriterien\n- [ ] Restic + Rclone auf Elysium konfiguriert\n- [ ] Verschluesseltes Backup auf Google Drive funktioniert\n- [ ] Automatischer Cron-Job laeuft\n- [ ] Restore-Test erfolgreich\n- [ ] Speicherverbrauch auf Google Drive \u003c 2TB","status":"open","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T09:51:34Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:09Z","labels":["epic:claude-k6i"]}
{"id":"claude-uvj","title":"Calibre-Web: Bücher-Import (~84GB, ~1767 Dateien)","description":"## Quellen (auf Solaris/MacBook)\n\n### 1. Hugo Awards Collection (73 GB, 1102 Dateien)\n- Pfad: ~/Hugo/\n- Formate: EPUB (686) + MOBI (416)\n- Struktur: Nach Jahr (2016-2025) und Kategorie\n- Wichtigste Sammlung!\n\n### 2. Books INBOX (6.1 GB, 625 Dateien)\n- Pfad: ~/Documents/INBOX/Books/\n- Formate: PDF (400) + MOBI (216) + EPUB (9)\n- Gemischt: Sachbücher, Reiseführer, Fiction\n\n### 3. Calibre-Bibliothek (57 MB, 16 EPUB)\n- Pfad: ~/Calibre-Bibliothek/\n- Hat bereits metadata.db\n- 14 Autoren-Ordner\n\n### 4. Agile Training/Topics (4.6 GB, 18 Dateien)\n- Pfade: ~/Documents/Agile Training/ + ~/Documents/Agile Topics/\n- EPUB (9) + MOBI (9)\n- Professionelle Entwicklung\n\n### 5. Calibre Library (652 KB, 1 EPUB)\n- Pfad: ~/Calibre Library/\n- Minimal, hat metadata.db\n\n## Migrationsstrategie\n1. Calibre-Bibliothek metadata.db als Basis in Calibre-Web importieren\n2. Hugo Collection per calibredb add importieren (nach Jahr als Tag)\n3. Books INBOX durchgehen - PDFs vs. echte E-Books trennen\n4. Agile-Bücher importieren\n\n## Transfer\nrsync/scp von Solaris nach LXC 109 (192.168.60.19:/opt/calibre-web/books/)\n\n## Akzeptanzkriterien\n- [ ] Alle Hugo Awards E-Books importiert und nach Jahr getaggt\n- [ ] INBOX Books importiert\n- [ ] Bestehende Calibre-Bibliotheken merged\n- [ ] Agile-Bücher importiert\n- [ ] Calibre-Web zeigt alle Bücher mit Metadaten","notes":"KLARSTELLUNG: Beim Hugo-Import nur Text-Formate (EPUB/MOBI/PDF) aus Fiction-Kategorien (Novel, Novella, Novelette, Short Story, Series, Astounding, Lodestar). Audio-Dateien gehen nach Audiobookshelf (claude-oza), Graphic Novels separat.\nAUSSCHLUSS Graphic Novels: Hugo Graphic Story Kategorien gehen nach Komga (claude-eg7), nicht nach Calibre-Web. Calibre-Web importiert nur Text-Fiction (Novel, Novella, Novelette, Short Story) und Sachbücher.\nPOST-IMPORT ARCHIVIERUNG: Nach erfolgreichem Import Quelldateien auf PRO-G40 verschieben (Pattern: claude-e41). Ziel: /Volumes/PRO-G40/Imported-to-Elysium/{Service}/ mit .manifest.json. Befreit lokalen Speicher auf Solaris und dokumentiert Import-Status.\n## Zusätzliche Quellen (Spotlight-Scan 2026-02-17)\n\n### 6. Apple Books / iBooks iCloud (2,4 GB, 178 EPUBs)\n- Pfad: ~/Library/Mobile Documents/iCloud~com~apple~iBooks/Documents/\n- Viele Hugo-Duplikate, aber auch eigenständige Titel (Annihilation, Southern Reach Trilogy, Return of the Lazy Dungeon Master, etc.)\n- Vor Import: Duplikate gegen Hugo-Collection abgleichen\n\n### 7. cognovis Leadership Books (946 MB, 12 EPUBs)\n- Pfad: ~/Documents/cognovis/Dokumente/Reading Material/Leadership/\n- Professionelle Entwicklung: Servant Leadership, Humble Leadership, Long Distance Leader, etc.\n- Enthält auch 1 Audiobook (MP3) → geht nach Audiobookshelf\n\n### 8. Documents/Stories (16 MB, 12 EPUBs)\n- Pfad: ~/Documents/Stories/\n- Fiction-Sammlung (verschiedene Autoren)\n\n### 9. Thorium Reader Cache (1 EPUB)\n- Pfad: ~/Library/Application Support/EDRLab.ThoriumReader/publications/\n- Prüfen ob Duplikat\n\n### 10. Kindle-Formate AZW/AZW3 (6 Dateien)\n- 4x AZW in ~/Documents/INBOX/Books/ (Too Big To Fail, What The Dog Saw, Piano Teacher, Junkie)\n- 2x AZW3 in Hugo 2022\n- Calibre kann AZW/AZW3 importieren\n\n## Deduplizierungsstrategie\n- Bei mehreren Formaten desselben Titels: EPUB bevorzugen, dann AZW3, dann MOBI, dann PDF\n- calibredb add --one-book-per-directory oder manuelles Filtern\n- Hugo-Duplikate zwischen iBooks iCloud und ~/Hugo/ identifizieren und nur einmal importieren\n\n## Post-Import Validierung\n- Nach Verschieben aller Quelldateien: finaler Spotlight-Scan auf ~ um verbleibende E-Books zu finden\n- mdfind für EPUB, MOBI, AZW, AZW3, PDF (in Book-Kontexten)\nFinal Spotlight scan: no missing EPUBs. 3 stray MOBIs found in INBOX subfolders (Coaching, Negotiation, Scrummaster) - imported. Total: 777 books in Calibre-Web. All 10 sources archived to PRO-G40/Imported-to-Elysium/Calibre-Web/.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T03:02:43Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","closed_at":"2026-02-17T10:29:09Z","close_reason":"777 Bücher importiert aus 10 Quellen (Hugo, iBooks, INBOX, Agile Training/Topics, Calibre-Bibliothek/Library, cognovis, Stories, Stray MOBIs). PDFs mit exiftool-Metadaten, 5 Lonely Planet Guides gemergt, Comics an Komga. Alle Quellen auf PRO-G40 archiviert.","labels":["epic:claude-k6i"]}
{"id":"claude-uwm","title":"Session Close Skill: /session-close Command","description":"Neuer Skill in malte/skills/session-close/ der den erweiterten Session Close Workflow orchestriert:\n\nWorkflow-Schritte:\n1. Offene Beads prüfen und schließen lassen\n2. git status + staged changes review\n3. Conventional Commit Message erstellen\n4. git-cliff: Changelog-Eintrag generieren\n5. CalVer: Nächste Version bestimmen (YYYY.0M.MICRO)\n6. Doku-Check: Hat sich was geändert das Doku braucht?\n7. Learnings-Pipeline triggern\n8. git tag + commit + push\n9. bd sync\n\nDer Skill ersetzt das aktuelle manuelle Session Close Protokoll in PRIME.md/CLAUDE.md.\n\nAkzeptanzkriterien:\n- /session-close triggert den vollen Workflow\n- Changelog wird automatisch aktualisiert\n- Version-Tag wird gesetzt\n- Learnings werden extrahiert\n- Doku-Gaps werden gemeldet","status":"closed","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-26T02:08:25Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:23:13Z","closed_at":"2026-02-26T02:23:13Z","close_reason":"Skill created: SKILL.md + skill.zsh + 4 handlers (beads-close, changelog, version, docs-check). All tested with --dry-run. Integrates with infrastructure scripts/next-version.sh and cliff.toml.","dependencies":[{"issue_id":"claude-uwm","depends_on_id":"claude-l31","type":"blocks","created_at":"2026-02-26T02:09:10Z","created_by":"Malte Sussdorff","metadata":"{}"},{"issue_id":"claude-uwm","depends_on_id":"claude-pog","type":"blocks","created_at":"2026-02-26T02:09:09Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-uyn","title":"Migrate deploy-imap.sh to Python with UPSERT logic","description":"Replace destructive DELETE+INSERT deploy-imap.sh with deploy-imap.py using UPSERT semantics. Preserves import statistics (total, imported, duplicate, error). Adds --dry-run and --status modes. Uses uv script header, stdlib only.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T10:25:57Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:12Z","closed_at":"2026-02-17T10:28:27Z","close_reason":"Replaced deploy-imap.sh with deploy-imap.py: UPSERT preserves import stats, --dry-run and --status modes, verified with live dry-run (6/6 accounts matched)"}
{"id":"claude-vj7","title":"Paperless-ngx auf Elysium deployen (Dokumenten-Management)","description":"## Ziel\nSelf-hosted DMS fuer Papierkram: Rechnungen, Vertraege, Bescheide, Steuerdokumente, Scans.\nAutomatisches OCR, KI-Tagging, Volltextsuche. Zugriff via Web-UI (auch mobil).\n\n## Domain\npaperless.sussdorff.de (Hetzner DNS, Caddy Reverse Proxy, Let's Encrypt)\n\n## Hardware-Integration: ScanSnap iX1600\n- Steht direkt neben Elysium\n- Aktuell: Scannt nach /Users/malte/Documents/Scans auf Solaris (MacBook)\n- Neu: ScanSnap direkt an Elysium anschliessen (USB) ODER\n  Scan-Ordner auf Solaris -\u003e Nextcloud Sync -\u003e Paperless Consume-Ordner\n- Paperless 'Consume'-Ordner: Alles was reinkommt wird automatisch verarbeitet\n\n### Scan-Workflow Optionen\nA) ScanSnap -\u003e USB an Elysium -\u003e direkt in Consume-Ordner (kuerzester Weg)\nB) ScanSnap -\u003e Solaris -\u003e Sync-Ordner -\u003e Paperless Consume (flexibler, Scan auch wenn nicht am Schreibtisch)\nC) ScanSnap Cloud -\u003e Paperless API (ueber Internet, unnoetiger Umweg)\n-\u003e Empfehlung: Option A wenn ScanSnap dauerhaft am Schreibtisch neben Elysium steht\n\n## Schritte\n\n### Deployment\n1. LXC fuer Paperless-ngx erstellen (Docker: paperless, redis, postgres, gotenberg, tika)\n2. Storage: Dokumente auf NVMe (primaer), Backup auf DAS\n3. DNS: A-Record paperless.sussdorff.de (Hetzner)\n4. Caddy Reverse Proxy + TLS\n5. Alternativ/zusaetzlich: Tailscale fuer VPN-Zugriff von unterwegs\n\n### ScanSnap Integration\n6. ScanSnap iX1600 Anbindung konfigurieren (USB an Elysium oder Sync-Ordner)\n7. Consume-Ordner einrichten (automatischer Import)\n8. Test-Scan -\u003e automatisch in Paperless\n\n### KI + Automatisierung\n9. OCR konfigurieren (Deutsch + Englisch)\n10. Auto-Tagging Regeln erstellen:\n    - Korrespondenten (Telekom, Finanzamt, Versicherung etc.)\n    - Dokumenttypen (Rechnung, Vertrag, Bescheid, Kontoauszug)\n    - Datum automatisch aus Dokument extrahieren\n11. Mail-Consumption (optional): Paperless kann Dokumente direkt aus E-Mail-Anhaengen importieren\n\n### Migration bestehender Dokumente\n12. /Users/malte/Documents/Scans importieren (bestehende Scans)\n13. Weitere relevante PDFs aus Finder-Ordnern importieren\n14. Tags/Kategorien nach Import pruefen und korrigieren\n\n### Backup\n15. DAS: Paperless-Daten auf /mnt/das/archive\n16. Off-Site: In Restic/Rclone Backup-Job aufnehmen (Google Drive 2TB)\n\n## Zugriff von unterwegs\n- Web-UI (responsive, iPhone-tauglich)\n- Tailscale VPN (empfohlen) oder oeffentlich via Caddy\n- Typischer Use-Case: Steuer-Dokument suchen, PDF oeffnen/downloaden\n- Kein Offline-Sync noetig (Suche + Download reicht)\n\n## Ressourcen\n- RAM: ~1 GB (Paperless + Redis + Tika/Gotenberg fuer OCR)\n- Disk: Abhaengig von Dokumentenmenge, typisch 5-50 GB\n- CPU: OCR braucht kurz Power bei neuen Dokumenten, sonst idle\n\n## Akzeptanzkriterien\n- [ ] Paperless Web-UI erreichbar unter paperless.sussdorff.de\n- [ ] ScanSnap -\u003e Consume -\u003e automatisch importiert + OCR\n- [ ] Volltextsuche funktioniert (deutsch + englisch)\n- [ ] Auto-Tagging fuer gaengige Korrespondenten\n- [ ] Bestehende Scans migriert\n- [ ] Backup auf DAS + Off-Site eingerichtet\n- [ ] Zugriff von unterwegs (Tailscale oder Caddy)","notes":"LXC setup-skripte + docker-compose (Paperless+Redis+PostgreSQL+Gotenberg+Tika) + .env.example + deploy.sh erstellt (lxc/paperless/). OCR für deu+eng, Caddy-Entry für paperless.sussdorff.de. Nächster Schritt: setup-lxc.sh auf Proxmox, .env anlegen, deploy.sh, dann ScanSnap anbinden.\nDeployed und verifiziert. 5/5 Container laufen (Paperless, Redis, PostgreSQL, Gotenberg, Tika). Extern erreichbar unter https://paperless.sussdorff.de (HTTP 302 -\u003e Login). Placeholder-Passwort in .env muss noch geändert werden.\nWeb-Setup abgeschlossen. Admin-Login verifiziert. v2.20.6 läuft. Placeholder-Passwörter durch sichere ersetzt. ScanSnap noch nicht angebunden.","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T10:00:51Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:13Z","closed_at":"2026-02-17T02:50:30Z","close_reason":"LXC 108 deployed, Paperless-ngx v2.20.6 mit Gotenberg+Tika+OCR deu+eng. Admin login OK. Dokumente noch nicht importiert (separater Bead).","labels":["epic:claude-k6i"]}
{"id":"claude-vsx","title":"ABS ASIN-Enrichment: Audible-Bücher ohne ASIN mit Libation-Daten abgleichen","description":"## Ziel\n62 Audiobookshelf-Items haben keine ASIN. Davon sind viele PDFs oder Non-Audible-Content (Hugo Awards, manuelle Imports). Für echte Audible-Bücher ohne ASIN: ASIN aus Libation DB per Title-Matching nachpflegen via ABS API.\n\n## Ansatz\n1. ABS-Items ohne ASIN filtern\n2. PDFs und Non-Audible-Content ausschließen\n3. Verbleibende per Titel gegen Libation DB matchen\n4. ASIN via ABS API PATCH setzen\n\n## Akzeptanzkriterien\n- [ ] Alle Audible-Bücher in ABS haben korrekte ASIN\n- [ ] PDFs und Non-Audible bleiben unverändert\n- [ ] Script ist wiederholbar","notes":"ASIN Enrichment: 21 items enriched via exact+substring title matching against Libation DB (99→133 with ASIN). PDF Cleanup: moved Discord of Gods PDF to correct folder, deleted 5 orphan PDF duplicates, 4 zero-byte artifacts, 4 duplicate (1) copies, 12 ghost ABS items. Remaining: 1 Oathbringer audio dupe (269h vs 55h, different source folders), 42 items without ASIN (genuine non-Audible content). Ebook companions not auto-detected by ABS scan — may need investigation.","status":"closed","priority":3,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:00:33Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:14Z","closed_at":"2026-02-17T14:26:42Z","close_reason":"21 Audible books enriched with ASIN via title matching (99→133), 15 duplicate/ghost items cleaned up, 1 Oathbringer dupe remaining (needs manual decision on which copy to keep)"}
{"id":"claude-vtb","title":"ABS Library Restructure: Fix multi-book folders + Libation template","description":"39 series folders had multiple books as flat files in one folder. ABS treated each as a single merged item. Split all 39 folders into per-book subfolders (145 books, 395 file moves). Fixed Libation FolderTemplate to prevent recurrence. Cleaned 33 stale isMissing entries, enriched metadata. Final: 263 items, 252 with ASIN (96%), 263 with covers (100%), 0 isMissing.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T15:04:13Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:15Z","closed_at":"2026-02-17T15:04:20Z","close_reason":"39 folders split into 145 per-book subfolders (395 file moves). Libation FolderTemplate fixed: \u003cauthor\u003e\u003cif series-\u003e/\u003cseries\u003e/\u003cseries#[00.##]\u003e - \u003ctitle short\u003e\u003c-if series\u003e. 33 stale isMissing items deleted. Final library: 263 items, 252 ASIN (96%), 263 covers (100%), 0 isMissing."}
{"id":"claude-vx7","title":"Unified 1Password → .env injection for LXC deploys","description":"## Problem\nCredential handling is ad-hoc across LXC containers. Secrets live as plaintext in .env files on containers. Only Mailpiler IMAP has 1Password integration (deploy-imap.py running from Mac). Docker warns about unencrypted credentials.\n\n## Solution: 1Password Service Account + op run\n\nUse a **1Password Service Account** with read-only access to the \"API Keys\" vault. Install `op` CLI on containers that need runtime secrets. Use `op run --env-file=.env.tpl` to inject secrets at Docker Compose startup — secrets never touch disk.\n\n### Architecture\n\n```\n1Password Cloud (API Keys vault)\n        │\n        ▼\n   Service Account Token (OP_SERVICE_ACCOUNT_TOKEN)\n   - read_items on \"API Keys\" vault only\n   - stored as /etc/op-service-account-token on each LXC (root:root 0600)\n        │\n        ├── LXC 111 (Mailpiler) ──→ op run --env-file=.env.tpl -- docker compose up -d\n        ├── LXC 114 (MIRA)      ──→ op run --env-file=.env.tpl -- docker compose up -d\n        ├── LXC 101 (Ignis)     ──→ op run --env-file=.env.tpl -- docker compose up -d\n        ├── LXC 108 (Paperless) ──→ op run --env-file=.env.tpl -- docker compose up -d\n        └── LXC 107 (Immich)    ──→ op run --env-file=.env.tpl -- docker compose up -d\n```\n\n### .env.tpl format (replaces .env)\n```\n# Non-secret values stay as plain text\nPILER_DOMAIN=mail-archive.sussdorff.de\nPILER_VERSION=1.4.8\nTIME_ZONE=Europe/Berlin\n\n# Secrets reference 1Password via op:// URIs\nMYSQL_PASSWORD=op://API Keys/Mailpiler-DB/password\n```\n\n### How op run works\n- Reads .env.tpl, resolves op:// references against 1Password\n- Injects resolved values as env vars into subprocess (docker compose)\n- Secrets exist only in process memory, never written to disk\n- Docker Compose reads env vars as usual (${MYSQL_PASSWORD} syntax)\n\n### Containers and their secrets\n\n**Mailpiler (111)** — CRITICAL (all emails)\n- MYSQL_PASSWORD (DB access, healthcheck)\n- 1Password item: needs new \"Mailpiler-DB\" item with password field\n- Note: deploy-imap.py stays as-is (it syncs IMAP accounts to DB, different concern)\n\n**MIRA (114)** — 5+ API keys\n- AIDBOX_PASSWORD, AIDBOX_LICENSE_KEY, ELEVENLABS_API_KEY, ELEVENLABS_AGENT_ID\n- TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, TWILIO_PHONE_NUMBER\n- ANTHROPIC_API_KEY, OPENAI_API_KEY, JWT_SECRET\n\n**Ignis (101)** — 7 API keys (overlaps with MIRA)\n- Shares: OPENAI_API_KEY, ELEVENLABS_*, TWILIO_*\n\n**Paperless (108)** — DB + admin passwords\n- PAPERLESS_ADMIN_PASSWORD, PAPERLESS_DB_PASSWORD\n\n**Immich (107)** — DB password\n- DB_PASSWORD\n\n### Implementation steps\n\n1. **Create service account** (one for all containers)\n   - `op service-account create claude-lxc --vault \"API Keys\":read_items`\n   - Store token in 1Password itself + deploy to containers\n\n2. **Create/update 1Password items** for missing DB credentials\n   - Mailpiler-DB (MYSQL_PASSWORD)\n   - Paperless-DB (PAPERLESS_DB_PASSWORD)\n   - Immich-DB (DB_PASSWORD)\n   - MIRA items (if not already there)\n\n3. **Create shared lib/op-setup.sh** helper\n   - Installs op CLI on Debian LXC\n   - Deploys service account token to /etc/op-service-account-token\n   - Creates systemd drop-in or wrapper for op run\n\n4. **Convert each container** (.env → .env.tpl)\n   - Replace secret values with op:// references\n   - Update deploy.sh to use op run pattern\n   - Update docker compose restart to use op run (for secret rotation)\n\n5. **Create restart wrapper** per container\n   - `/opt/\u003cservice\u003e/start.sh`: reads token, runs `op run --env-file=.env.tpl -- docker compose up -d`\n   - Handles container reboot (systemd service or cron @reboot)\n\n### Mailpiler-specific concerns\n- DB password is used in healthcheck command in docker-compose.yaml\n- docker-compose.yaml uses ${MYSQL_PASSWORD} interpolation — op run handles this\n- deploy-imap.py is orthogonal (syncs IMAP accounts, not Docker secrets) — keep as-is\n- piler stores all emails encrypted with key in /etc/piler/piler.conf — no change needed\n\n### Acceptance criteria\n- [ ] Service account created with read-only access to \"API Keys\" vault\n- [ ] op CLI installed on all 5 containers\n- [ ] .env.tpl files replace .env for all 5 containers\n- [ ] deploy.sh scripts updated to use op run pattern\n- [ ] Containers survive reboot (start.sh + systemd)\n- [ ] Existing Mailpiler data unaffected (test: search for recent email after migration)\n- [ ] Dry-run / validation: `op run --env-file=.env.tpl -- env | grep MYSQL` works\n- [ ] deploy-imap.py continues to work (unchanged)","notes":"Starting implementation. Phase 1: Service account + Mailpiler (most sensitive container).","status":"closed","priority":2,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-20T04:40:50Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:21Z","closed_at":"2026-02-22T05:15:36Z","close_reason":"5/5 Container migriert (Mailpiler, MIRA, Ignis, Paperless, Immich). op CLI 2.32.1, SA-Token, .env.tpl + start.sh auf allen Containern. Alte .env mit Plaintext-Secrets entfernt. 7 neue 1Password-Items (MIRA, Ignis, ElevenLabs, Twilio, Immich + Paperless-Update). Deploy-Script lxc/deploy-op-integration.sh für Wiederholung."}
{"id":"claude-wj6","title":"AlertManager + ntfy Notification-Pipeline","description":"## Anforderungen\nAlertManager konfigurieren für Disk/Memory-Alerts mit ntfy als Notification-Kanal.\n\n## Alert-Regeln (Prometheus):\n- DiskUsageWarning: node_filesystem_avail_bytes / node_filesystem_size_bytes \u003c 0.20 (\u003e80% used) → warning\n- DiskUsageCritical: \u003c 0.10 (\u003e90% used) → critical\n- MemoryUsageWarning: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes \u003c 0.15 (\u003e85% used) → warning\n- MemoryUsageCritical: \u003c 0.05 (\u003e95% used) → critical\n- ServiceDown: probe_success == 0 (Blackbox Exporter) → critical\n\n## ntfy Setup:\n- Self-hosted ntfy ODER ntfy.sh Topic\n- AlertManager webhook receiver → ntfy\n\n## Akzeptanzkriterien\n- [ ] Prometheus alert rules für Disk (80%/90%) und Memory (85%/95%)\n- [ ] AlertManager config mit ntfy receiver\n- [ ] Test-Alert auslösbar und kommt als Push-Notification an\n- [ ] Grouping: Alerts pro Container gruppiert (nicht einzeln pro Filesystem)\n- [ ] Silence/Inhibit: Critical unterdrückt Warning für gleichen Container","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-17T14:30:42Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:16Z","closed_at":"2026-02-17T14:45:38Z","close_reason":"AlertManager mit ntfy Webhook konfiguriert, Inhibit-Rules aktiv, 6 Alert-Regeln geladen","dependencies":[{"issue_id":"claude-wj6","depends_on_id":"claude-0tk","type":"blocks","created_at":"2026-02-17T15:31:03Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-wlg","title":"Deploy nginx on NetBird VPS via docker-compose.override.yml","description":"nginx Container auf dem NetBird VPS (46.224.133.69) via docker-compose.override.yml deployen.\n\n## Ziel\nStatische Landing Pages + .well-known Redirects für cognovis.de und sussdorff.de direkt auf dem VPS hosten, ohne NetBird Custom Domain (*.cognovis.de Wildcard-Konflikt).\n\n## Architektur\n- nginx Container joined das `netbird` Docker Network\n- Traefik entdeckt ihn via Docker Labels (exposedbydefault=false, traefik.enable=true)\n- Let's Encrypt Cert automatisch via bestehenden letsencrypt Resolver\n- HTTP Router priority=100 matched vor TCP catch-all (priority=1)\n- docker-compose.override.yml überlebt NetBird Updates (getting-started.sh überschreibt nur docker-compose.yml)\n\n## Domains\n- cognovis.de + www.cognovis.de\n- sussdorff.de + www.sussdorff.de\n\n## .well-known Redirects (beide Domains)\n- /.well-known/carddav → https://carddav.fastmail.com (301)\n- /.well-known/caldav → https://caldav.fastmail.com (301)\n\n## Files auf VPS\n- /opt/docker-compose.override.yml\n- /opt/cognovis-web/nginx.conf (vhosts)\n- /opt/cognovis-web/html/cognovis.de/index.html\n- /opt/cognovis-web/html/sussdorff.de/index.html\n\n## Files im Repo (IaC)\n- vps/netbird/docker-compose.override.yml\n- vps/netbird/cognovis-web/ (nginx config + HTML)\n- vps/netbird/deploy-web.sh (rsync + docker compose restart)\n\n## DNS-Änderungen\n- cognovis.de A → 46.224.133.69 (aktuell 138.201.89.78)\n- www.cognovis.de → CNAME netbird.cognovis.de (aktuell A 138.201.89.78)\n- sussdorff.de: prüfen ob Änderung nötig\n\n## Acceptance Criteria\n- [ ] nginx Container läuft auf VPS im netbird Network\n- [ ] https://cognovis.de zeigt Landing Page\n- [ ] https://sussdorff.de zeigt Landing Page\n- [ ] .well-known/carddav + caldav Redirects funktionieren\n- [ ] docker-compose.override.yml überlebt `docker compose up -d`\n- [ ] Deploy-Script im Repo\n- [ ] DNS Records aktualisiert","notes":"## Stand 2026-02-25\n\n### Erledigt\n- docker-compose.override.yml deployed to /opt/ on VPS\n- nginx container (cognovis-web) running on opt_netbird network\n- Traefik auto-discovered container, routing works (HTTP 200 on both domains)\n- .well-known/carddav → 301 Fastmail, .well-known/caldav → 301 Fastmail\n- DNS updated: cognovis.de A → 46.224.133.69, *.cognovis.de A → 46.224.133.69, www CNAME → netbird.cognovis.de\n- DNS updated: sussdorff.de A → 46.224.133.69, www CNAME → netbird.cognovis.de\n\n### Wartend\n- Let's Encrypt Certs: ACME TLS challenge schlägt fehl weil DNS noch nicht propagiert (LE resolves noch alte IPs). Traefik retried automatisch. Rate-limited auf sussdorff.de bis ~11:27 UTC.\n- Aktuell Traefik Default Cert (self-signed) — funktioniert mit curl -k\n\n### IaC\n- vps/netbird/docker-compose.override.yml\n- vps/netbird/cognovis-web/ (nginx.conf + HTML)\n- vps/netbird/deploy-web.sh\n\n### SSH-Zugang\n- `ssh netbird` funktioniert (via NetBird Mesh, nicht öffentliches Internet)\n- Port 22 öffentlich closed (fail2ban oder sshd config)\n- SSH config: ~/.ssh/config.d/netbird existiert bereits\n## Ergebnis 2026-02-25\n\n### cognovis.de ✅ FERTIG\n- Landing Page served via HTTPS mit gültigem LE Cert (CN=cognovis.de, SAN=www.cognovis.de)\n- .well-known/carddav → 301 Fastmail ✅\n- .well-known/caldav → 301 Fastmail ✅\n- Apple Contacts Autodiscovery-Timeout gelöst\n\n### sussdorff.de ⏳ WARTET\n- DNS propagation noch ~50 Min (TTL 3600s, Google/Cloudflare zeigen noch alte IP)\n- LE Rate-limited bis 11:27 UTC (erledigt), aber DNS muss erst propagieren\n- Traefik retried automatisch — Cert wird ohne Eingriff ausgestellt\n- Landing Page funktioniert mit curl -k --resolve\n\n### Dokumentation\n- vps/netbird/README.md angelegt mit Architektur, DNS-Tabellen, Deploy-Anleitung\n- CLAUDE.md Structure-Section um vps/netbird/ erweitert\n- MEMORY.md NetBird-Section von \"geplant\" auf \"deployed\" aktualisiert","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-25T11:12:47Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:17Z","closed_at":"2026-02-25T11:26:02Z","close_reason":"cognovis.de + www mit LE Cert live, .well-known Redirects funktionieren. sussdorff.de wartet nur noch auf DNS-Propagation (~50min), Cert wird automatisch ausgestellt."}
{"id":"claude-wlo","title":"DAS-Gehaeuse beschaffen und ZFS-Pool auf Proxmox einrichten","description":"## Ziel\nUSB-C DAS-Gehaeuse mit 4x WD 4TB an Elysium anschliessen, ZFS RAIDZ1 Pool erstellen.\n\n## Hardware-Entscheidung\n\n**Gehaeuse: TerraMaster D4-320** (~190 EUR auf Amazon.de)\n- 4 Bay, 3.5 Zoll SATA\n- USB 3.2 Gen2 (10 Gbps) Type-C\n- Hot-Swap Schubladen (Plattentausch ohne Schrauben)\n- Aluminium, Smart-Luefter\n- JBOD-Modus (kein Hardware-RAID -- ideal fuer ZFS)\n- ASIN: B0CTWSD8X6 oder B0DY83XCCH\n\n**Alternativen (abgelehnt):**\n- ORICO WS400RC3 (~160 EUR): Hardware-RAID kollidiert mit ZFS, nur USB 3.2 Gen1 (5 Gbps)\n- ICY BOX 4-fach (~133 EUR): USB 3.0 (5 Gbps), Plastik, kein Hot-Swap\n- QNAP TL-D800C (~570 EUR): 8 Bays overkill, fast so teuer wie UNAS Pro\n\n**Platten: 4x WD 4TB HDD** (vorhanden)\n- Eine Platte enthaelt aktuell Windows-Disk-Image (Rollback Safety Net)\n- Vor Einbau: Windows-Image loeschen oder auf andere Platte sichern falls noch gewuenscht\n\n**Anschluss an Elysium (GMKtec EVO-X1):**\n- Option A: USB-A 3.2 Gen2 Port (10 Gbps) -- 4 Ports verfuegbar\n- Option B: USB 4 Port (40 Gbps, abwaertskompatibel) -- 1 Port verfuegbar\n- Empfehlung: USB-A 3.2 Gen2 nutzen, USB 4 Port frei lassen fuer andere Zwecke\n\n## Schritte\n1. TerraMaster D4-320 bestellen (~190 EUR Amazon.de)\n2. Windows-Image von Backup-Platte: behalten oder loeschen entscheiden\n3. 4x WD 4TB HDDs in Hot-Swap Schubladen einsetzen\n4. Per USB-C an Elysium anschliessen (USB-A 3.2 Gen2 oder USB 4)\n5. ZFS RAIDZ1 Pool erstellen (~12TB nutzbar, 1 Platte Redundanz)\n6. Mount-Points einrichten:\n   - /mnt/das/backup (Proxmox Backups)\n   - /mnt/das/media (Jellyfin Media)\n   - /mnt/das/archive (E-Mail Archiv, Immich Backup)\n7. ZFS scrub cron-job einrichten (monatlich)\n8. SMART-Monitoring aktivieren (smartmontools)\n\n## Akzeptanzkriterien\n- [ ] DAS-Gehaeuse bestellt und geliefert\n- [ ] ZFS RAIDZ1 Pool healthy und gemountet\n- [ ] SMART-Monitoring fuer alle 4 Platten aktiv\n- [ ] Mount-Points persistent nach Reboot\n- [ ] ZFS scrub scheduled\n\n## Hinweise\n- USB-DAS an Proxmox: zuverlaessig genug fuer Backup/Media/Archiv\n- Nicht fuer primaeren Datei-Speicher verwenden (bekannte USB-Disconnect-Problematik bei ZFS)\n- Primaere Dateiablage gehoert auf die 4TB NVMe in Elysium (Nextcloud)\n- Bei USB-Disconnect: ZFS Pool geht read-only, nach Reconnect resilver/scrub","notes":"2026-02-16: TerraMaster D4-320 bestellt (Amazon.de). Naechster Schritt: Lieferung abwarten, dann HDDs einbauen und ZFS-Pool auf Proxmox einrichten.","status":"in_progress","priority":1,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T08:29:56Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:18Z","labels":["decision","epic:claude-k6i"],"dependencies":[{"issue_id":"claude-wlo","depends_on_id":"claude-fc0","type":"blocks","created_at":"2026-02-16T11:22:58Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
{"id":"claude-wno","title":"Reverse Proxy (Traefik/Caddy) für Proxmox Services","description":"Zentraler Reverse Proxy für alle gehosteten Services auf Elysium.\n\n## Architektur\n- Caddy in schlanker LXC (kein Docker nötig)\n- VLAN 60 (Services/DMZ), IP 192.168.60.5\n- SSL-Terminierung via Let's Encrypt (HTTP-Challenge oder DNS-Challenge)\n- Port-Forwarding im UniFi Gateway: 80/443 → 192.168.60.5\n\n## Proxy-Routen\n- ignis.cognovis.de → 192.168.60.10:80 (Ignis FHIR Demo)\n- Zukünftig: weitere Services auf VLAN 60\n\n## Akzeptanzkriterien\n- [ ] LXC 102 auf VLAN 60 mit Caddy installiert\n- [ ] ignis.cognovis.de → Ignis LXC proxied\n- [ ] SSL/TLS via Let's Encrypt funktioniert\n- [ ] Autostart konfiguriert\n- [ ] Port-Forwarding 80/443 im UniFi Gateway eingerichtet","notes":"LXC 102 (proxy) erstellt auf 192.168.60.5, VLAN 60. Caddy 2.10.2 installiert, enabled, Autostart. Caddyfile: ignis.cognovis.de → 192.168.60.10:80. Lokal testbar via :8080. Noch offen: Port-Forwarding 80/443 im UniFi Gateway, DNS ignis.cognovis.de auf externe IP.\nPort-Forwarding umgebogen: 80/443 → 192.168.60.5 (Caddy Proxy). Alte Regeln zeigten auf 192.168.2.26 (aura, offline). Let's Encrypt Zertifikat erfolgreich via TLS-ALPN-01 Challenge. https://ignis.cognovis.de gibt HTTP 200.","status":"closed","priority":1,"issue_type":"feature","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-15T12:46:22Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:19Z","closed_at":"2026-02-15T16:51:03Z","close_reason":"Caddy LXC 102 auf 192.168.60.5, Let's Encrypt SSL aktiv, Port-Forwarding 80/443 konfiguriert, ignis.cognovis.de erreichbar","work_type":"mutex"}
{"id":"claude-wvc","title":"[DISCOVERY] Kalender-Konsolidierung evaluieren","description":"## Ist-Zustand\n- Fastmail: Business-Kalender (CalDAV)\n- Apple/iCloud: Private Kalender\n- Google: Obligatorischer Google-Kalender\n- Diverse Kunden-Kalender (je nach Projekt)\n- Fantastical als Aggregator (funktioniert, aber nicht rund)\n- Buchungslinks: theoretisch ueber Fantastical moeglich\n\n## Fragen zu klaeren\n1. Lohnt sich Zentralisierung auf Nextcloud CalDAV?\n   - Pro: Ein Ort fuer alles, eigene Kontrolle\n   - Contra: Kunden-Kalender bleiben extern, Fastmail-CalDAV funktioniert schon\n2. Was genau fuehlt sich 'nicht rund' an bei Fantastical?\n   - Sync-Probleme? Darstellung? Buchungslinks?\n3. Buchungslinks: Fantastical vs. Cal.com (self-hosted) vs. Calendly?\n4. Kontakte-Sync: Auch konsolidieren? (Fastmail CardDAV, Apple Contacts, Google)\n\n## Ergebnis\nDiscovery-Bead: Entscheidung dokumentieren ob/wie konsolidiert wird.\nKein Code, nur Recherche und Entscheidung.","status":"open","priority":4,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-16T08:30:36Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:20Z","labels":["epic:claude-k6i"]}
{"id":"claude-xly","title":"Deploy central Dolt server for shared beads across team","description":"## Context\nTeam members clone beads repos and work with beads issues. Currently synced via JSONL export to git beads-sync branch. JSONL merge conflicts are a recurring pain point.\n\n## Decision Needed\nWhere to host the central Dolt SQL server:\n- **Option A: Hetzner (dolt.cognovis.de)** — Public DNS, reachable externally without VPN. Same server as planned Netbird deployment.\n- **Option B: Proxmox LXC (internal)** — Alongside MIRA and other services. Requires Netbird/VPN for remote access but consolidates infra.\n\n## Requirements\n- Dolt SQL server accessible by all team members\n- TLS for remote connections\n- Auth (MySQL user/password per team member or shared)\n- Backup strategy for Dolt data\n- Team members configure `bd dolt set mode server` + host/port pointing to central server\n- bd dolt push/pull or direct SQL connection\n\n## Acceptance Criteria\n- [ ] Hosting location decided\n- [ ] Dolt server deployed with TLS + auth\n- [ ] At least one project (e.g. mira) configured to use remote Dolt\n- [ ] Team members can bd dolt pull/push successfully\n- [ ] JSONL merge conflicts eliminated from workflow","notes":"## Background\n\n### Current Pain Point\nTeam members work with beads via git clone. `bd sync` exports JSONL to a beads-sync branch, which gets pushed/pulled via git. When multiple people work on issues concurrently, JSONL merge conflicts arise in merge requests — these are tedious to resolve and error-prone.\n\n### What Changed in Beads 0.53+\nBeads 0.53.0 introduced Dolt-native sync (`bd dolt push` / `bd dolt pull`) which replaces the JSONL sync pipeline entirely. With a central Dolt server, all team members read/write directly to SQL — no more JSONL file merges. The old JSONL sync-branch pipeline (~16K lines) was removed.\n\n### How It Works\n- Dolt is a MySQL-compatible database with git-like versioning (branch, merge, diff at cell level)\n- `bd dolt push/pull` uses Dolt's native replication protocol\n- Alternatively, team members can connect directly to a shared Dolt SQL server (`bd dolt set mode server`)\n- TLS + MySQL auth for remote connections\n\n### Infrastructure Options\n- **Hetzner**: Already planned for Netbird. Public DNS (dolt.cognovis.de). No VPN needed. But adds another service to a server that's not yet deployed.\n- **Proxmox**: Services already running (MIRA, Aidbox, etc.). Well-understood LXC deployment. But requires Netbird/VPN for colleagues working remotely.\n\n### Dolt Resource Requirements\n- Lightweight: ~50MB RAM idle, grows with concurrent connections\n- Storage: beads databases are tiny (\u003c 100MB typically)\n- Port: 3306 or 3307 (MySQL protocol)\n- Docker image available: `dolthub/dolt`\n\n### Team Members Using Beads\nProjects with beads: mira, nanobanana, claude-proxmox. Colleagues interact via cloned repos.\nDolt server running on LXC 116 (192.168.60.30:3307), database beads_elysium exists, users configured. TCP proxy via VPS (dolt.cognovis.de:3307) working. Hosting decision: Proxmox LXC 116 (Option B). Remaining: TLS, team member onboarding.","status":"open","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-21T09:17:57Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:20:31Z","labels":["decision"]}
{"id":"claude-zo9","title":"piler-cli: read — Einzelne Mail lesen (pilerget + EML-Parsing)","description":"'piler read \u003cid\u003e' holt piler_id aus MySQL v_messages, ruft pilerget auf, parst EML (MIME/Multipart) zu lesbarem Text + Metadaten (From, To, Subject, Date, Body text/plain, Attachment-Liste). Output: strukturiert für Agent-Konsum (JSON oder formatierter Text). Acceptance: Beliebige archivierte Mail wird lesbar ausgegeben.","status":"closed","priority":2,"issue_type":"task","owner":"malte.sussdorff@cognovis.de","created_at":"2026-02-18T04:27:10Z","created_by":"Malte Sussdorff","updated_at":"2026-02-26T02:18:21Z","closed_at":"2026-02-18T04:31:46Z","close_reason":"Im Scaffold-Task mitimplementiert und gegen Live-Instanz getestet","labels":["epic:claude-ecz"],"dependencies":[{"issue_id":"claude-zo9","depends_on_id":"claude-8oh","type":"blocks","created_at":"2026-02-18T05:27:28Z","created_by":"Malte Sussdorff","metadata":"{}"}]}
